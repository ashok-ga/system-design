{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to System Design Hub","text":""},{"location":"#what-is-this","title":"\ud83d\ude80 What is This?","text":"<p>System Design Hub is a collaborative, open-source resource for learning, teaching, and documenting High-Level Design (HLD) and Low-Level Design (LLD) of software and hardware systems.</p> <p>Whether you are preparing for interviews, architecting a real-world solution, or seeking reference designs, you\u2019ll find clear explanations, diagrams, and design patterns here.</p>"},{"location":"#what-youll-find-here","title":"\ud83d\udcd6 What You'll Find Here","text":"<ul> <li>HLD Docs: Architectural overviews, technology choices, design decisions, major flows, and system context diagrams.</li> <li>LLD Docs: Detailed module specs, class diagrams, sequence diagrams, interface contracts, and logic flows.</li> <li>Diagrams &amp; Visuals: All key concepts are illustrated wherever possible.</li> <li>References: Further reading, links, standards, and best-practice guides.</li> <li>Contribution Guide: Friendly guidance for adding your own designs or improvements.</li> </ul>"},{"location":"#how-this-repository-is-organized","title":"\ud83d\uddc2\ufe0f How This Repository is Organized","text":"<ul> <li><code>hld/</code>: High-Level Design (system overviews, architectures, context)</li> <li><code>lld/</code>: Low-Level Design (detailed modules, APIs, data flows)</li> <li><code>assets/</code>: Shared images and diagrams</li> <li><code>references.md</code>: Papers, blog posts, books, and other resources</li> </ul> <p>Browse using the navigation sidebar or the links above!</p>"},{"location":"#how-to-contribute","title":"\ud83e\udd1d How to Contribute","text":"<p>We welcome your input! - Read the CONTRIBUTING.md for how to start. - Add your system designs, diagrams, or improvements. - Open issues for suggestions, bugs, or topic requests.</p> <p>Let\u2019s make system design knowledge accessible for all.</p>"},{"location":"#who-is-this-for","title":"\ud83d\udce3 Who is This For?","text":"<ul> <li>System architects</li> <li>Backend and full-stack developers</li> <li>Students and interview candidates</li> <li>Hardware and embedded designers</li> <li>Curious engineers</li> </ul> <p>If you want to understand, teach, or build real systems, this is for you!</p>"},{"location":"#star-the-repo-and-share-with-friends-if-you-find-it-useful","title":"\u2b50\ufe0f Star the repo and share with friends if you find it useful!","text":"<p>Happy Designing!</p>"},{"location":"references/","title":"References &amp; Further Reading","text":""},{"location":"references/#books","title":"Books","text":"<ul> <li>Designing Data-Intensive Applications \u2013 Martin Kleppmann</li> <li>System Design Interview \u2013 Alex Xu</li> </ul>"},{"location":"references/#blogs","title":"Blogs","text":"<ul> <li>Uber Engineering Blog</li> <li>Netflix Tech Blog</li> </ul>"},{"location":"references/#community","title":"Community","text":"<ul> <li>Awesome System Design</li> <li>System Design Primer</li> </ul>"},{"location":"references/#standards","title":"Standards","text":"<ul> <li>RFC 7231 (HTTP/1.1)</li> <li>REST API Design Guidelines (Microsoft)</li> </ul>"},{"location":"hld/architecture/","title":"System Architecture Example","text":""},{"location":"hld/architecture/#overview","title":"Overview","text":"<p>This document describes the architecture of a sample distributed system, including major components and their interactions.</p>"},{"location":"hld/architecture/#system-context-diagram","title":"System Context Diagram","text":""},{"location":"hld/architecture/#main-components","title":"Main Components","text":"<ul> <li>API Gateway: Handles all client requests and routing.</li> <li>Service Layer: Business logic is implemented in modular services.</li> <li>Database: Stores persistent data, supports replication and backup.</li> <li>Cache: Improves read performance and reduces DB load.</li> <li>Message Queue: Decouples services and enables async processing.</li> <li>Monitoring &amp; Logging: Provides observability.</li> </ul>"},{"location":"hld/architecture/#key-design-decisions","title":"Key Design Decisions","text":"<ul> <li>Technology stack: Python (FastAPI), PostgreSQL, Redis, RabbitMQ, Prometheus/Grafana</li> <li>Scalability: Each component can be scaled horizontally.</li> <li>Security: JWT-based authentication at API layer.</li> <li>Resilience: Retry policies, timeouts, health checks.</li> </ul>"},{"location":"hld/architecture/#sequence-diagram","title":"Sequence Diagram","text":"<p>Add relevant sequence diagrams for user flows here.</p> <p>Feel free to replace this sample with your own system\u2019s architecture!</p>"},{"location":"hld/de-shaw/","title":"DE Shaw HLD with Implementations","text":"<ul> <li>How to Approach</li> <li>Backtesting Platform (Distributed)</li> <li>CDC Data Platform (Operational DB to Lakehouse)</li> <li>Chat (1_1 + Typing + Read Receipts)</li> <li>Collaborative Document Editing (Google-Docs-lite)</li> <li>Distributed Cache (Multi-Region)</li> <li>Distributed ID Generator (Snowflake-like)</li> <li>E-commerce Checkout</li> <li>Feature Flag Platform (Multi-tenant)</li> <li>Feature Flag Service (Local)</li> <li>HLD More</li> <li>In-Memory File System (Simplified)</li> <li>IoT Fleet Management (Edge)</li> <li>Job Scheduler (Cron + DAGs) with Retries and SLAs</li> <li>Limit Order Book &amp; Matching Engine</li> <li>Live Video Streaming with DVR</li> <li>Meeting Room Scheduler</li> <li>Metrics Logs and Alerts Platform</li> <li>Model Serving Platform</li> <li>Multi-camera RTSP to WebRTC Gateway</li> <li>Near-real-time Analytics Pipeline</li> <li>Notifications Hub</li> <li>Parking Lot</li> <li>Payment Gateway (Cards-UPI) with Idempotency</li> <li>Portfolio Risk Calculation</li> <li>Real-time Chat + Notifications</li> <li>Real-time Fraud Detection</li> <li>Real-time Market Data Fan-out</li> <li>Real-time P&amp;L and Exposure Dashboard</li> <li>Restaurant Delivery (Match Orders to Riders)</li> <li>Search Autocomplete with Typo Tolerance</li> <li>Short-video Feed (TikTok-style)</li> <li>Splitwise-like Expense Splitter</li> <li>Threshold Alerting Engine</li> <li>Ticketing (High Contention)</li> <li>Timeseries Database</li> <li>Trade Capture and Reconciliation</li> <li>URL Shortener (Core)</li> <li>URL Shortener (Global)</li> <li>Vector Search Service</li> </ul>"},{"location":"hld/overview/","title":"High-Level Design (HLD) Overview","text":"<p>This section provides a bird\u2019s-eye view of system architectures, their major components, interactions, and key design decisions.</p>"},{"location":"hld/overview/#what-is-high-level-design","title":"What is High-Level Design?","text":"<p>High-Level Design (HLD) covers: - System architecture and main components - Data flow between subsystems - Technology stack choices - Major APIs and integrations - Non-functional considerations (scalability, fault-tolerance, security, etc.)</p>"},{"location":"hld/overview/#contents","title":"Contents","text":"<ul> <li>Architecture</li> <li>DE Shaw</li> </ul>"},{"location":"hld/overview/#when-to-use-hld","title":"When to use HLD?","text":"<ul> <li>During initial project scoping</li> <li>For design reviews and presentations</li> <li>When comparing architecture alternatives</li> </ul> <p>Start with <code>architecture.md</code> for an example system!</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Backtesting%20Platform%20%28Distributed%29/","title":"Backtesting Platform (Distributed)","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Backtesting%20Platform%20%28Distributed%29/#1-problem-statement-scope","title":"1. Problem Statement &amp; Scope","text":"<p>Design a distributed platform for quantitative analysts (\"quants\") to test their trading strategies against massive historical market data sets. The platform must be scalable to run hundreds of simulations concurrently and ensure that every backtest is perfectly reproducible.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Backtesting%20Platform%20%28Distributed%29/#2-requirements","title":"2. Requirements","text":"<ul> <li>Functional Requirements:<ul> <li>Users can submit a backtest job with parameters: strategy code, date range, symbols, etc.</li> <li>The platform runs the strategy simulation over the specified historical data.</li> <li>The system must produce detailed results: performance metrics (Sharpe ratio, drawdown), a list of simulated trades, and logs.</li> <li>Reproducibility: A backtest run with the same code and data must produce the exact same result, bit for bit, every time.</li> </ul> </li> <li>Non-Functional Requirements:<ul> <li>Scalability: Handle 10+ TB of historical data and run hundreds of concurrent backtest jobs.</li> <li>Performance: A typical backtest of one strategy over one year of tick data should complete in a reasonable time (e.g., under 30 minutes).</li> <li>Isolation: Jobs from different users must be isolated in terms of resources and security.</li> <li>Cost-Effectiveness: Leverage cloud resources efficiently, potentially using cheaper spot instances for computation.</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Backtesting%20Platform%20%28Distributed%29/#3-capacity-estimation","title":"3. Capacity Estimation","text":"<ul> <li>Data Size: 10 TB of tick data. A single year for a single stock can be 50-100 GB.</li> <li>Concurrent Jobs: 200.</li> <li>Compute: If each job needs 4 CPU cores, we need <code>200 * 4 = 800</code> cores available.</li> <li>Data Access: A single job might need to read 100 GB of data. At 200 concurrent jobs, the peak read throughput from storage could be significant, necessitating a high-performance storage solution.</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Backtesting%20Platform%20%28Distributed%29/#4-high-level-architecture-diagram","title":"4. High-Level Architecture Diagram","text":"<p>Code snippet</p> <p>`graph TD     subgraph \"User Interface\"         A[Quant Analyst via UI/SDK] --&gt; B[Job API Service];     end</p> <pre><code>subgraph \"Control Plane\"\n    B --&gt; C[Job Scheduler];\n    C -- reads/writes --&gt; D[Metadata DB (Postgres)];\nend\n\nsubgraph \"Execution Plane (e.g., on Kubernetes)\"\n    C -- creates Pod --&gt; E{Backtest Runner Pod};\n    subgraph E\n        F[Containerized Strategy Code]\n    end\n    E --&gt; G[Data Access Layer];\nend\n\nsubgraph \"Data &amp; Storage\"\n    G --&gt; H[Object Storage (S3)];\n    H -- contains --&gt; I[Historical Data (Parquet)];\n    E -- writes logs/results --&gt; J[Results Store (S3)];\n    D -- stores --&gt; K[Job Metadata];\n    J -- triggers --&gt; L[Results Analysis Service]\nend`\n</code></pre>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Backtesting%20Platform%20%28Distributed%29/#5-data-schema-api-design","title":"5. Data Schema &amp; API Design","text":"<ul> <li>API:<ul> <li><code>POST /v1/jobs</code>: Submit a new backtest.<ul> <li>Body: <code>{\"strategy_image\": \"docker.io/repo/my_strategy:v1.2\", \"start_date\": \"...\", \"end_date\": \"...\", \"params\": {...}}</code></li> </ul> </li> <li><code>GET /v1/jobs/{job_id}</code>: Get the status and results of a job.</li> </ul> </li> <li>Data Models:<ul> <li>Metadata DB (Postgres):<ul> <li><code>jobs</code>: <code>job_id, user_id, status, docker_image_digest, submitted_at, results_path, ...</code></li> </ul> </li> <li>Storage (S3):<ul> <li>Historical Data: Stored in Parquet format, partitioned by date and symbol. <code>s3://market-data/ticks/symbol=AAPL/date=2025-08-14/data.parquet</code></li> <li>Results: Each job writes its output to a dedicated path. <code>s3://backtest-results/{job_id}/trades.csv</code>, <code>s3://backtest-results/{job_id}/metrics.json</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Backtesting%20Platform%20%28Distributed%29/#6-detailed-component-breakdown","title":"6. Detailed Component Breakdown","text":"<ul> <li>Job API Service: The entry point for users. It authenticates the request, validates the parameters, and creates a new job record in the Metadata DB with a <code>PENDING</code> status.</li> <li>Job Scheduler: The core of the control plane. It can be a custom service or built on a workflow orchestrator like Argo Workflows or a simple Kubernetes Operator. It polls the database for <code>PENDING</code> jobs and submits them to the compute cluster for execution.</li> <li>Containerized Runner: This is the key to reproducibility. The user's strategy code and all its dependencies (e.g., specific versions of pandas, numpy) are packaged into a Docker image. The scheduler runs this specific, immutable image. This eliminates \"it works on my machine\" problems and guarantees an identical execution environment every time.</li> <li>Data Access Layer: A library or sidecar container within the runner pod responsible for efficiently fetching data. It understands the partitioning scheme of the data in S3. To optimize performance, it can implement a local cache on the worker node's SSD, so if another job needs the same data, it can be read from the fast local disk instead of S3. The scheduler can be made \"cache-aware\" to try and place jobs on nodes that already have the data.</li> <li>Object Storage (S3 + Parquet):<ul> <li>S3: Provides a cheap, scalable, and durable way to store terabytes of data.</li> <li>Parquet: A columnar storage format. This is extremely efficient for backtesting, as a strategy often only needs a few columns (e.g., <code>price</code>, <code>volume</code>) out of many. Columnar storage allows the runner to read only the data it needs, drastically reducing I/O.</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Backtesting%20Platform%20%28Distributed%29/#7-end-to-end-flow-submitting-a-backtest","title":"7. End-to-End Flow (Submitting a Backtest)","text":"<p>Code snippet</p> <p>`sequenceDiagram     participant Analyst     participant JobAPI     participant Scheduler     participant Kubernetes     participant RunnerPod     participant S3</p> <pre><code>Analyst-&gt;&gt;JobAPI: POST /jobs (strategy_image, params)\nJobAPI-&gt;&gt;JobAPI: Create job record in DB (status=PENDING)\nJobAPI--&gt;&gt;Analyst: 202 Accepted (job_id)\n\nloop Scheduler Loop\n    Scheduler-&gt;&gt;Scheduler: Poll DB for PENDING jobs.\n    Scheduler-&gt;&gt;Kubernetes: Create Pod from docker_image for job_id.\nend\n\nKubernetes-&gt;&gt;RunnerPod: Start container.\nRunnerPod-&gt;&gt;S3: Stream relevant Parquet data partitions.\nNote over RunnerPod: Execute strategy logic tick-by-tick...\nRunnerPod-&gt;&gt;S3: Write trades.csv and metrics.json to results path.\nRunnerPod-&gt;&gt;RunnerPod: Update job status to SUCCESS in DB.`\n</code></pre>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Backtesting%20Platform%20%28Distributed%29/#8-bottlenecks-fault-tolerance-and-trade-offs","title":"8. Bottlenecks, Fault Tolerance, and Trade-offs","text":"<ul> <li>Bottleneck: Data I/O: Reading large volumes of data from S3 can be the slowest part.<ul> <li>Mitigation: The columnar Parquet format is the primary mitigation. The local SSD cache on worker nodes is another. Using a high-performance query engine like DuckDB within the runner can also speed up data processing.</li> </ul> </li> <li>Fault Tolerance:<ul> <li>Runner Failure: The runner is a container. If it fails (e.g., out of memory), Kubernetes will automatically restart it based on the defined policy. Since the job is deterministic, it will restart from the beginning and produce the same result. The system can be enhanced with checkpointing for very long jobs.</li> </ul> </li> <li>Key Trade-offs:<ul> <li>Object Store (S3) vs. Distributed File System (HDFS): S3 is easier to manage, more cost-effective, and offers infinite scalability (decoupled compute and storage). HDFS can offer better performance if data locality is critical but comes with significant operational overhead. For this use case, the flexibility of S3 is usually preferred.</li> <li>Cost (Spot vs. On-Demand Instances): Backtesting jobs are often batch workloads that can tolerate interruption. Using cheaper EC2 Spot Instances can reduce compute costs by up to 90%. The trade-off is that a job might be preempted and need to be restarted, increasing its total wall-clock time.</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/CDC%20Data%20Platform%20%28Operational%20DB%20-%20Lakehouse%29/","title":"CDC Data Platform (Operational DB -&gt; Lakehouse)","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/CDC%20Data%20Platform%20%28Operational%20DB%20-%20Lakehouse%29/#1-problem-statement-scope","title":"1. Problem Statement &amp; Scope","text":"<p>Design a real-time Change Data Capture (CDC) platform to stream all changes from operational databases (e.g., Postgres, MySQL) into a central lakehouse (e.g., Iceberg, Delta Lake). The system must support high throughput, schema evolution, and strong delivery guarantees.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/CDC%20Data%20Platform%20%28Operational%20DB%20-%20Lakehouse%29/#2-requirements","title":"2. Requirements","text":"<ul> <li>Functional Requirements:<ul> <li>Capture all inserts, updates, deletes from source DBs.</li> <li>Deliver changes to the lakehouse with at-least-once or exactly-once semantics.</li> <li>Handle schema evolution and DDL changes.</li> <li>Support multiple source DBs and tables.</li> </ul> </li> <li>Non-Functional Requirements:<ul> <li>Scalability: 100MB+/sec ingest, 1000+ tables.</li> <li>Reliability: No data loss, strong delivery guarantees.</li> <li>Extensibility: Add new sources/sinks easily.</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/CDC%20Data%20Platform%20%28Operational%20DB%20-%20Lakehouse%29/#3-capacity-estimation","title":"3. Capacity Estimation","text":"<ul> <li>Source DBs: 10, each 1TB, 100GB/day change rate.</li> <li>Change Rate: 10MB/sec per DB, 100MB/sec total.</li> <li>Lakehouse Storage: 10TB+.</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/CDC%20Data%20Platform%20%28Operational%20DB%20-%20Lakehouse%29/#4-high-level-architecture-diagram","title":"4. High-Level Architecture Diagram","text":"<p>Code snippet</p> <p><code>graph TD     A[Source DB (Postgres/MySQL)] --&gt; B[Debezium Connector];     B --&gt; C[Kafka (CDC Topics)];     C --&gt; D[Stream Processor (Flink/Spark)] ;     D --&gt; E[Lakehouse (Iceberg/Delta)];     D --&gt; F[Monitoring/Alerting];     C --&gt; G[Schema Registry];</code></p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/CDC%20Data%20Platform%20%28Operational%20DB%20-%20Lakehouse%29/#5-data-schema-api-design","title":"5. Data Schema &amp; API Design","text":"<ul> <li>CDC Event (Debezium): <code>{table, op (insert/update/delete), before, after, ts, schema_version}</code></li> <li>Kafka Topic: Partitioned by table, Avro/JSON encoding.</li> <li>Lakehouse Table: SCD2 (slowly changing dimension) or append-only, partitioned by date/table.</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/CDC%20Data%20Platform%20%28Operational%20DB%20-%20Lakehouse%29/#6-detailed-component-breakdown","title":"6. Detailed Component Breakdown","text":"<ul> <li>Debezium Connector: Reads DB logs, emits CDC events to Kafka. Handles schema changes.</li> <li>Kafka: Durable, scalable event bus. Buffers CDC events, supports replay.</li> <li>Stream Processor (Flink/Spark): Consumes CDC events, applies transformations, merges, and writes to lakehouse. Handles exactly-once via checkpointing.</li> <li>Lakehouse (Iceberg/Delta): Stores raw and processed data, supports ACID, schema evolution, and time travel.</li> <li>Schema Registry: Tracks schema versions for compatibility.</li> <li>Monitoring/Alerting: Tracks lag, failures, and data quality.</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/CDC%20Data%20Platform%20%28Operational%20DB%20-%20Lakehouse%29/#7-end-to-end-flow-cdc-ingest","title":"7. End-to-End Flow (CDC Ingest)","text":"<p>Code snippet</p> <p>`sequenceDiagram     participant SourceDB     participant Debezium     participant Kafka     participant Flink     participant Lakehouse</p> <pre><code>SourceDB-&gt;&gt;Debezium: Write to binlog/WAL\nDebezium-&gt;&gt;Kafka: Emit CDC event\nKafka-&gt;&gt;Flink: Stream event\nFlink-&gt;&gt;Lakehouse: Write/merge data\nFlink-&gt;&gt;Kafka: Commit offset (checkpoint)\nLakehouse--&gt;&gt;Flink: Ack\n</code></pre> <p>`</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/CDC%20Data%20Platform%20%28Operational%20DB%20-%20Lakehouse%29/#8-bottlenecks-fault-tolerance-and-trade-offs","title":"8. Bottlenecks, Fault Tolerance, and Trade-offs","text":"<ul> <li>Bottleneck: Stream Processor:<ul> <li>Scale out Flink/Spark for high ingest. Use partitioned topics.</li> </ul> </li> <li>Delivery Guarantees:<ul> <li>At-least-once is simpler, exactly-once requires checkpointing and idempotent writes.</li> </ul> </li> <li>Schema Evolution:<ul> <li>Use schema registry, support backward/forward compatibility.</li> </ul> </li> <li>Trade-offs:<ul> <li>Micro-batch merges are efficient but add latency. Row-by-row upserts are slower but more real-time.</li> </ul> </li> </ul> <p>This architecture is used by modern data platforms (e.g., Netflix, Uber) for real-time analytics and data lake ingestion.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Chat%20%281_1%20%2B%20Typing%20%2B%20Read%20Receipts%29/","title":"Chat (1_1 + Typing + Read Receipts)","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Chat%20%281_1%20%2B%20Typing%20%2B%20Read%20Receipts%29/#problem-statement","title":"Problem Statement","text":"<p>Design a real-time chat system supporting 1:1 messaging, typing indicators, and read receipts. The system must provide low-latency delivery, message persistence, and seamless experience across devices.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Chat%20%281_1%20%2B%20Typing%20%2B%20Read%20Receipts%29/#functional-requirements","title":"Functional Requirements","text":"<ul> <li>1:1 chat between users.</li> <li>Typing indicators (show when the other user is typing).</li> <li>Read receipts (show when a message is read).</li> <li>Message history and offline delivery.</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Chat%20%281_1%20%2B%20Typing%20%2B%20Read%20Receipts%29/#non-functional-requirements","title":"Non-Functional Requirements","text":"<ul> <li>Scalability: 10M+ users, 100k QPS.</li> <li>Low Latency: &lt;100ms message delivery.</li> <li>Reliability: No message loss.</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Chat%20%281_1%20%2B%20Typing%20%2B%20Read%20Receipts%29/#capacity-estimation","title":"Capacity Estimation","text":"<ul> <li>Users: 10M.</li> <li>Message Rate: 100k/sec peak.</li> <li>Storage: 1B messages/day, 1KB/message = 1TB/day.</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Chat%20%281_1%20%2B%20Typing%20%2B%20Read%20Receipts%29/#high-level-architecture-diagram","title":"High-Level Architecture Diagram","text":"<p>Code snippet</p> <p><code>graph TD     A[Client] --&gt; B[WebSocket Gateway];     B --&gt; C[Chat Service];     C --&gt; D[Message Store (NoSQL)];     C --&gt; E[Presence Service];     C --&gt; F[Typing Indicator Service];     C --&gt; G[Read Receipt Service];     D --&gt; H[Search Service];</code></p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Chat%20%281_1%20%2B%20Typing%20%2B%20Read%20Receipts%29/#data-schema-api-design","title":"Data Schema &amp; API Design","text":"<ul> <li>API:<ul> <li>WebSocket: <code>send_message</code>, <code>typing</code>, <code>read_receipt</code>, etc.</li> <li>REST: <code>GET /v1/messages</code>, <code>GET /v1/conversations</code>, etc.</li> </ul> </li> <li>Data Models:<ul> <li>Messages: <code>message_id, sender_id, receiver_id, content, ts, status</code></li> <li>Conversations: <code>conversation_id, participants, last_message_id, ...</code></li> <li>Presence: <code>user_id, status, last_seen</code></li> <li>Typing: <code>conversation_id, user_id, is_typing, ts</code></li> <li>ReadReceipt: <code>message_id, user_id, read_at</code></li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Chat%20%281_1%20%2B%20Typing%20%2B%20Read%20Receipts%29/#detailed-component-breakdown","title":"Detailed Component Breakdown","text":"<ul> <li>WebSocket Gateway: Maintains persistent connections, authenticates users, routes messages.</li> <li>Chat Service: Core logic for message delivery, persistence, and fan-out.</li> <li>Message Store (NoSQL): Stores chat history, supports search and offline delivery.</li> <li>Presence Service: Tracks user status (online/offline).</li> <li>Typing Indicator Service: Publishes typing events to the other user.</li> <li>Read Receipt Service: Tracks and notifies when messages are read.</li> <li>Search Service: Indexes messages for fast retrieval.</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Chat%20%281_1%20%2B%20Typing%20%2B%20Read%20Receipts%29/#end-to-end-flow-message-send-read-receipt","title":"End-to-End Flow (Message Send &amp; Read Receipt)","text":"<p>Code snippet</p> <p>`sequenceDiagram     participant UserA     participant Gateway     participant ChatSvc     participant MessageStore     participant TypingSvc     participant ReadReceiptSvc     participant UserB</p> <pre><code>UserA-&gt;&gt;Gateway: send_message\nGateway-&gt;&gt;ChatSvc: Forward message\nChatSvc-&gt;&gt;MessageStore: Persist message\nChatSvc-&gt;&gt;UserB: Deliver message\nUserB-&gt;&gt;Gateway: typing\nGateway-&gt;&gt;TypingSvc: Publish typing\nTypingSvc-&gt;&gt;UserA: Show typing\nUserB-&gt;&gt;Gateway: read_receipt\nGateway-&gt;&gt;ReadReceiptSvc: Record read\nReadReceiptSvc-&gt;&gt;UserA: Notify read\n</code></pre> <p>`</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Chat%20%281_1%20%2B%20Typing%20%2B%20Read%20Receipts%29/#bottlenecks-fault-tolerance-and-trade-offs","title":"Bottlenecks, Fault Tolerance, and Trade-offs","text":"<ul> <li>Bottleneck: WebSocket Gateway:<ul> <li>Horizontally scalable, stateless. Use sticky sessions or consistent hashing.</li> </ul> </li> <li>Message Store:<ul> <li>NoSQL DB for high write throughput. Partition by conversation_id.</li> </ul> </li> <li>Typing/Read Receipts:<ul> <li>Pub-sub for real-time updates. Eventual consistency is acceptable.</li> </ul> </li> <li>Trade-offs:<ul> <li>Eventual consistency for presence/typing/read receipts. Strong consistency for message delivery.</li> </ul> </li> </ul> <p>This design is used by WhatsApp, Messenger, and other chat apps for real-time 1:1 messaging.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Chat%20%281_1%20%2B%20Typing%20%2B%20Read%20Receipts%29/#chat-11-typing-read-receipts","title":"Chat (1:1 + Typing + Read Receipts)","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Chat%20%281_1%20%2B%20Typing%20%2B%20Read%20Receipts%29/#problem-statement_1","title":"Problem Statement","text":"<p>Design a simple chat service (no persistence required for LLD round). Support 1:1 chat, typing, and read receipts.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Chat%20%281_1%20%2B%20Typing%20%2B%20Read%20Receipts%29/#functional-requirements_1","title":"Functional Requirements","text":"<ul> <li>Send message</li> <li>Delivery receipt</li> <li>Read receipt</li> <li>Typing indicator</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Chat%20%281_1%20%2B%20Typing%20%2B%20Read%20Receipts%29/#core-concepts","title":"Core Concepts","text":"<ul> <li><code>User</code>, <code>Conversation</code>, <code>Message</code>, <code>ChatService</code></li> <li><code>PresenceService</code> (in-memory), <code>Delivery</code> (Observer)</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Chat%20%281_1%20%2B%20Typing%20%2B%20Read%20Receipts%29/#high-level-design","title":"High-Level Design","text":"<ul> <li>Conversations:<ul> <li>Each conversation between two users</li> <li>Messages sent, delivered, read</li> </ul> </li> <li>Presence:<ul> <li>Track online/offline status</li> <li>Typing indicator via in-memory pub/sub</li> </ul> </li> <li>Delivery:<ul> <li>Observer pattern for delivery/read receipts</li> </ul> </li> <li>Edge Cases:<ul> <li>Ordering per conversation</li> <li>Idempotent resend</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Chat%20%281_1%20%2B%20Typing%20%2B%20Read%20Receipts%29/#step-by-step-solution","title":"Step-by-Step Solution","text":"<ol> <li>Define classes: User, Conversation, Message, ChatService</li> <li>PresenceService: in-memory status</li> <li>Delivery: observer for receipts</li> <li>API: send, typing, read</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Chat%20%281_1%20%2B%20Typing%20%2B%20Read%20Receipts%29/#edge-cases","title":"Edge Cases","text":"<ul> <li>Out-of-order delivery</li> <li>Duplicate messages</li> <li>User disconnects</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Collaborative%20Document%20Editing%20%28Google-Docs-lite%29/","title":"Collaborative Document Editing (Google-Docs-lite) \u2014 Deep Dive","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Collaborative%20Document%20Editing%20%28Google-Docs-lite%29/#1-problem-statement-scope","title":"1. Problem Statement &amp; Scope","text":"<p>Design a Google Docs\u2013like system for real-time collaborative editing, supporting dozens of concurrent users, presence, versioning, and robust conflict resolution. The system must ensure low-latency convergence, offline support, and operational resilience.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Collaborative%20Document%20Editing%20%28Google-Docs-lite%29/#2-functional-non-functional-requirements","title":"2. Functional &amp; Non-Functional Requirements","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Collaborative%20Document%20Editing%20%28Google-Docs-lite%29/#functional-requirements","title":"Functional Requirements","text":"<ul> <li>Real-time multi-user editing with sub-second latency</li> <li>User presence and cursor/selection sharing</li> <li>Version history and undo/redo</li> <li>Conflict-free merging of concurrent edits</li> <li>Late joiners see latest state instantly</li> <li>Support for comments, suggestions, and permissions</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Collaborative%20Document%20Editing%20%28Google-Docs-lite%29/#non-functional-requirements","title":"Non-Functional Requirements","text":"<ul> <li>Scalability: 100+ concurrent editors per doc, 1M+ docs</li> <li>Reliability: No data loss, robust against network partitions</li> <li>Low Latency: p99 &lt; 200ms for edit propagation</li> <li>Offline Support: Edits sync when reconnected</li> <li>Security: Access control, audit logs</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Collaborative%20Document%20Editing%20%28Google-Docs-lite%29/#3-core-architecture-data-model","title":"3. Core Architecture &amp; Data Model","text":"<ul> <li>Editing Engine:<ul> <li>OT (Operational Transform): Server-centric, easier for centralized control</li> <li>CRDT (Conflict-free Replicated Data Type): Peer-to-peer/offline, eventual consistency</li> </ul> </li> <li>Doc Shard Service: Horizontally sharded doc servers for scalability</li> <li>Presence/Notification: PubSub for user presence, typing, and cursor updates</li> <li>Snapshot &amp; Compaction: Periodic snapshots for fast late join and recovery</li> <li>Storage:<ul> <li>Op Log: Append-only log of all edits</li> <li>Snapshots: Periodic full doc state</li> <li>Metadata: User, permissions, comments</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Collaborative%20Document%20Editing%20%28Google-Docs-lite%29/#4-high-level-architecture-diagram","title":"4. High-Level Architecture Diagram","text":"<pre><code>graph TD\n    Client --&gt;|Edits| OT_CRDT_Engine\n    OT_CRDT_Engine --&gt;|Transformed Ops| ShardService\n    ShardService --&gt;|Broadcast| PresenceService\n    ShardService --&gt;|Persist| Storage\n    PresenceService --&gt;|Presence| Client\n    Storage --&gt;|Snapshot| ShardService\n</code></pre>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Collaborative%20Document%20Editing%20%28Google-Docs-lite%29/#5-detailed-workflows","title":"5. Detailed Workflows","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Collaborative%20Document%20Editing%20%28Google-Docs-lite%29/#a-real-time-editing","title":"a) Real-time Editing","text":"<ol> <li>User types in client; edit sent to OT/CRDT engine</li> <li>Engine transforms/merges edit, assigns version</li> <li>Edit broadcast to all clients via ShardService</li> <li>Clients update local state, show remote cursors</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Collaborative%20Document%20Editing%20%28Google-Docs-lite%29/#b-late-joiner","title":"b) Late Joiner","text":"<ol> <li>New user connects to doc</li> <li>Receives latest snapshot + op log since snapshot</li> <li>Applies ops to reach current state</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Collaborative%20Document%20Editing%20%28Google-Docs-lite%29/#c-offline-editing","title":"c) Offline Editing","text":"<ol> <li>User edits offline; ops queued locally</li> <li>On reconnect, ops sent to server, merged via CRDT/OT</li> <li>Conflicts resolved automatically</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Collaborative%20Document%20Editing%20%28Google-Docs-lite%29/#d-versioning-undoredo","title":"d) Versioning &amp; Undo/Redo","text":"<ol> <li>All ops stored in log with user/timestamp</li> <li>Undo/redo traverses op log</li> <li>Version history allows rollback and diff</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Collaborative%20Document%20Editing%20%28Google-Docs-lite%29/#6-scaling-fault-tolerance-and-trade-offs","title":"6. Scaling, Fault Tolerance, and Trade-offs","text":"<ul> <li>Scaling:<ul> <li>Shard docs by docId for horizontal scaling</li> <li>Use distributed pubsub (e.g., Redis, Kafka) for presence and edit broadcast</li> </ul> </li> <li>Fault Tolerance:<ul> <li>Persist all ops and snapshots to durable storage</li> <li>Use leader election for shard failover</li> </ul> </li> <li>Trade-offs:<ul> <li>OT is simpler for server-centric, but CRDT is better for offline/P2P</li> <li>Snapshots speed up late join but increase storage</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Collaborative%20Document%20Editing%20%28Google-Docs-lite%29/#7-api-interface-design","title":"7. API &amp; Interface Design","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Collaborative%20Document%20Editing%20%28Google-Docs-lite%29/#client-apis","title":"Client APIs","text":"<ul> <li><code>POST /edit</code>: Submit edit op</li> <li><code>GET /snapshot</code>: Get latest doc state</li> <li><code>GET /presence</code>: Get current users/cursors</li> <li><code>POST /comment</code>: Add comment</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Collaborative%20Document%20Editing%20%28Google-Docs-lite%29/#admin-apis","title":"Admin APIs","text":"<ul> <li><code>GET /audit</code>: Get edit history</li> <li><code>POST /restore</code>: Restore to previous version</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Collaborative%20Document%20Editing%20%28Google-Docs-lite%29/#8-security-operational-considerations","title":"8. Security &amp; Operational Considerations","text":"<ul> <li>Security:<ul> <li>Per-doc/user access control</li> <li>All edits and comments logged for audit</li> </ul> </li> <li>Monitoring:<ul> <li>Real-time dashboards for doc activity, errors, and latency</li> </ul> </li> <li>Disaster Recovery:<ul> <li>Regular backups of op logs and snapshots</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Collaborative%20Document%20Editing%20%28Google-Docs-lite%29/#9-best-practices-industry-insights","title":"9. Best Practices &amp; Industry Insights","text":"<ul> <li>Use CRDT for offline-first, OT for centralized</li> <li>Always persist ops before broadcasting</li> <li>Use vector clocks or Lamport timestamps for ordering</li> <li>Snapshots every N ops for fast recovery</li> <li>Integrate with cloud storage for durability</li> <li>Design for graceful degradation (read-only mode on failure)</li> </ul> <p>This design is inspired by Google Docs, Etherpad, and Figma, and can be extended for rich media, plugins, and enterprise features.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Distributed%20Cache%20%28Multi-Region%29/","title":"Distributed Cache (Multi-Region) \u2014 Deep Dive","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Distributed%20Cache%20%28Multi-Region%29/#1-problem-statement-scope","title":"1. Problem Statement &amp; Scope","text":"<p>Design a highly available, low-latency, multi-region distributed cache to accelerate database reads and writes for global applications. The system must support strong or eventual consistency, explicit invalidation, seamless failover, and data locality for optimal performance.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Distributed%20Cache%20%28Multi-Region%29/#2-functional-non-functional-requirements","title":"2. Functional &amp; Non-Functional Requirements","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Distributed%20Cache%20%28Multi-Region%29/#functional-requirements","title":"Functional Requirements","text":"<ul> <li>Store key-value data with TTL and versioning</li> <li>Support read-through, write-through, and write-behind patterns</li> <li>Explicit cache invalidation (by key, pattern, or region)</li> <li>Multi-region deployments with data locality and failover</li> <li>Metrics and monitoring for cache hits/misses, latency, and invalidations</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Distributed%20Cache%20%28Multi-Region%29/#non-functional-requirements","title":"Non-Functional Requirements","text":"<ul> <li>Low Latency: &lt;10ms for local reads, &lt;50ms for cross-region</li> <li>High Availability: Survive region and node failures</li> <li>Consistency: Configurable (eventual/strong, per key or namespace)</li> <li>Scalability: 1M+ QPS, 10TB+ data, 5+ regions</li> <li>Security: Encrypted in transit and at rest, access control</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Distributed%20Cache%20%28Multi-Region%29/#3-capacity-scale-estimation","title":"3. Capacity &amp; Scale Estimation","text":"<ul> <li>Cache Size: 10TB total, 5 regions, 2TB/region</li> <li>QPS: 1M/sec global, 200k/sec/region</li> <li>Key Size: 64B avg, Value Size: 1KB avg</li> <li>Replication Lag: &lt;1s for eventual, &lt;100ms for strong</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Distributed%20Cache%20%28Multi-Region%29/#4-high-level-architecture","title":"4. High-Level Architecture","text":"<pre><code>graph TD\n    App1[App Server (Region 1)] --&gt; Cache1[Cache Cluster (Region 1)]\n    App2[App Server (Region 2)] --&gt; Cache2[Cache Cluster (Region 2)]\n    Cache1 &lt;--&gt; InvalidationBus[Global Invalidation Bus (Kafka)]\n    Cache2 &lt;--&gt; InvalidationBus\n    Cache1 --&gt; DB1[Primary DB (Region 1)]\n    Cache2 --&gt; DB2[DB Replica (Region 2)]\n    InvalidationBus --&gt; Cache1\n    InvalidationBus --&gt; Cache2\n</code></pre> <p>Components: - Regional Cache Cluster: Redis/Memcached/Custom, per region, sharded for scale - Global Invalidation Bus: Kafka/PubSub for propagating invalidations and updates - Primary DB + Replicas: Source of truth, cache misses/read-throughs go here - Consistency Controller: Ensures strong/eventual consistency as configured - Monitoring &amp; Metrics: Tracks hit/miss, latency, replication lag</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Distributed%20Cache%20%28Multi-Region%29/#5-data-model-api-design","title":"5. Data Model &amp; API Design","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Distributed%20Cache%20%28Multi-Region%29/#data-models","title":"Data Models","text":"<ul> <li>Cache Entry: {key, value, version, timestamp, ttl, region}</li> <li>Invalidation Event: {key/pattern, version, region, timestamp, type}</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Distributed%20Cache%20%28Multi-Region%29/#api-endpoints","title":"API Endpoints","text":"<ul> <li><code>GET /cache/{key}</code>: Get value</li> <li><code>SET /cache/{key}</code>: Set value</li> <li><code>DEL /cache/{key}</code>: Delete key</li> <li><code>INVALIDATE /cache/{pattern}</code>: Invalidate keys by pattern</li> <li><code>GET /metrics</code>: Get cache stats</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Distributed%20Cache%20%28Multi-Region%29/#6-detailed-component-breakdown","title":"6. Detailed Component Breakdown","text":"<ul> <li>Regional Cache Cluster:<ul> <li>Handles all local traffic for low latency</li> <li>Sharded for scale, replicated for HA</li> <li>Supports local and global invalidation</li> </ul> </li> <li>Global Invalidation Bus:<ul> <li>Propagates invalidation and update events to all regions</li> <li>Ensures cache coherence across the globe</li> </ul> </li> <li>Primary DB + Replicas:<ul> <li>Source of truth for all data</li> <li>Cache misses/read-throughs go here</li> </ul> </li> <li>Consistency Controller:<ul> <li>Configurable per key/namespace (eventual/strong)</li> <li>Uses distributed locks or consensus for strong consistency</li> </ul> </li> <li>Monitoring &amp; Metrics:<ul> <li>Real-time dashboards for hit/miss, latency, replication lag</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Distributed%20Cache%20%28Multi-Region%29/#7-end-to-end-flow-cache-readwriteinvalidate","title":"7. End-to-End Flow (Cache Read/Write/Invalidate)","text":"<pre><code>sequenceDiagram\n    participant App\n    participant Cache\n    participant DB\n    participant InvalidationBus\n\n    App-&gt;&gt;Cache: GET key\n    alt Hit\n        Cache--&gt;&gt;App: Return value\n    else Miss\n        Cache-&gt;&gt;DB: Fetch value\n        DB--&gt;&gt;Cache: Return value\n        Cache--&gt;&gt;App: Return value\n        Cache-&gt;&gt;Cache: SET key\n    end\n    App-&gt;&gt;Cache: SET/DEL key\n    Cache-&gt;&gt;InvalidationBus: Publish invalidation\n    InvalidationBus-&gt;&gt;Cache: Invalidate key in all regions\n</code></pre>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Distributed%20Cache%20%28Multi-Region%29/#8-scaling-fault-tolerance-and-trade-offs","title":"8. Scaling, Fault Tolerance, and Trade-offs","text":"<ul> <li>Scaling:<ul> <li>Shard cache clusters for scale</li> <li>Use async pub/sub for invalidation propagation</li> </ul> </li> <li>Fault Tolerance:<ul> <li>Multi-AZ deployment, failover nodes</li> <li>Each region operates independently; global bus ensures coherence</li> </ul> </li> <li>Trade-offs:<ul> <li>Eventual consistency is fast, but may serve stale data</li> <li>Strong consistency is slower, requires cross-region coordination</li> <li>Choose per use case: session tokens (strong), product catalog (eventual)</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Distributed%20Cache%20%28Multi-Region%29/#9-security-operational-considerations","title":"9. Security &amp; Operational Considerations","text":"<ul> <li>Security:<ul> <li>Encrypt data in transit (TLS) and at rest</li> <li>Access control for cache APIs</li> </ul> </li> <li>Monitoring:<ul> <li>Real-time dashboards for cache health, usage, and errors</li> </ul> </li> <li>Disaster Recovery:<ul> <li>Regular backups of cache metadata and config</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Distributed%20Cache%20%28Multi-Region%29/#10-best-practices-industry-insights","title":"10. Best Practices &amp; Industry Insights","text":"<ul> <li>Use versioning for all cache entries to avoid stale writes</li> <li>Prefer local reads, but always support global invalidation</li> <li>Use async propagation for scale, but allow strong consistency for critical data</li> <li>Integrate with application monitoring for end-to-end visibility</li> <li>Design for graceful degradation (read-through to DB on cache miss)</li> </ul> <p>This design is inspired by Netflix EVCache, AWS ElastiCache Global Datastore, and other global-scale caching systems, and can be extended for write-behind, near-cache, and edge caching.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Distributed%20ID%20Generator%20%28Snowflake-like%29/","title":"Distributed ID Generator (Snowflake-like)","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Distributed%20ID%20Generator%20%28Snowflake-like%29/#1-problem-statement-scope","title":"1. Problem Statement &amp; Scope","text":"<p>Design a distributed ID generator that produces unique, sortable 64-bit IDs across multiple data centers and workers, similar to Twitter Snowflake. The system must handle clock skew, sequence rollover, and be highly available.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Distributed%20ID%20Generator%20%28Snowflake-like%29/#2-requirements","title":"2. Requirements","text":"<ul> <li>Functional Requirements:<ul> <li>Generate unique 64-bit IDs: <code>timestamp | datacenter | worker | sequence</code>.</li> <li>IDs must be sortable by time.</li> <li>Handle clock skew, sequence rollover, and thread safety.</li> </ul> </li> <li>Non-Functional Requirements:<ul> <li>Low Latency: &lt;1ms per ID generation.</li> <li>High Availability: No duplicate IDs, even on failover.</li> <li>Scalability: 10k+ QPS per node, 1000+ nodes.</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Distributed%20ID%20Generator%20%28Snowflake-like%29/#3-capacity-estimation","title":"3. Capacity Estimation","text":"<ul> <li>Nodes: 1000 (workers across DCs).</li> <li>QPS: 10k/node = 10M QPS global.</li> <li>ID Space: 64 bits, 41b timestamp, 5b DC, 5b worker, 12b sequence.</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Distributed%20ID%20Generator%20%28Snowflake-like%29/#4-high-level-architecture-diagram","title":"4. High-Level Architecture Diagram","text":"<p>Code snippet</p> <p><code>graph TD     A[Client] --&gt; B[ID Generator Node];     B --&gt; C[Clock/Time Source];     B --&gt; D[Persistence (optional)];     B --&gt; E[Monitoring];     B --&gt; F[Cluster Coordination (optional)];</code></p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Distributed%20ID%20Generator%20%28Snowflake-like%29/#5-data-schema-api-design","title":"5. Data Schema &amp; API Design","text":"<ul> <li>API:<ul> <li><code>GET /v1/next_id</code>: Returns next unique ID.</li> </ul> </li> <li>ID Layout:<ul> <li>41 bits: timestamp (ms since custom epoch)</li> <li>5 bits: datacenter ID</li> <li>5 bits: worker ID</li> <li>12 bits: sequence (per ms)</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Distributed%20ID%20Generator%20%28Snowflake-like%29/#6-detailed-component-breakdown","title":"6. Detailed Component Breakdown","text":"<ul> <li>ID Generator Node: Implements the ID generation logic, maintains local state (last timestamp, sequence), and exposes API.</li> <li>Clock/Time Source: Uses system clock. If clock moves backward, node waits until safe.</li> <li>Persistence (optional): Stores last timestamp for crash recovery.</li> <li>Cluster Coordination (optional): Assigns unique worker/datacenter IDs, prevents collisions.</li> <li>Monitoring: Tracks QPS, errors, clock skew events.</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Distributed%20ID%20Generator%20%28Snowflake-like%29/#7-end-to-end-flow-id-generation","title":"7. End-to-End Flow (ID Generation)","text":"<p>Code snippet</p> <p>`sequenceDiagram     participant Client     participant IDGen     participant Clock     participant Persist</p> <pre><code>Client-&gt;&gt;IDGen: Request next_id\nIDGen-&gt;&gt;Clock: Get current timestamp\nalt Same ms as last\n    IDGen-&gt;&gt;IDGen: Increment sequence\n    alt Sequence overflow\n        IDGen-&gt;&gt;Clock: Wait for next ms\n    end\nelse Clock moved backward\n    IDGen-&gt;&gt;Clock: Wait until safe\nend\nIDGen-&gt;&gt;Persist: (Optional) Store last timestamp\nIDGen--&gt;&gt;Client: Return ID\n</code></pre> <p>`</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Distributed%20ID%20Generator%20%28Snowflake-like%29/#8-bottlenecks-fault-tolerance-and-trade-offs","title":"8. Bottlenecks, Fault Tolerance, and Trade-offs","text":"<ul> <li>Bottleneck: Sequence Overflow:<ul> <li>12 bits = 4096 IDs/ms/node. If exceeded, must wait for next ms.</li> </ul> </li> <li>Clock Skew:<ul> <li>If clock moves backward, node must wait. Use NTP and monotonic clocks.</li> </ul> </li> <li>Worker/DC ID Collisions:<ul> <li>Use static config or coordination service (e.g., Zookeeper) to assign unique IDs.</li> </ul> </li> <li>Persistence:<ul> <li>Optional for crash recovery. If not used, may generate duplicate IDs after crash.</li> </ul> </li> <li>Trade-offs:<ul> <li>Simpler design is stateless but risks duplicates on crash. Persistent design is safer but slower.</li> </ul> </li> </ul> <p>This design is used by Twitter, Instagram, and many distributed systems for unique, sortable ID generation.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/E-commerce%20Checkout/","title":"E-commerce Checkout","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/E-commerce%20Checkout/#1-problem-statement-scope","title":"1. Problem Statement &amp; Scope","text":"<p>Design a robust, reliable, and scalable checkout system for an e-commerce platform. The system must handle order creation, inventory reservation, payment processing, and confirmation, ensuring no overselling or double-charging, even under failures or retries.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/E-commerce%20Checkout/#2-requirements","title":"2. Requirements","text":"<ul> <li>Functional Requirements:<ul> <li>Create an order from a user's cart.</li> <li>Reserve inventory for each item.</li> <li>Process payment (credit card, wallet, etc.).</li> <li>Confirm order and notify user.</li> <li>Rollback all steps if any sub-step fails (distributed transaction).</li> </ul> </li> <li>Non-Functional Requirements:<ul> <li>Reliability: No double-charging, no overselling.</li> <li>Idempotency: Safe to retry any step.</li> <li>Scalability: Handle 10k+ checkouts/minute.</li> <li>Consistency: Strong consistency for inventory and payment.</li> <li>Observability: Trace each order's status.</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/E-commerce%20Checkout/#3-capacity-estimation","title":"3. Capacity Estimation","text":"<ul> <li>Peak Checkouts: 10k/minute (167/sec).</li> <li>Inventory Items/Order: Avg 3.</li> <li>Payment Failures: 1%.</li> <li>Storage: Orders table grows by 10M/year.</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/E-commerce%20Checkout/#4-high-level-architecture-diagram","title":"4. High-Level Architecture Diagram","text":"<p>Code snippet</p> <p><code>graph TD     A[User] --&gt; B[API Gateway];     B --&gt; C[Order Service (Saga Orchestrator)];     C --&gt; D[Inventory Service];     C --&gt; E[Payment Service];     C --&gt; F[Notification Service];     C --&gt; G[Outbox/Event Bus];     D --&gt; H[Inventory DB];     E --&gt; I[Payment Gateway];     F --&gt; J[Email/SMS];     G --&gt; K[Order Analytics];</code></p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/E-commerce%20Checkout/#5-data-schema-api-design","title":"5. Data Schema &amp; API Design","text":"<ul> <li>API:<ul> <li><code>POST /v1/checkout</code>: <code>{cart_id, payment_method, shipping_address, ...}</code></li> <li><code>GET /v1/orders/{order_id}</code>: Get order status.</li> </ul> </li> <li>Data Models:<ul> <li>Orders: <code>order_id, user_id, status, total, created_at, ...</code></li> <li>OrderItems: <code>order_id, item_id, qty, price</code></li> <li>Inventory: <code>item_id, available_qty</code></li> <li>Payments: <code>payment_id, order_id, status, amount, ...</code></li> <li>Idempotency Key: For safe retries.</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/E-commerce%20Checkout/#6-detailed-component-breakdown","title":"6. Detailed Component Breakdown","text":"<ul> <li>Order Service (Saga Orchestrator): Coordinates the distributed transaction. Starts the saga, tracks progress, and rolls back on failure.</li> <li>Inventory Service: Checks and reserves inventory. Supports compensation (release) on rollback.</li> <li>Payment Service: Processes payment. Supports refund on rollback.</li> <li>Notification Service: Sends order confirmation or failure notifications.</li> <li>Outbox/Event Bus: Ensures reliable event publishing for downstream consumers (analytics, fulfillment).</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/E-commerce%20Checkout/#7-end-to-end-flow-checkout-saga","title":"7. End-to-End Flow (Checkout Saga)","text":"<p>Code snippet</p> <p>`sequenceDiagram     participant User     participant API     participant OrderSvc     participant InventorySvc     participant PaymentSvc     participant NotificationSvc     participant Outbox</p> <pre><code>User-&gt;&gt;API: POST /checkout\nAPI-&gt;&gt;OrderSvc: Create order (PENDING)\nOrderSvc-&gt;&gt;InventorySvc: Reserve items\nInventorySvc--&gt;&gt;OrderSvc: Success/Fail\nOrderSvc-&gt;&gt;PaymentSvc: Charge payment\nPaymentSvc--&gt;&gt;OrderSvc: Success/Fail\nalt All succeed\n    OrderSvc-&gt;&gt;OrderSvc: Mark order CONFIRMED\n    OrderSvc-&gt;&gt;NotificationSvc: Send confirmation\n    OrderSvc-&gt;&gt;Outbox: Publish event\nelse Any fail\n    OrderSvc-&gt;&gt;InventorySvc: Release items (compensate)\n    OrderSvc-&gt;&gt;PaymentSvc: Refund (if needed)\n    OrderSvc-&gt;&gt;OrderSvc: Mark order FAILED\n    OrderSvc-&gt;&gt;NotificationSvc: Send failure\nend\n</code></pre> <p>`</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/E-commerce%20Checkout/#8-bottlenecks-fault-tolerance-and-trade-offs","title":"8. Bottlenecks, Fault Tolerance, and Trade-offs","text":"<ul> <li>Bottleneck: Inventory/Payment:<ul> <li>Both must be strongly consistent. Use row-level locks or atomic DB ops for inventory. Payment must be idempotent.</li> </ul> </li> <li>Saga Pattern:<ul> <li>Enables distributed rollback. Each step has a compensating action.</li> </ul> </li> <li>Outbox Pattern:<ul> <li>Ensures events are reliably published even if the service crashes after DB commit.</li> </ul> </li> <li>Trade-offs:<ul> <li>Strong consistency adds latency. Eventual consistency is possible for non-critical steps (e.g., notifications).</li> <li>Sagas are more complex than monolithic transactions but scale better and avoid distributed locks.</li> </ul> </li> </ul> <p>This design is used by leading e-commerce platforms to ensure reliability and scalability in the checkout process.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Elevator%20Controller%20%28N%20Elevators%29/","title":"Elevator Controller (N Elevators)","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Elevator%20Controller%20%28N%20Elevators%29/#problem-statement","title":"Problem Statement","text":"<p>Schedule N elevators to minimize wait time. Handle hall/cab calls, group control, and safety.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Elevator%20Controller%20%28N%20Elevators%29/#functional-requirements","title":"Functional Requirements","text":"<ul> <li>Handle hall &amp; cab calls</li> <li>States: IDLE, MOVING, DOOR_OPEN</li> <li>Group control, peak modes</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Elevator%20Controller%20%28N%20Elevators%29/#core-concepts","title":"Core Concepts","text":"<ul> <li><code>Elevator(id, currentFloor, direction, queue)</code> (State pattern)</li> <li><code>Scheduler.assign(call)</code> (Nearest Car / Look Algorithm)</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Elevator%20Controller%20%28N%20Elevators%29/#high-level-design","title":"High-Level Design","text":"<ul> <li>Elevator:<ul> <li>Each elevator tracks current floor, direction, and queue of stops</li> <li>State transitions: IDLE \u2194 MOVING \u2194 DOOR_OPEN</li> </ul> </li> <li>Scheduler:<ul> <li>Assigns calls to elevators (nearest car, look algorithm)</li> <li>Handles peak modes (morning/evening)</li> </ul> </li> <li>Safety:<ul> <li>Door interlocks, overload sensors</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Elevator%20Controller%20%28N%20Elevators%29/#step-by-step-solution","title":"Step-by-Step Solution","text":"<ol> <li>Elevator class: state, queue, move logic</li> <li>Scheduler: assign calls, optimize for wait time</li> <li>Safety: enforce interlocks</li> <li>Simulation: test with multiple elevators/calls</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Elevator%20Controller%20%28N%20Elevators%29/#edge-cases","title":"Edge Cases","text":"<ul> <li>Simultaneous calls</li> <li>Overload</li> <li>Emergency stop</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Feature%20Flag%20Platform%20%28Multi-tenant%29/","title":"Feature Flag Platform (Multi tenant)","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Feature%20Flag%20Platform%20%28Multi-tenant%29/#feature-flag-platform-multi-tenant","title":"Feature Flag Platform (Multi-tenant)","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Feature%20Flag%20Platform%20%28Multi-tenant%29/#1-problem-statement-requirements","title":"1. Problem Statement &amp; Requirements","text":"<p>Design a multi-tenant feature flag platform for dynamic config, rollouts, and experimentation at scale.</p> <p>Functional Requirements: - Per-environment and per-tenant flags - Percentage rollouts, segments, and targeting - SDKs for client/server integration - Audit logs and change history - Webhook and push/poll for config updates</p> <p>Non-Functional Requirements: - 100k QPS flag evaluations - SDK poll &lt; 60s - High availability, low-latency</p> <p>Assumptions: - Config changes are infrequent, reads are high QPS - CDN/edge cache for global low-latency</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Feature%20Flag%20Platform%20%28Multi-tenant%29/#2-high-level-architecture","title":"2. High-Level Architecture","text":"<p>Components: - Config Store: Stores flag definitions, segments, rules - Evaluator: Evaluates flag for user/context - SDKs: Client/server libraries for integration - CDN/Edge Cache: Distributes config globally - Webhook Service: Pushes invalidations to SDKs - Audit Log: Tracks all changes</p> <p>Architecture Diagram: <pre><code> [SDK] -&gt; [CDN/Cache] -&gt; [Evaluator] -&gt; [Config Store]\n                        |\n                        v\n                   [Webhook/Audit]\n</code></pre></p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Feature%20Flag%20Platform%20%28Multi-tenant%29/#3-data-model-evaluation-logic","title":"3. Data Model &amp; Evaluation Logic","text":"<ul> <li>Flag: { id, key, rules, rollout %, segments, ... }</li> <li>Segment: { id, criteria, users }</li> <li>Evaluation Request: { flag_key, user_id, context }</li> <li>Audit Entry: { flag_id, user, change, ts }</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Feature%20Flag%20Platform%20%28Multi-tenant%29/#4-key-workflows","title":"4. Key Workflows","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Feature%20Flag%20Platform%20%28Multi-tenant%29/#a-flag-evaluation","title":"a) Flag Evaluation","text":"<ol> <li>SDK requests flag for user/context</li> <li>CDN/edge cache serves config if fresh</li> <li>Evaluator applies rules, segments, rollout %</li> <li>Returns flag value to SDK</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Feature%20Flag%20Platform%20%28Multi-tenant%29/#b-config-update-invalidation","title":"b) Config Update &amp; Invalidation","text":"<ol> <li>Admin updates flag/segment</li> <li>Config store persists change, updates audit log</li> <li>Webhook service pushes invalidation to SDKs/CDN</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Feature%20Flag%20Platform%20%28Multi-tenant%29/#c-audit-metrics","title":"c) Audit &amp; Metrics","text":"<ol> <li>All changes logged for compliance</li> <li>Metrics collected for flag usage, rollout impact</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Feature%20Flag%20Platform%20%28Multi-tenant%29/#5-scaling-reliability","title":"5. Scaling &amp; Reliability","text":"<ul> <li>CDN/Edge Cache: Global low-latency config</li> <li>Stateless Evaluator: Scales horizontally</li> <li>Push/Poll: SDKs support both for updates</li> <li>Monitoring: Latency, error rates, cache hit</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Feature%20Flag%20Platform%20%28Multi-tenant%29/#6-trade-offs-alternatives","title":"6. Trade-offs &amp; Alternatives","text":"<ul> <li>Push vs Poll: Push is faster, poll is simpler</li> <li>Consistency vs Latency: Edge cache may serve stale config</li> <li>Auditability: All changes must be logged</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Feature%20Flag%20Platform%20%28Multi-tenant%29/#7-best-practices-extensions","title":"7. Best Practices &amp; Extensions","text":"<ul> <li>Use signed config for tamper-proofing</li> <li>Per-tenant isolation and RBAC</li> <li>Experimentation and A/B testing support</li> <li>Integrate with CI/CD for safe deploys</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Feature%20Flag%20Platform%20%28Multi-tenant%29/#8-example-pseudocode-flag-evaluation","title":"8. Example Pseudocode (Flag Evaluation)","text":"<pre><code>def evaluate_flag(flag, user, context):\n    for rule in flag.rules:\n        if rule.matches(user, context):\n            return rule.value\n    if random() &lt; flag.rollout_percent / 100:\n        return flag.on_value\n    return flag.off_value\n</code></pre>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Feature%20Flag%20Platform%20%28Multi-tenant%29/#9-references","title":"9. References","text":"<ul> <li>Feature Flags at Scale</li> <li>LaunchDarkly Architecture</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Feature%20Flag%20Service%20%28Local%29/","title":"Feature Flag Service (Local) \u2014 Deep Dive","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Feature%20Flag%20Service%20%28Local%29/#1-problem-statement-scope","title":"1. Problem Statement &amp; Scope","text":"<p>Design a robust, local-first feature flag service to enable/disable features for users, groups, or segments without redeploying code. The system must support fine-grained targeting, percentage rollouts, instant rollbacks, and low-latency evaluation in the app or SDK.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Feature%20Flag%20Service%20%28Local%29/#2-functional-non-functional-requirements","title":"2. Functional &amp; Non-Functional Requirements","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Feature%20Flag%20Service%20%28Local%29/#functional-requirements","title":"Functional Requirements","text":"<ul> <li>Create, update, delete feature flags</li> <li>Target flags by user, group, segment, or percentage rollout</li> <li>Evaluate flags in the app (SDK or API)</li> <li>Audit log for all flag changes</li> <li>Support for flag dependencies and prerequisites</li> <li>Admin UI for flag management and monitoring</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Feature%20Flag%20Service%20%28Local%29/#non-functional-requirements","title":"Non-Functional Requirements","text":"<ul> <li>Low Latency: &lt;5ms flag evaluation (critical path)</li> <li>Reliability: No flag loss, safe rollbacks, high availability</li> <li>Consistency: Eventual consistency for local cache, strong consistency for writes</li> <li>Security: Role-based access control for flag changes</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Feature%20Flag%20Service%20%28Local%29/#3-capacity-scale-estimation","title":"3. Capacity &amp; Scale Estimation","text":"<ul> <li>Flags: 10,000+</li> <li>Users: 1M+</li> <li>QPS: 10k/sec flag evaluations, 100/sec writes</li> <li>SDKs: 1000+ connected clients</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Feature%20Flag%20Service%20%28Local%29/#4-high-level-architecture","title":"4. High-Level Architecture","text":"<pre><code>graph TD\n    AdminUI --&gt;|CRUD| FeatureFlagService\n    FeatureFlagService --&gt;|Persist| FlagStoreDB\n    FeatureFlagService --&gt;|Push| Cache\n    FeatureFlagService --&gt;|Serve| SDKClient\n    SDKClient --&gt;|Evaluate| App\n    FeatureFlagService --&gt;|Audit| AuditLog\n</code></pre> <p>Components: - FeatureFlag Service: Central API for flag CRUD, targeting, and evaluation - Flag Store (DB): Durable storage (RDBMS, NoSQL) - Cache: In-memory cache (Redis, local SDK cache) for fast reads - SDK Client: Fetches, caches, and evaluates flags locally - Admin UI: For flag management, monitoring, and audit - Audit Log: Stores all flag changes for compliance</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Feature%20Flag%20Service%20%28Local%29/#5-data-model-api-design","title":"5. Data Model &amp; API Design","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Feature%20Flag%20Service%20%28Local%29/#data-models","title":"Data Models","text":"<ul> <li>Flag: {flag_id, name, enabled, targeting_rules, rollout_percentage, prerequisites, updated_at}</li> <li>TargetingRule: {rule_id, flag_id, user_id/group_id/segment, condition, value}</li> <li>AuditLog: {log_id, flag_id, action, user, timestamp, before, after}</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Feature%20Flag%20Service%20%28Local%29/#api-endpoints","title":"API Endpoints","text":"<ul> <li><code>POST /v1/flags</code>: Create flag</li> <li><code>GET /v1/flags/{flag_id}</code>: Get flag</li> <li><code>PUT /v1/flags/{flag_id}</code>: Update flag</li> <li><code>DELETE /v1/flags/{flag_id}</code>: Delete flag</li> <li><code>GET /v1/flags</code>: List all flags</li> <li><code>GET /v1/audit</code>: Get audit log</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Feature%20Flag%20Service%20%28Local%29/#6-detailed-component-breakdown","title":"6. Detailed Component Breakdown","text":"<ul> <li>FeatureFlag Service:<ul> <li>CRUD for flags, manages targeting rules, exposes API for SDKs</li> <li>Pushes updates to SDKs via WebSocket or polling</li> <li>Handles flag dependencies and prerequisites</li> </ul> </li> <li>Flag Store (DB):<ul> <li>Persistent storage for flags, rules, and audit logs</li> <li>Supports versioning for safe rollbacks</li> </ul> </li> <li>SDK Client:<ul> <li>Fetches and caches flags locally</li> <li>Evaluates flags for user/group/segment</li> <li>Supports background refresh and instant update via push</li> </ul> </li> <li>Cache:<ul> <li>In-memory cache for fast evaluation, supports TTL and refresh</li> <li>Local SDK cache for ultra-low latency</li> </ul> </li> <li>Admin UI:<ul> <li>For flag management, monitoring, and audit</li> <li>Role-based access control</li> </ul> </li> <li>Audit Log:<ul> <li>Stores all flag changes, who made them, and when</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Feature%20Flag%20Service%20%28Local%29/#7-end-to-end-flow-flag-evaluation","title":"7. End-to-End Flow (Flag Evaluation)","text":"<pre><code>sequenceDiagram\n    participant Admin\n    participant FlagSvc\n    participant DB\n    participant SDK\n    participant App\n\n    Admin-&gt;&gt;FlagSvc: Create/Update flag\n    FlagSvc-&gt;&gt;DB: Persist flag\n    FlagSvc-&gt;&gt;AuditLog: Log change\n    SDK-&gt;&gt;FlagSvc: Fetch flags\n    FlagSvc--&gt;&gt;SDK: Return flags\n    SDK-&gt;&gt;App: Evaluate flag for user\n    App--&gt;&gt;SDK: Use feature\n</code></pre>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Feature%20Flag%20Service%20%28Local%29/#8-scaling-fault-tolerance-and-trade-offs","title":"8. Scaling, Fault Tolerance, and Trade-offs","text":"<ul> <li>Scaling:<ul> <li>Use sharded DB and distributed cache for high QPS</li> <li>Push updates to SDKs for instant propagation</li> </ul> </li> <li>Fault Tolerance:<ul> <li>Durable writes, multi-AZ deployment</li> <li>SDKs fall back to last known good config if service is down</li> </ul> </li> <li>Trade-offs:<ul> <li>Local cache is fast but may be stale; push updates to minimize staleness</li> <li>Centralized API is always fresh but higher latency</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Feature%20Flag%20Service%20%28Local%29/#9-security-operational-considerations","title":"9. Security &amp; Operational Considerations","text":"<ul> <li>Security:<ul> <li>Role-based access for flag changes</li> <li>All changes logged for compliance</li> </ul> </li> <li>Monitoring:<ul> <li>Real-time dashboards for flag usage, errors, and latency</li> </ul> </li> <li>Disaster Recovery:<ul> <li>Regular DB and audit log backups</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Feature%20Flag%20Service%20%28Local%29/#10-best-practices-industry-insights","title":"10. Best Practices &amp; Industry Insights","text":"<ul> <li>Use versioning for all flag changes to enable instant rollback</li> <li>Push updates to SDKs for near real-time propagation</li> <li>Use local cache for evaluation, but always support refresh</li> <li>Integrate with CI/CD for feature flag-driven deployments</li> <li>Design for safe default (fail closed or open as appropriate)</li> </ul> <p>This design is inspired by LaunchDarkly, Unleash, and other industry leaders, and can be extended for experimentation, A/B testing, and progressive delivery.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/HLD%20More/","title":"HLD More","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/HLD%20More/#high-level-design-expansions","title":"High-Level Design Expansions","text":"<p>This document contains detailed HLDs for selected systems from the main list. See the main README or other files for more.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/How%20to%20Approach/","title":"How to Approach a System Design Interview","text":"<p>This guide provides a repeatable, industry-grade script for tackling any system design interview. Use it to structure your 45\u201360 minute discussion and demonstrate both depth and breadth in your thinking.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/How%20to%20Approach/#1-lock-the-scope-clarify-requirements","title":"1. Lock the Scope (Clarify Requirements)","text":"<ul> <li>Ask clarifying questions: What is the core use case? What is out of scope? Who are the users? What are the must-have vs. nice-to-have features?</li> <li>Write down requirements: Separate functional (what the system does) and non-functional (scale, latency, availability, etc.).</li> <li>Confirm with interviewer: \"Just to confirm, for this session, we are focusing on X, Y, and Z, and not A or B. Is that correct?\"</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/How%20to%20Approach/#2-capacity-planning-back-of-the-envelope-estimation","title":"2. Capacity Planning (Back-of-the-Envelope Estimation)","text":"<ul> <li>Estimate scale: Users, QPS, data size, growth rate, peak vs. average load.</li> <li>Do quick math: E.g., \"If we expect 10M users, and each generates 100 requests/day, that's ~115 QPS.\"</li> <li>Document assumptions: State them clearly so you can adjust if the interviewer pushes back.</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/How%20to%20Approach/#3-api-data-model-design","title":"3. API &amp; Data Model Design","text":"<ul> <li>Define core APIs: REST/gRPC endpoints, request/response schemas, error handling, idempotency.</li> <li>Sketch data models: Tables, indexes, key fields, relationships. Consider partitioning and sharding keys.</li> <li>Discuss trade-offs: E.g., SQL vs. NoSQL, denormalization, consistency needs.</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/How%20to%20Approach/#4-high-level-architecture-boxes-arrows","title":"4. High-Level Architecture (Boxes &amp; Arrows)","text":"<ul> <li>Draw the big picture: Major components (clients, API gateway, services, DBs, caches, queues, etc.).</li> <li>Show data flow: How does a request travel through the system?</li> <li>Call out key patterns: E.g., load balancers, CDN, microservices, event-driven, etc.</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/How%20to%20Approach/#5-hot-path-deep-dive","title":"5. Hot Path Deep Dive","text":"<ul> <li>Pick a critical flow: E.g., \"Let's walk through a user posting a message.\"</li> <li>Sequence diagram: Step-by-step, from client to DB and back.</li> <li>Discuss latency, consistency, and failure points at each step.</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/How%20to%20Approach/#6-failure-consistency","title":"6. Failure &amp; Consistency","text":"<ul> <li>Identify failure modes: What if a DB is down? What if a message is lost?</li> <li>Mitigations: Retries, timeouts, circuit breakers, replication, backups.</li> <li>Consistency model: Strong, eventual, read-your-writes, etc. How do you guarantee it?</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/How%20to%20Approach/#7-bottlenecks-mitigations","title":"7. Bottlenecks &amp; Mitigations","text":"<ul> <li>Find the limits: What will break first as you scale? (DB, cache, network, etc.)</li> <li>Mitigation strategies: Caching, sharding, partitioning, async processing, rate limiting.</li> <li>Trade-offs: Simplicity vs. scalability, cost vs. performance.</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/How%20to%20Approach/#8-evolution-future-improvements","title":"8. Evolution (Future Improvements)","text":"<ul> <li>What would you do next? E.g., \"If we need to support 10x more users, I'd add X.\"</li> <li>Discuss extensibility: How would you add new features or support new use cases?</li> <li>Tech debt: What shortcuts did you take, and how would you address them later?</li> </ul> <p>Tips: - Always state your assumptions. - Use diagrams liberally (sequence, architecture, data model). - Prioritize clarity and structure over covering every possible detail. - If stuck, narrate your thought process and ask for hints.</p> <p>Example: See the main README or HLDs in this repo for detailed, step-by-step examples following this script.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/In-Memory%20File%20System%20%28Simplified%29/","title":"In-Memory File System (Simplified)","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/In-Memory%20File%20System%20%28Simplified%29/#1-problem-statement-scope","title":"1. Problem Statement &amp; Scope","text":"<p>Design an in-memory file system supporting mkdir, ls, create, read, write, move, and delete operations. The system should mimic a real file system's API and structure, with fast, thread-safe operations and extensibility for future features (permissions, journaling).</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/In-Memory%20File%20System%20%28Simplified%29/#2-requirements","title":"2. Requirements","text":"<ul> <li>Functional Requirements:<ul> <li>Create/delete directories and files.</li> <li>List directory contents (ls).</li> <li>Read/write file data.</li> <li>Move/rename files and directories.</li> <li>Path resolution (absolute/relative).</li> </ul> </li> <li>Non-Functional Requirements:<ul> <li>Low Latency: All operations in-memory, &lt;1ms.</li> <li>Thread Safety: Support concurrent access.</li> <li>Extensibility: Permissions, journaling (future).</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/In-Memory%20File%20System%20%28Simplified%29/#3-capacity-estimation","title":"3. Capacity Estimation","text":"<ul> <li>Files/Dirs: 1M nodes.</li> <li>File Size: Up to 10MB/file.</li> <li>RAM: 10GB+ for large trees.</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/In-Memory%20File%20System%20%28Simplified%29/#4-high-level-architecture-diagram","title":"4. High-Level Architecture Diagram","text":"<p>Code snippet</p> <p><code>graph TD     A[User/API] --&gt; B[FileSystem];     B --&gt; C[Path Resolver];     B --&gt; D[Root Directory];     D --&gt; E[Directory/File Nodes];     B --&gt; F[Lock Manager];     B --&gt; G[Future: Journal/Log];</code></p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/In-Memory%20File%20System%20%28Simplified%29/#5-data-schema-api-design","title":"5. Data Schema &amp; API Design","text":"<ul> <li>API:<ul> <li><code>mkdir(path)</code></li> <li><code>ls(path)</code></li> <li><code>create(path, data)</code></li> <li><code>read(path)</code></li> <li><code>write(path, data)</code></li> <li><code>move(src, dst)</code></li> <li><code>delete(path)</code></li> </ul> </li> <li>Data Models:<ul> <li>Node: <code>name, type (file/dir), parent, metadata</code></li> <li>File: <code>name, data, size, created_at, updated_at</code></li> <li>Directory: <code>name, children (map)</code></li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/In-Memory%20File%20System%20%28Simplified%29/#6-detailed-component-breakdown","title":"6. Detailed Component Breakdown","text":"<ul> <li>FileSystem: Main API, manages root, path resolution, and delegates to nodes.</li> <li>Path Resolver: Parses and resolves absolute/relative paths.</li> <li>Directory Node: Holds children (files/dirs) in a map for fast lookup.</li> <li>File Node: Stores file data and metadata.</li> <li>Lock Manager: Ensures thread safety for concurrent ops.</li> <li>Journal/Log (Future): For durability and crash recovery.</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/In-Memory%20File%20System%20%28Simplified%29/#7-end-to-end-flow-file-create-move","title":"7. End-to-End Flow (File Create &amp; Move)","text":"<p>Code snippet</p> <p>`sequenceDiagram     participant User     participant FS     participant PathRes     participant Dir     participant File</p> <pre><code>User-&gt;&gt;FS: create(/foo/bar.txt, data)\nFS-&gt;&gt;PathRes: Resolve /foo\nPathRes--&gt;&gt;FS: Directory node\nFS-&gt;&gt;Dir: Add File node\nDir-&gt;&gt;File: Store data\nUser-&gt;&gt;FS: move(/foo/bar.txt, /baz/bar.txt)\nFS-&gt;&gt;PathRes: Resolve /foo/bar.txt, /baz\nPathRes--&gt;&gt;FS: Source file, dest dir\nFS-&gt;&gt;Dir: Remove from /foo, add to /baz\n</code></pre> <p>`</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/In-Memory%20File%20System%20%28Simplified%29/#8-bottlenecks-fault-tolerance-and-trade-offs","title":"8. Bottlenecks, Fault Tolerance, and Trade-offs","text":"<ul> <li>Bottleneck: Path Resolution:<ul> <li>Use trie/map for fast lookup. Cache resolved paths.</li> </ul> </li> <li>Thread Safety:<ul> <li>Use fine-grained locks or lock-free structures for concurrency.</li> </ul> </li> <li>Durability:<ul> <li>In-memory only; add journaling for persistence.</li> </ul> </li> <li>Trade-offs:<ul> <li>In-memory is fast but volatile. Adding journaling increases durability but adds latency.</li> </ul> </li> </ul> <p>This design is used in interview questions and as a basis for real file system implementations.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/IoT%20Fleet%20Management%20%28Edge%29/","title":"IoT Fleet Management (Devices at Edge)","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/IoT%20Fleet%20Management%20%28Edge%29/#requirements","title":"Requirements","text":"<ul> <li>100k\u20131M devices</li> <li>Secure provisioning</li> <li>OTA updates</li> <li>Telemetry</li> <li>Commands</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/IoT%20Fleet%20Management%20%28Edge%29/#scale","title":"Scale","text":"<ul> <li>10\u201350k msgs/s</li> <li>Intermittent connectivity</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/IoT%20Fleet%20Management%20%28Edge%29/#core-architecture","title":"Core Architecture","text":"<ul> <li>Device registry (PKI)</li> <li>MQTT broker</li> <li>Shadow/state service</li> <li>OTA distribution</li> <li>Rules engine</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/IoT%20Fleet%20Management%20%28Edge%29/#storage","title":"Storage","text":"<ul> <li>Time-series DB for telemetry</li> <li>Object store for firmware</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/IoT%20Fleet%20Management%20%28Edge%29/#flow","title":"Flow","text":"<ul> <li>Connect \u2192 authenticate \u2192 publish telemetry \u2192 rules \u2192 act/store; OTA staged rollout</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/IoT%20Fleet%20Management%20%28Edge%29/#trade-offs","title":"Trade-offs","text":"<ul> <li>Online/offline state reconciliation</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/IoT%20Fleet%20Management%20%28Edge%29/#diagram","title":"Diagram","text":"<pre><code>[Device] -&gt; [MQTT Broker] -&gt; [Shadow Service] -&gt; [Rules Engine] -&gt; [OTA]\n</code></pre>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/IoT%20Fleet%20Management%20%28Edge%29/#notes","title":"Notes","text":"<ul> <li>Use PKI for secure provisioning</li> <li>OTA staged rollout for reliability</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/IoT%20Fleet%20Management/","title":"IoT Fleet Management","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/IoT%20Fleet%20Management/#1-problem-statement-scope","title":"1. Problem Statement &amp; Scope","text":"<p>Design a cloud-native platform to manage a large fleet of IoT devices. The system must support secure onboarding, high-volume telemetry ingestion, remote control, device shadowing, and over-the-air (OTA) firmware updates, with high reliability and scalability.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/IoT%20Fleet%20Management/#2-requirements","title":"2. Requirements","text":"<ul> <li>Functional Requirements:<ul> <li>Secure device onboarding and authentication.</li> <li>Ingest and store high-frequency telemetry from devices.</li> <li>Remote command/control (e.g., reboot, config update).</li> <li>Device shadow (digital twin) for state sync.</li> <li>OTA firmware updates to devices.</li> </ul> </li> <li>Non-Functional Requirements:<ul> <li>Scalability: 1M+ devices, 10k+ messages/sec.</li> <li>Reliability: No data loss, strong delivery guarantees.</li> <li>Security: TLS, mutual auth, role-based access.</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/IoT%20Fleet%20Management/#3-capacity-estimation","title":"3. Capacity Estimation","text":"<ul> <li>Devices: 1M.</li> <li>Telemetry Rate: 1 msg/sec/device = 1M/sec.</li> <li>Storage: 1KB/msg, 1TB/day.</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/IoT%20Fleet%20Management/#4-high-level-architecture-diagram","title":"4. High-Level Architecture Diagram","text":"<p>Code snippet</p> <p><code>graph TD     A[Device] --&gt; B[MQTT Broker Cluster];     B --&gt; C[Device Registry];     B --&gt; D[Device Shadow Service];     B --&gt; E[Rules Engine];     E --&gt; F[Time-series DB];     E --&gt; G[OTA Update Service];     D --&gt; H[Shadow DB];     G --&gt; I[Firmware Store];     C --&gt; J[User Portal/API];</code></p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/IoT%20Fleet%20Management/#5-data-schema-api-design","title":"5. Data Schema &amp; API Design","text":"<ul> <li>API:<ul> <li><code>POST /v1/devices</code>: Register device.</li> <li><code>POST /v1/devices/{id}/command</code>: Send command.</li> <li><code>POST /v1/ota/deployments</code>: Deploy firmware.</li> </ul> </li> <li>Data Models:<ul> <li>Device Registry: <code>device_id, cert, status, metadata</code></li> <li>Device Shadow: <code>device_id, reported, desired, last_sync</code></li> <li>Telemetry: <code>device_id, ts, payload</code></li> <li>OTA Deployment: <code>deployment_id, firmware_url, status</code></li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/IoT%20Fleet%20Management/#6-detailed-component-breakdown","title":"6. Detailed Component Breakdown","text":"<ul> <li>MQTT Broker Cluster: Handles device connections, message routing, and QoS.</li> <li>Device Registry: Stores device identities, certificates, and metadata.</li> <li>Device Shadow Service: Maintains digital twin for each device, syncs state.</li> <li>Rules Engine: Processes telemetry, triggers alerts/actions.</li> <li>Time-series DB: Stores telemetry for analytics and monitoring.</li> <li>OTA Update Service: Manages firmware deployments, tracks status.</li> <li>Firmware Store: Stores firmware binaries.</li> <li>User Portal/API: For device management and monitoring.</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/IoT%20Fleet%20Management/#7-end-to-end-flow-telemetry-ingest-ota-update","title":"7. End-to-End Flow (Telemetry Ingest &amp; OTA Update)","text":"<p>Code snippet</p> <p>`sequenceDiagram     participant Device     participant MQTT     participant Registry     participant Shadow     participant Rules     participant TSDB     participant OTA     participant Firmware</p> <pre><code>Device-&gt;&gt;MQTT: Connect &amp; authenticate\nMQTT-&gt;&gt;Registry: Validate device\nDevice-&gt;&gt;MQTT: Publish telemetry\nMQTT-&gt;&gt;Rules: Route message\nRules-&gt;&gt;TSDB: Store telemetry\nUser-&gt;&gt;OTA: Deploy firmware\nOTA-&gt;&gt;Firmware: Fetch binary\nOTA-&gt;&gt;MQTT: Notify device\nDevice-&gt;&gt;MQTT: Download &amp; update\nMQTT-&gt;&gt;OTA: Report status\n</code></pre> <p>`</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/IoT%20Fleet%20Management/#8-bottlenecks-fault-tolerance-and-trade-offs","title":"8. Bottlenecks, Fault Tolerance, and Trade-offs","text":"<ul> <li>Bottleneck: MQTT Broker:<ul> <li>Use clustering, horizontal scaling. Partition by device_id.</li> </ul> </li> <li>Telemetry Storage:<ul> <li>Time-series DB optimized for high ingest.</li> </ul> </li> <li>OTA Updates:<ul> <li>Staged rollout, retries for reliability.</li> </ul> </li> <li>Trade-offs:<ul> <li>MQTT is efficient for IoT, but HTTP is simpler for some use cases.</li> <li>Device shadow enables offline sync but adds complexity.</li> </ul> </li> </ul> <p>This design is used by AWS IoT, Azure IoT Hub, and other large-scale IoT platforms.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Job%20Scheduler%20%28Cron%20%2B%20DAGs%29%20with%20Retries%20and%20SLAs/","title":"Job Scheduler (Cron + DAGs) with Retries &amp; SLAs \u2014 Deep Dive","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Job%20Scheduler%20%28Cron%20%2B%20DAGs%29%20with%20Retries%20and%20SLAs/#1-problem-statement-scope","title":"1. Problem Statement &amp; Scope","text":"<p>Design a scalable, reliable job scheduler supporting cron jobs, dependency DAGs, retries, SLAs, and backfills. The system must orchestrate complex workflows, ensure reliability, and provide observability for operations teams.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Job%20Scheduler%20%28Cron%20%2B%20DAGs%29%20with%20Retries%20and%20SLAs/#2-functional-non-functional-requirements","title":"2. Functional &amp; Non-Functional Requirements","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Job%20Scheduler%20%28Cron%20%2B%20DAGs%29%20with%20Retries%20and%20SLAs/#functional-requirements","title":"Functional Requirements","text":"<ul> <li>Schedule jobs via cron or dependency DAGs</li> <li>Support retries, backoff, and max attempts</li> <li>SLA monitoring and alerting for missed deadlines</li> <li>Backfill for missed or failed jobs</li> <li>Job artifact and log storage</li> <li>Manual and API-triggered runs</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Job%20Scheduler%20%28Cron%20%2B%20DAGs%29%20with%20Retries%20and%20SLAs/#non-functional-requirements","title":"Non-Functional Requirements","text":"<ul> <li>Scalability: 100k+ jobs/day, 10k+ concurrent</li> <li>Reliability: No job loss, at-least-once execution</li> <li>Observability: Real-time status, logs, and metrics</li> <li>Extensibility: Pluggable executors, custom hooks</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Job%20Scheduler%20%28Cron%20%2B%20DAGs%29%20with%20Retries%20and%20SLAs/#3-core-architecture-data-model","title":"3. Core Architecture &amp; Data Model","text":"<ul> <li>Scheduler Service: Central brain, plans DAGs, enqueues jobs</li> <li>DAG State Store: Tracks job dependencies, state, and progress</li> <li>Executor Pool: Workers that run jobs, report status</li> <li>Artifact Store: Stores logs, outputs, and artifacts (S3, GCS)</li> <li>SLA Monitor: Tracks deadlines, triggers alerts</li> <li>Metadata DB: Stores job definitions, runs, and history</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Job%20Scheduler%20%28Cron%20%2B%20DAGs%29%20with%20Retries%20and%20SLAs/#4-high-level-architecture-diagram","title":"4. High-Level Architecture Diagram","text":"<pre><code>graph TD\n    Scheduler --&gt; DAGState\n    DAGState --&gt; ExecutorPool\n    ExecutorPool --&gt; ArtifactStore\n    ExecutorPool --&gt; SLA_Monitor\n    Scheduler --&gt; MetadataDB\n    SLA_Monitor --&gt; Alerting\n</code></pre>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Job%20Scheduler%20%28Cron%20%2B%20DAGs%29%20with%20Retries%20and%20SLAs/#5-detailed-workflows","title":"5. Detailed Workflows","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Job%20Scheduler%20%28Cron%20%2B%20DAGs%29%20with%20Retries%20and%20SLAs/#a-job-scheduling-execution","title":"a) Job Scheduling &amp; Execution","text":"<ol> <li>User defines job (cron or DAG) via API/UI</li> <li>Scheduler plans DAG, resolves dependencies</li> <li>Runnable jobs enqueued to Executor Pool</li> <li>Executors pick up jobs, run, and report status</li> <li>On failure, retry/backoff logic applied</li> <li>Artifacts/logs uploaded to store</li> <li>SLA Monitor checks deadlines, triggers alerts if missed</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Job%20Scheduler%20%28Cron%20%2B%20DAGs%29%20with%20Retries%20and%20SLAs/#b-backfill-manual-runs","title":"b) Backfill &amp; Manual Runs","text":"<ol> <li>User triggers backfill for missed/failed jobs</li> <li>Scheduler re-plans DAG, enqueues jobs as needed</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Job%20Scheduler%20%28Cron%20%2B%20DAGs%29%20with%20Retries%20and%20SLAs/#c-sla-monitoring-alerting","title":"c) SLA Monitoring &amp; Alerting","text":"<ol> <li>SLA Monitor tracks job deadlines</li> <li>If job exceeds SLA, alert sent to ops/on-call</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Job%20Scheduler%20%28Cron%20%2B%20DAGs%29%20with%20Retries%20and%20SLAs/#6-scaling-fault-tolerance-and-trade-offs","title":"6. Scaling, Fault Tolerance, and Trade-offs","text":"<ul> <li>Scaling:<ul> <li>Shard executor pool for scale</li> <li>Use distributed queue for job dispatch</li> </ul> </li> <li>Fault Tolerance:<ul> <li>Persist all job state to DB</li> <li>Executors heartbeat to detect failures</li> <li>At-least-once execution with idempotent jobs</li> </ul> </li> <li>Trade-offs:<ul> <li>Central queue is simple but can bottleneck; per-executor queues scale better</li> <li>Fairness vs throughput: prioritize critical jobs or maximize throughput</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Job%20Scheduler%20%28Cron%20%2B%20DAGs%29%20with%20Retries%20and%20SLAs/#7-api-interface-design","title":"7. API &amp; Interface Design","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Job%20Scheduler%20%28Cron%20%2B%20DAGs%29%20with%20Retries%20and%20SLAs/#useradmin-apis","title":"User/Admin APIs","text":"<ul> <li><code>POST /jobs</code>: Create job</li> <li><code>POST /runs</code>: Trigger run/backfill</li> <li><code>GET /jobs/{id}</code>: Get job status</li> <li><code>GET /runs/{id}</code>: Get run status/logs</li> <li><code>GET /sla</code>: Get SLA status</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Job%20Scheduler%20%28Cron%20%2B%20DAGs%29%20with%20Retries%20and%20SLAs/#8-security-operational-considerations","title":"8. Security &amp; Operational Considerations","text":"<ul> <li>Security:<ul> <li>Role-based access for job creation and management</li> <li>All actions logged for audit</li> </ul> </li> <li>Monitoring:<ul> <li>Real-time dashboards for job status, failures, and SLAs</li> </ul> </li> <li>Disaster Recovery:<ul> <li>Regular DB and artifact backups</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Job%20Scheduler%20%28Cron%20%2B%20DAGs%29%20with%20Retries%20and%20SLAs/#9-best-practices-industry-insights","title":"9. Best Practices &amp; Industry Insights","text":"<ul> <li>Use DAGs for complex dependencies, cron for simple schedules</li> <li>Persist all state for reliability</li> <li>Use idempotent jobs to handle retries safely</li> <li>Integrate with alerting/on-call for SLA misses</li> <li>Design for manual override and backfill</li> </ul> <p>This design is inspired by Airflow, Argo, and other industry schedulers, and can be extended for event-driven triggers, dynamic scaling, and multi-tenant support.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Job%20Scheduler%20%28cron%20%2B%20DAGs%29/","title":"Job Scheduler (cron + DAGs) \u2014 Deep Dive","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Job%20Scheduler%20%28cron%20%2B%20DAGs%29/#1-problem-statement-scope","title":"1. Problem Statement &amp; Scope","text":"<p>Design a reliable, scalable job scheduling and orchestration platform for cron and DAG-based workflows (like Airflow/Prefect). The system must support complex dependencies, retries, monitoring, high availability, and extensibility for custom operators and plugins.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Job%20Scheduler%20%28cron%20%2B%20DAGs%29/#2-functional-non-functional-requirements","title":"2. Functional &amp; Non-Functional Requirements","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Job%20Scheduler%20%28cron%20%2B%20DAGs%29/#functional-requirements","title":"Functional Requirements","text":"<ul> <li>Define workflows as DAGs (Directed Acyclic Graphs) of tasks</li> <li>Trigger jobs on schedule (cron), event, or manually</li> <li>Manage dependencies, retries, backoff, and failure handling</li> <li>UI/API for workflow management, monitoring, and manual intervention</li> <li>Support for parameterized and dynamic DAGs</li> <li>SLA monitoring and alerting</li> <li>Backfill and rerun for missed/failed jobs</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Job%20Scheduler%20%28cron%20%2B%20DAGs%29/#non-functional-requirements","title":"Non-Functional Requirements","text":"<ul> <li>Scalability: 10k+ concurrent jobs, 100k+ tasks/day</li> <li>Reliability: No job loss, strong guarantees, at-least-once execution</li> <li>Extensibility: Support custom operators, plugins, and hooks</li> <li>Observability: Real-time status, logs, and metrics</li> <li>Security: Role-based access, audit logs</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Job%20Scheduler%20%28cron%20%2B%20DAGs%29/#3-capacity-scale-estimation","title":"3. Capacity &amp; Scale Estimation","text":"<ul> <li>Workflows: 10k active DAGs</li> <li>Tasks/DAG: Avg 10</li> <li>Job Rate: 1k/sec peak</li> <li>Log Storage: 1TB+/month</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Job%20Scheduler%20%28cron%20%2B%20DAGs%29/#4-high-level-architecture","title":"4. High-Level Architecture","text":"<pre><code>graph TD\n    User[User/UI/API] --&gt; Scheduler\n    Scheduler --&gt; MetadataDB[Metadata DB (Postgres)]\n    Scheduler --&gt; Queue[Message Queue (RabbitMQ/Kafka)]\n    Queue --&gt; WorkerFleet[Worker Fleet]\n    WorkerFleet --&gt; ObjectStorage[Object Storage]\n    Scheduler --&gt; Monitoring[Monitoring/Alerting]\n    Scheduler --&gt; UIAPI[UI/API]\n</code></pre>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Job%20Scheduler%20%28cron%20%2B%20DAGs%29/#5-data-model-api-design","title":"5. Data Model &amp; API Design","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Job%20Scheduler%20%28cron%20%2B%20DAGs%29/#api-endpoints","title":"API Endpoints","text":"<ul> <li><code>POST /v1/dags</code>: Create DAG</li> <li><code>POST /v1/dags/{dag_id}/runs</code>: Trigger run</li> <li><code>GET /v1/dags/{dag_id}/runs/{run_id}</code>: Get status</li> <li><code>POST /v1/dags/{dag_id}/backfill</code>: Backfill DAG</li> <li><code>GET /v1/tasks/{task_id}/logs</code>: Get task logs</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Job%20Scheduler%20%28cron%20%2B%20DAGs%29/#data-models","title":"Data Models","text":"<ul> <li>DAG: {dag_id, definition, schedule, owner, ...}</li> <li>DagRun: {run_id, dag_id, status, start_time, end_time}</li> <li>TaskInstance: {task_id, run_id, status, retries, logs, sla_deadline}</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Job%20Scheduler%20%28cron%20%2B%20DAGs%29/#6-detailed-component-breakdown","title":"6. Detailed Component Breakdown","text":"<ul> <li>Scheduler: Core orchestrator. Evaluates schedules, triggers DAG runs, manages state, handles retries and backoff</li> <li>Metadata DB: Stores DAG definitions, run history, task state, and audit logs</li> <li>Message Queue: Decouples scheduling from execution. Ensures reliable delivery of tasks to workers</li> <li>Worker Fleet: Stateless workers execute tasks, autoscale, heartbeat for liveness</li> <li>Object Storage: Stores logs, artifacts, and large outputs</li> <li>Monitoring/Alerting: Tracks job status, failures, metrics, and SLAs</li> <li>UI/API: For workflow management, monitoring, and manual intervention</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Job%20Scheduler%20%28cron%20%2B%20DAGs%29/#7-end-to-end-workflows","title":"7. End-to-End Workflows","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Job%20Scheduler%20%28cron%20%2B%20DAGs%29/#a-dag-run","title":"a) DAG Run","text":"<ol> <li>User triggers DAG run (manual, scheduled, or event)</li> <li>Scheduler creates DagRun in DB</li> <li>Scheduler enqueues runnable tasks to Message Queue</li> <li>Workers fetch tasks, execute, write logs/artifacts to Object Storage</li> <li>Workers update task status in DB</li> <li>Scheduler monitors progress, retries failed tasks with backoff</li> <li>SLA monitor triggers alerts if deadlines missed</li> <li>User/UI receives status updates</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Job%20Scheduler%20%28cron%20%2B%20DAGs%29/#b-backfill-rerun","title":"b) Backfill &amp; Rerun","text":"<ol> <li>User triggers backfill for missed/failed runs</li> <li>Scheduler re-plans DAG, enqueues tasks as needed</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Job%20Scheduler%20%28cron%20%2B%20DAGs%29/#c-sla-monitoring-alerting","title":"c) SLA Monitoring &amp; Alerting","text":"<ol> <li>SLA monitor tracks deadlines for each task</li> <li>Alerts sent to ops/on-call if missed</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Job%20Scheduler%20%28cron%20%2B%20DAGs%29/#8-scaling-fault-tolerance-and-trade-offs","title":"8. Scaling, Fault Tolerance, and Trade-offs","text":"<ul> <li>Scaling:<ul> <li>Partition queues and worker pools for scale</li> <li>Use distributed scheduler for HA</li> </ul> </li> <li>Fault Tolerance:<ul> <li>All state persisted in DB, durable queue</li> <li>Workers heartbeat, zombie detector for failures</li> <li>At-least-once execution, idempotent tasks</li> </ul> </li> <li>Trade-offs:<ul> <li>Strong guarantees add complexity; eventual consistency possible for non-critical metrics</li> <li>Centralized scheduler is simple, distributed is more resilient</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Job%20Scheduler%20%28cron%20%2B%20DAGs%29/#9-security-operational-considerations","title":"9. Security &amp; Operational Considerations","text":"<ul> <li>Security:<ul> <li>Role-based access for job creation and management</li> <li>All actions logged for audit</li> </ul> </li> <li>Monitoring:<ul> <li>Real-time dashboards for job status, failures, and SLAs</li> </ul> </li> <li>Disaster Recovery:<ul> <li>Regular DB and artifact backups</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Job%20Scheduler%20%28cron%20%2B%20DAGs%29/#10-best-practices-industry-insights","title":"10. Best Practices &amp; Industry Insights","text":"<ul> <li>Use DAGs for complex dependencies, cron for simple schedules</li> <li>Persist all state for reliability</li> <li>Use idempotent jobs to handle retries safely</li> <li>Integrate with alerting/on-call for SLA misses</li> <li>Design for manual override, backfill, and dynamic scaling</li> </ul> <p>This design is inspired by Airflow, Prefect, Argo, and other industry workflow engines, and can be extended for event-driven triggers, dynamic scaling, and multi-tenant support.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Limit%20Order%20Book%20%26%20Matching%20Engine/","title":"Limit Order Book &amp; Matching Engine \u2014 Deep Dive","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Limit%20Order%20Book%20%26%20Matching%20Engine/#1-problem-statement-scope","title":"1. Problem Statement &amp; Scope","text":"<p>Design a high-performance, deterministic matching engine for a single financial instrument (e.g., AAPL stock). The engine must process new/cancel/modify orders, match trades using strict price-time priority, and ensure durability, auditability, and fault tolerance. The system should support high throughput (100k+ orders/sec), low latency (&lt;1ms per match), and be the source of truth for all trades.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Limit%20Order%20Book%20%26%20Matching%20Engine/#2-functional-non-functional-requirements","title":"2. Functional &amp; Non-Functional Requirements","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Limit%20Order%20Book%20%26%20Matching%20Engine/#functional-requirements","title":"Functional Requirements","text":"<ul> <li>Accept new limit and market orders (buy/sell)</li> <li>Accept order cancellation and modification requests</li> <li>Match orders using price-time priority (FIFO within price level)</li> <li>Support order types: Limit, Market, IOC (Immediate or Cancel), FOK (Fill or Kill)</li> <li>Generate trade execution reports and order status updates</li> <li>Support for partial fills, order expiry, and self-trade prevention</li> <li>Real-time order book snapshot API</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Limit%20Order%20Book%20%26%20Matching%20Engine/#non-functional-requirements","title":"Non-Functional Requirements","text":"<ul> <li>Performance: &lt;1ms matching latency, 100k+ orders/sec</li> <li>Determinism: Same input sequence always produces same output</li> <li>Durability: No loss of orders/trades on crash (WAL, snapshots)</li> <li>Availability: 99.99% uptime, fast failover</li> <li>Auditability: Full replay and audit trail</li> <li>Security: Authenticated clients, encrypted channels</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Limit%20Order%20Book%20%26%20Matching%20Engine/#3-capacity-scale-estimation","title":"3. Capacity &amp; Scale Estimation","text":"<ul> <li>Order Rate: 100k orders/sec peak</li> <li>Order Book Depth: 10k price levels, 1M open orders</li> <li>Trade Rate: 10k trades/sec</li> <li>Storage: Each order ~200 bytes, 1M open orders = 200MB in-memory. WAL: 100k orders/sec * 200B = 20MB/sec, ~1.7TB/day</li> <li>Snapshot Frequency: Every 1s or 10k events</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Limit%20Order%20Book%20%26%20Matching%20Engine/#4-high-level-architecture","title":"4. High-Level Architecture","text":"<pre><code>graph TD\n    Gateway[Client Gateway] --&gt; Sequencer\n    Sequencer --&gt; MatchingEngine[Matching Engine (Single-threaded)]\n    MatchingEngine --&gt; WAL[WAL Persister]\n    MatchingEngine --&gt; Snapshotter\n    MatchingEngine --&gt; EventBus\n    EventBus --&gt; Downstream[Downstream Consumers (Analytics, Risk, UI)]\n    WAL --&gt; DurableStorage\n    Snapshotter --&gt; DurableStorage\n    Sequencer --&gt; OrderBookState\n    MatchingEngine --&gt; OrderBookState\n    OrderBookState --&gt; MatchingEngine\n</code></pre>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Limit%20Order%20Book%20%26%20Matching%20Engine/#5-data-model-api-design","title":"5. Data Model &amp; API Design","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Limit%20Order%20Book%20%26%20Matching%20Engine/#api-endpoints","title":"API Endpoints","text":"<ul> <li><code>POST /order</code>: New order (limit/market/IOC/FOK)</li> <li><code>POST /cancel</code>: Cancel order</li> <li><code>POST /replace</code>: Modify order</li> <li><code>GET /orderbook</code>: Get current order book snapshot</li> <li><code>GET /trades</code>: Get recent trades</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Limit%20Order%20Book%20%26%20Matching%20Engine/#data-models","title":"Data Models","text":"<ul> <li>Order: {order_id, side, price, qty, type, tif, user_id, timestamp}</li> <li>ExecutionReport: {order_id, status, fill_qty, fill_price, ...}</li> <li>Order Book: Two price-ordered trees (bids, asks), each price \u2192 FIFO queue of orders</li> <li>WAL (Write-Ahead Log): Append-only log of all order events, persisted before ack</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Limit%20Order%20Book%20%26%20Matching%20Engine/#6-detailed-component-breakdown","title":"6. Detailed Component Breakdown","text":"<ul> <li>Client Gateway: Authenticates clients, validates messages, and forwards to sequencer</li> <li>Sequencer: Assigns a global sequence number to all incoming messages, ensuring total ordering and preventing race conditions</li> <li>Matching Engine: Single-threaded for determinism. Maintains in-memory order book, processes events in order, matches trades, and generates execution reports</li> <li>WAL Persister: Writes every event to disk before ack. Enables crash recovery and replay</li> <li>Snapshotter: Periodically saves full in-memory state for fast recovery</li> <li>Event Bus: Publishes all events (order, trade, cancel) to downstream consumers (risk, analytics, UI)</li> <li>Durable Storage: Stores WAL and snapshots for audit and replay</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Limit%20Order%20Book%20%26%20Matching%20Engine/#7-end-to-end-workflows","title":"7. End-to-End Workflows","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Limit%20Order%20Book%20%26%20Matching%20Engine/#a-order-submission-matching","title":"a) Order Submission &amp; Matching","text":"<ol> <li>Trader submits new order via Gateway</li> <li>Gateway authenticates, validates, and forwards to Sequencer</li> <li>Sequencer assigns sequence number, forwards to Matching Engine</li> <li>Matching Engine writes event to WAL, waits for ack</li> <li>Matching Engine updates order book, matches trades, generates execution reports</li> <li>Execution reports published to Event Bus and returned to client</li> <li>Periodic snapshots taken for fast recovery</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Limit%20Order%20Book%20%26%20Matching%20Engine/#b-crash-recovery","title":"b) Crash Recovery","text":"<ol> <li>On crash, engine loads last snapshot</li> <li>Replays WAL from snapshot point to current</li> <li>Resumes matching with no loss of state</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Limit%20Order%20Book%20%26%20Matching%20Engine/#c-failover","title":"c) Failover","text":"<ol> <li>Hot standby replica replays WAL in real-time</li> <li>On failover, standby takes over with minimal downtime</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Limit%20Order%20Book%20%26%20Matching%20Engine/#8-scaling-fault-tolerance-and-trade-offs","title":"8. Scaling, Fault Tolerance, and Trade-offs","text":"<ul> <li>Scaling:<ul> <li>Partition by instrument (one engine per symbol) for horizontal scale</li> <li>Use sharded WAL and snapshot storage for throughput</li> </ul> </li> <li>Fault Tolerance:<ul> <li>WAL + periodic snapshots for durability</li> <li>Hot standby replica for fast failover</li> </ul> </li> <li>Trade-offs:<ul> <li>Single-threaded = simple, deterministic, but not horizontally scalable for one instrument</li> <li>WAL = strong durability, but adds write latency</li> <li>Partitioning by instrument enables horizontal scale</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Limit%20Order%20Book%20%26%20Matching%20Engine/#9-security-operational-considerations","title":"9. Security &amp; Operational Considerations","text":"<ul> <li>Security:<ul> <li>Authenticate all clients, encrypt all channels</li> <li>All actions logged for audit</li> </ul> </li> <li>Monitoring:<ul> <li>Real-time dashboards for order flow, latency, and errors</li> </ul> </li> <li>Disaster Recovery:<ul> <li>Regular backups of WAL and snapshots</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Limit%20Order%20Book%20%26%20Matching%20Engine/#10-best-practices-industry-insights","title":"10. Best Practices &amp; Industry Insights","text":"<ul> <li>Use single-threaded engine for determinism, partition by instrument for scale</li> <li>Always persist to WAL before ack</li> <li>Use periodic snapshots for fast recovery</li> <li>Integrate with risk and analytics systems via event bus</li> <li>Design for auditability and replay</li> </ul> <p>This design is inspired by real-world exchanges (e.g., NASDAQ, NYSE, CME) and can be extended for multi-instrument, multi-market, and cross-venue matching.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Live%20Video%20Streaming%20with%20DVR/","title":"Live Video Streaming with DVR","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Live%20Video%20Streaming%20with%20DVR/#live-video-streaming-webrtc-with-dvr-seekable","title":"Live Video Streaming (WebRTC) with DVR (Seekable)","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Live%20Video%20Streaming%20with%20DVR/#1-problem-statement-requirements","title":"1. Problem Statement &amp; Requirements","text":"<p>Design a scalable, low-latency live video streaming platform with DVR (seekable playback) and multi-camera support.</p> <p>Functional Requirements: - Ingest live video from publishers (WebRTC, RTMP) - &lt;500ms glass-to-glass latency for live - DVR: Seekable playback (HLS/DASH fallback) - Multi-camera support (switching, simulcast) - Viewer authentication and access control - Adaptive bitrate (ABR) streaming</p> <p>Non-Functional Requirements: - 1\u201310k concurrent viewers - 100\u2013500 publishers - High availability, geo-distributed - Scalable to spikes (e.g., events)</p> <p>Assumptions: - SFU (Selective Forwarding Unit) for WebRTC - Object store for DVR segments</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Live%20Video%20Streaming%20with%20DVR/#2-high-level-architecture","title":"2. High-Level Architecture","text":"<p>Components: - Ingest Gateway: Accepts WebRTC/RTMP streams from publishers - SFU: Routes video/audio to viewers, supports simulcast - Transcoder: Optional, for ABR and format conversion - Timeshift Buffer: In-memory ring for short DVR, object store for long DVR - CDN: Distributes HLS/DASH segments to viewers - Viewer Gateway: Authenticates and manages viewer sessions - Segment Index: Tracks available segments for DVR</p> <p>Architecture Diagram: <pre><code> [Publisher] -&gt; [Ingest] -&gt; [SFU] -&gt; [Transcoder] -&gt; [Timeshift Buffer] -&gt; [CDN] -&gt; [Viewer]\n</code></pre></p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Live%20Video%20Streaming%20with%20DVR/#3-data-model-segmentation","title":"3. Data Model &amp; Segmentation","text":"<ul> <li>Segment: { id, camera_id, start_ts, duration, url }</li> <li>DVR Index: Maps camera_id to list of segments</li> <li>Viewer Session: { id, user_id, camera_id, live/seek, ... }</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Live%20Video%20Streaming%20with%20DVR/#4-key-workflows","title":"4. Key Workflows","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Live%20Video%20Streaming%20with%20DVR/#a-live-ingest-routing","title":"a) Live Ingest &amp; Routing","text":"<ol> <li>Publisher connects via WebRTC/RTMP</li> <li>Ingest gateway authenticates and registers stream</li> <li>SFU routes video/audio to viewers (simulcast for ABR)</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Live%20Video%20Streaming%20with%20DVR/#b-dvr-recording-playback","title":"b) DVR Recording &amp; Playback","text":"<ol> <li>Segments written to in-memory ring buffer (short-term)</li> <li>Segments flushed to object store for long-term DVR</li> <li>Segment index updated for seek/playback</li> <li>Viewer requests live or past segment; CDN serves from buffer or object store</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Live%20Video%20Streaming%20with%20DVR/#c-multi-camera-abr","title":"c) Multi-camera &amp; ABR","text":"<ol> <li>Publisher can switch cameras or simulcast</li> <li>Viewer can select camera/bitrate</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Live%20Video%20Streaming%20with%20DVR/#5-scaling-reliability","title":"5. Scaling &amp; Reliability","text":"<ul> <li>Horizontal Scaling: Multiple ingest/SFU/CDN nodes</li> <li>Geo-distribution: Edge nodes for low-latency</li> <li>Segment Index: Distributed, consistent</li> <li>Monitoring: Latency, segment loss, viewer QoE</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Live%20Video%20Streaming%20with%20DVR/#6-bottlenecks-mitigations","title":"6. Bottlenecks &amp; Mitigations","text":"<ul> <li>CPU on Transcode: Use hardware encoders, ladder planning</li> <li>Network Spikes: CDN and edge cache</li> <li>Segment Loss: Redundant ingest, segment replication</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Live%20Video%20Streaming%20with%20DVR/#7-best-practices-extensions","title":"7. Best Practices &amp; Extensions","text":"<ul> <li>Use CMAF for low-latency HLS/DASH</li> <li>Health checks for publisher streams</li> <li>Analytics for viewer engagement</li> <li>DRM for premium content</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Live%20Video%20Streaming%20with%20DVR/#8-example-pseudocode-segment-index","title":"8. Example Pseudocode (Segment Index)","text":"<pre><code>class SegmentIndex:\n    def __init__(self):\n        self.index = defaultdict(list)\n    def add_segment(self, camera_id, segment):\n        self.index[camera_id].append(segment)\n    def get_segments(self, camera_id, start, end):\n        return [s for s in self.index[camera_id] if start &lt;= s.start_ts &lt; end]\n</code></pre>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Live%20Video%20Streaming%20with%20DVR/#9-references","title":"9. References","text":"<ul> <li>WebRTC SFU</li> <li>Low-latency HLS/DASH</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/ML%20Feature%20Store/","title":"ML Feature Store (Online + Offline)","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/ML%20Feature%20Store/#requirements","title":"Requirements","text":"<ul> <li>Point-in-time correctness</li> <li>Online/serving parity</li> <li>Backfills</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/ML%20Feature%20Store/#scale","title":"Scale","text":"<ul> <li>10k QPS feature reads</li> <li>100k QPS writes</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/ML%20Feature%20Store/#core-architecture","title":"Core Architecture","text":"<ul> <li>Offline store (Parquet/Iceberg) + online KV (Redis/Cassandra)</li> <li>Registry</li> <li>Materialization jobs</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/ML%20Feature%20Store/#storage","title":"Storage","text":"<ul> <li>As above; TTLs for online</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/ML%20Feature%20Store/#flow","title":"Flow","text":"<ul> <li>Write events \u2192 batch compute \u2192 push to online; join at inference</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/ML%20Feature%20Store/#trade-offs","title":"Trade-offs","text":"<ul> <li>Latency vs consistency; late-arriving data</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/ML%20Feature%20Store/#diagram","title":"Diagram","text":"<pre><code>[Event] -&gt; [Batch Compute] -&gt; [Offline Store] -&gt; [Materialization] -&gt; [Online Store] -&gt; [Serving]\n</code></pre>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/ML%20Feature%20Store/#notes","title":"Notes","text":"<ul> <li>TTLs for online features</li> <li>Registry for schema/versioning</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Meeting%20Room%20Scheduler/","title":"Meeting Room Scheduler","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Meeting%20Room%20Scheduler/#problem-statement","title":"Problem Statement","text":"<p>Book rooms avoiding conflicts, search by capacity/resources, support recurring bookings.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Meeting%20Room%20Scheduler/#functional-requirements","title":"Functional Requirements","text":"<ul> <li>Create rooms</li> <li>Book/cancel</li> <li>Search free slots</li> <li>Recurring bookings</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Meeting%20Room%20Scheduler/#core-concepts","title":"Core Concepts","text":"<ul> <li><code>Room(id, capacity, features)</code></li> <li><code>Booking(roomId, interval, user)</code></li> <li><code>IntervalTree</code> or ordered map per room for conflict checks</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Meeting%20Room%20Scheduler/#high-level-design","title":"High-Level Design","text":"<ul> <li>Room Management:<ul> <li>Add/edit/delete rooms</li> <li>Track features (A/V, whiteboard, etc.)</li> </ul> </li> <li>Booking:<ul> <li>Book/cancel with conflict checks</li> <li>Recurring bookings: expand to individual slots</li> </ul> </li> <li>Search:<ul> <li>Find free rooms by time/capacity/features</li> </ul> </li> <li>Edge Cases:<ul> <li>Buffer times between meetings</li> <li>Recurrence expansion</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Meeting%20Room%20Scheduler/#step-by-step-solution","title":"Step-by-Step Solution","text":"<ol> <li>Define classes: Room, Booking, IntervalTree</li> <li>Booking logic: conflict checks</li> <li>Search: by time/capacity/features</li> <li>API: create room, book, search</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Meeting%20Room%20Scheduler/#edge-cases","title":"Edge Cases","text":"<ul> <li>Overlapping bookings</li> <li>Recurring conflicts</li> <li>Room feature changes</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Metrics%20Store%20%28Append-only%20%2B%20Compaction%29/","title":"Metrics Store (Append-only + Compaction)","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Metrics%20Store%20%28Append-only%20%2B%20Compaction%29/#problem-statement","title":"Problem Statement","text":"<p>In-process time-series store with write/fetch and periodic compaction.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Metrics%20Store%20%28Append-only%20%2B%20Compaction%29/#functional-requirements","title":"Functional Requirements","text":"<ul> <li><code>put(metric, ts, value)</code>, <code>rangeQuery(metric, from, to)</code></li> <li>Compaction to downsample older data (1s\u21921m)</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Metrics%20Store%20%28Append-only%20%2B%20Compaction%29/#core-concepts","title":"Core Concepts","text":"<ul> <li><code>Segment</code> (append log), <code>Index</code>, <code>Compactor</code></li> <li>Memory-mapped segments (optional)</li> <li>Read path merges raw+compact</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Metrics%20Store%20%28Append-only%20%2B%20Compaction%29/#high-level-design","title":"High-Level Design","text":"<ul> <li>Segments:<ul> <li>Append-only log per metric</li> <li>Index for fast lookup</li> </ul> </li> <li>Compaction:<ul> <li>Downsample old data (e.g., 1s \u2192 1m)</li> <li>Merge segments</li> </ul> </li> <li>API:<ul> <li>put, rangeQuery</li> </ul> </li> <li>Edge Cases:<ul> <li>Out-of-order writes</li> <li>Query across raw+compact</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Metrics%20Store%20%28Append-only%20%2B%20Compaction%29/#step-by-step-solution","title":"Step-by-Step Solution","text":"<ol> <li>Define Segment, Index, Compactor classes</li> <li>Write path: append to segment</li> <li>Compaction: periodic downsampling</li> <li>API: put, rangeQuery</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Metrics%20Store%20%28Append-only%20%2B%20Compaction%29/#edge-cases","title":"Edge Cases","text":"<ul> <li>Data loss on crash (in-memory)</li> <li>Compaction lag</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Model%20Serving%20Platform/","title":"Model Serving Platform (AB Tests + Canary)","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Model%20Serving%20Platform/#requirements","title":"Requirements","text":"<ul> <li>Deploy models</li> <li>Traffic splits</li> <li>Versioned</li> <li>Logging/metrics</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Model%20Serving%20Platform/#scale","title":"Scale","text":"<ul> <li>5\u201320k QPS</li> <li>p99 &lt; 50ms</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Model%20Serving%20Platform/#core-architecture","title":"Core Architecture","text":"<ul> <li>Gateway</li> <li>Router</li> <li>Model containers (GPU/CPU)</li> <li>Feature fetch</li> <li>Result</li> <li>Control plane for versions/allocations</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Model%20Serving%20Platform/#storage","title":"Storage","text":"<ul> <li>Model registry (S3 + DB)</li> <li>Logs in OLAP</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Model%20Serving%20Platform/#flow","title":"Flow","text":"<ul> <li>Request \u2192 fetch features \u2192 call model \u2192 log; shadow/canary options</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Model%20Serving%20Platform/#bottlenecks-mitigations","title":"Bottlenecks &amp; Mitigations","text":"<ul> <li>Cold starts; fix with warm pools &amp; autoscaling</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Model%20Serving%20Platform/#diagram","title":"Diagram","text":"<pre><code>[Gateway] -&gt; [Router] -&gt; [Model Container] -&gt; [Result] -&gt; [Log]\n</code></pre>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Model%20Serving%20Platform/#notes","title":"Notes","text":"<ul> <li>Use shadow/canary for safe rollout</li> <li>Warm pools for low latency</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Multi-camera%20RTSP%20to%20WebRTC%20Gateway/","title":"Multi camera RTSP to WebRTC Gateway","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Multi-camera%20RTSP%20to%20WebRTC%20Gateway/#multi-camera-rtsp-webrtc-gateway","title":"Multi-camera RTSP \u2192 WebRTC Gateway","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Multi-camera%20RTSP%20to%20WebRTC%20Gateway/#1-problem-statement-requirements","title":"1. Problem Statement &amp; Requirements","text":"<p>Design a gateway to ingest multiple RTSP (CCTV) feeds, transcode/mux, and serve via WebRTC with per-camera auth and monitoring.</p> <p>Functional Requirements: - Pull RTSP feeds from cameras (hundreds of sources) - Transcode/mux to WebRTC-compatible format - Serve to viewers via WebRTC (1\u2013100 per feed) - Per-camera authentication and access control - Health checks and auto-restart for dead feeds - Metrics and monitoring for all streams</p> <p>Non-Functional Requirements: - Low-latency (sub-second) - High reliability, auto-recovery - Scalable to hundreds of feeds</p> <p>Assumptions: - GStreamer/NVENC for decode/encode - SFU for WebRTC fan-out</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Multi-camera%20RTSP%20to%20WebRTC%20Gateway/#2-high-level-architecture","title":"2. High-Level Architecture","text":"<p>Components: - RTSP Puller: Connects to camera, pulls RTSP stream - Decoder/Encoder: Transcodes to WebRTC format (H.264/Opus) - SFU: Routes streams to viewers - Access Control Service: Authenticates viewers per camera - Metrics Service: Collects stream health, viewer stats - Health Checker: Monitors and restarts dead feeds - Storage: Short buffer (tmpfs), S3 for recordings</p> <p>Architecture Diagram: <pre><code> [RTSP Puller] -&gt; [Decoder/Encoder] -&gt; [SFU] -&gt; [WebRTC] -&gt; [Viewer]\n                                 |\n                                 v\n                            [Metrics/Health]\n</code></pre></p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Multi-camera%20RTSP%20to%20WebRTC%20Gateway/#3-data-model-stream-management","title":"3. Data Model &amp; Stream Management","text":"<ul> <li>Camera: { id, url, auth, ... }</li> <li>Stream: { camera_id, status, viewers, bitrate, ... }</li> <li>Viewer: { id, camera_id, session, ... }</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Multi-camera%20RTSP%20to%20WebRTC%20Gateway/#4-key-workflows","title":"4. Key Workflows","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Multi-camera%20RTSP%20to%20WebRTC%20Gateway/#a-feed-ingest-transcode","title":"a) Feed Ingest &amp; Transcode","text":"<ol> <li>RTSP Puller connects to camera</li> <li>Decoder/Encoder transcodes to H.264/Opus</li> <li>SFU routes to viewers</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Multi-camera%20RTSP%20to%20WebRTC%20Gateway/#b-viewer-connect-auth","title":"b) Viewer Connect &amp; Auth","text":"<ol> <li>Viewer requests stream, authenticates</li> <li>Access control checks permissions</li> <li>SFU adds viewer to stream</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Multi-camera%20RTSP%20to%20WebRTC%20Gateway/#c-health-check-recovery","title":"c) Health Check &amp; Recovery","text":"<ol> <li>Health checker monitors stream status</li> <li>On failure, restarts RTSP puller/decoder</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Multi-camera%20RTSP%20to%20WebRTC%20Gateway/#5-scaling-reliability","title":"5. Scaling &amp; Reliability","text":"<ul> <li>Horizontal Scaling: Multiple pullers/encoders/SFU nodes</li> <li>Auto-recovery: Health checks and restart logic</li> <li>Metrics: Per-stream and per-viewer stats</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Multi-camera%20RTSP%20to%20WebRTC%20Gateway/#6-trade-offs-alternatives","title":"6. Trade-offs &amp; Alternatives","text":"<ul> <li>Passthrough vs Re-encode: Passthrough is lower latency, re-encode allows ABR and format conversion</li> <li>Buffering: Short buffer for jitter, S3 for long-term recording</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Multi-camera%20RTSP%20to%20WebRTC%20Gateway/#7-best-practices-extensions","title":"7. Best Practices &amp; Extensions","text":"<ul> <li>Use NVENC for efficient encoding</li> <li>Per-camera access control and audit</li> <li>Analytics for viewer engagement</li> <li>Integrate with VMS (video management system)</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Multi-camera%20RTSP%20to%20WebRTC%20Gateway/#8-example-pseudocode-health-checker","title":"8. Example Pseudocode (Health Checker)","text":"<pre><code>class HealthChecker:\n    def __init__(self, streams):\n        self.streams = streams\n    def check(self):\n        for s in self.streams:\n            if not s.is_alive():\n                s.restart()\n</code></pre>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Multi-camera%20RTSP%20to%20WebRTC%20Gateway/#9-references","title":"9. References","text":"<ul> <li>GStreamer</li> <li>WebRTC SFU</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Near-real-time%20Analytics%20Pipeline/","title":"Near-real-time Analytics Pipeline (Clickstream)","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Near-real-time%20Analytics%20Pipeline/#requirements","title":"Requirements","text":"<ul> <li>Sub-second ingest</li> <li>Minute-level aggregates</li> <li>Dashboards</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Near-real-time%20Analytics%20Pipeline/#scale","title":"Scale","text":"<ul> <li>100\u2013500k events/s</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Near-real-time%20Analytics%20Pipeline/#core-architecture","title":"Core Architecture","text":"<ul> <li>Edge collectors</li> <li>Kafka</li> <li>Stream processor (Flink/Spark)</li> <li>OLAP (Pinot/Druid/ClickHouse)</li> <li>BI</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Near-real-time%20Analytics%20Pipeline/#storage","title":"Storage","text":"<ul> <li>Lake for raw</li> <li>OLAP for queries</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Near-real-time%20Analytics%20Pipeline/#flow","title":"Flow","text":"<ul> <li>Ingest \u2192 parse \u2192 sessionize \u2192 materialize rollups</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Near-real-time%20Analytics%20Pipeline/#bottlenecks-mitigations","title":"Bottlenecks &amp; Mitigations","text":"<ul> <li>Reprocessing &amp; exactly-once; use transactional sinks</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Near-real-time%20Analytics%20Pipeline/#diagram","title":"Diagram","text":"<pre><code>[Collector] -&gt; [Kafka] -&gt; [Stream Processor] -&gt; [OLAP] -&gt; [BI]\n</code></pre>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Near-real-time%20Analytics%20Pipeline/#notes","title":"Notes","text":"<ul> <li>Use transactional sinks for exactly-once</li> <li>Sessionization for user analytics</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Notifications%20Hub/","title":"Notifications Hub","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Notifications%20Hub/#notifications-hub-emailsmspushwebhooks","title":"Notifications Hub (Email/SMS/Push/Webhooks)","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Notifications%20Hub/#1-problem-statement-requirements","title":"1. Problem Statement &amp; Requirements","text":"<p>Design a scalable notifications hub to send messages via email, SMS, push, and webhooks, with templating, retries, and per-channel failover.</p> <p>Functional Requirements: - Request API for notifications - Templating engine for dynamic content - Rate limits and idempotency per recipient/channel - Retries and dead-letter queue (DLQ) for failures - Per-channel provider failover - Status tracking and audit logs</p> <p>Non-Functional Requirements: - 10\u2013100M messages/day - High reliability, at-least-once delivery - Low-latency for critical notifications</p> <p>Assumptions: - Multiple providers per channel (e.g., Twilio, SendGrid) - Outbox/event sourcing for reliability</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Notifications%20Hub/#2-high-level-architecture","title":"2. High-Level Architecture","text":"<p>Components: - Request API: Accepts notification requests - Template Renderer: Renders message content - Send Queue: Buffers messages for delivery - Channel Workers: Deliver messages to providers - Provider Adapters: Integrate with email/SMS/push/webhook providers - DLQ: Stores failed messages for retry/manual review - Status Store: Tracks delivery status - Audit Log: Records all events</p> <p>Architecture Diagram: <pre><code> [API] -&gt; [Template] -&gt; [Queue] -&gt; [Channel Worker] -&gt; [Provider] -&gt; [DLQ]\n                                 |\n                                 v\n                            [Status/Audit]\n</code></pre></p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Notifications%20Hub/#3-data-model-delivery-logic","title":"3. Data Model &amp; Delivery Logic","text":"<ul> <li>Notification: { id, recipient, channel, template, params, status, ... }</li> <li>Provider: { id, type, priority, ... }</li> <li>Status: { notification_id, state, timestamp }</li> <li>DLQ Entry: { notification_id, reason, retries }</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Notifications%20Hub/#4-key-workflows","title":"4. Key Workflows","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Notifications%20Hub/#a-notification-request","title":"a) Notification Request","text":"<ol> <li>API receives notification request</li> <li>Template renderer generates content</li> <li>Message enqueued for delivery</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Notifications%20Hub/#b-delivery-retry","title":"b) Delivery &amp; Retry","text":"<ol> <li>Channel worker picks message, selects provider</li> <li>Sends to provider; on failure, retries with backoff</li> <li>On repeated failure, moves to DLQ</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Notifications%20Hub/#c-status-tracking-audit","title":"c) Status Tracking &amp; Audit","text":"<ol> <li>Status store updated on each delivery attempt</li> <li>Audit log records all events</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Notifications%20Hub/#5-scaling-reliability","title":"5. Scaling &amp; Reliability","text":"<ul> <li>Horizontal Scaling: Stateless API/workers, scale by QPS</li> <li>DLQ: Ensures no message lost</li> <li>Provider Failover: Multiple providers per channel</li> <li>Monitoring: Delivery rates, failures, latency</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Notifications%20Hub/#6-trade-offs-alternatives","title":"6. Trade-offs &amp; Alternatives","text":"<ul> <li>At-least-once vs Exactly-once: At-least-once is simpler, exactly-once is complex</li> <li>Synchronous vs Async Delivery: Async for scale, sync for critical</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Notifications%20Hub/#7-best-practices-extensions","title":"7. Best Practices &amp; Extensions","text":"<ul> <li>Use idempotency keys for deduplication</li> <li>Per-channel rate limits</li> <li>Analytics for delivery and engagement</li> <li>Integrate with user preferences and opt-outs</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Notifications%20Hub/#8-example-pseudocode-delivery-worker","title":"8. Example Pseudocode (Delivery Worker)","text":"<pre><code>def deliver_message(msg):\n    for provider in get_providers(msg.channel):\n        try:\n            send_to_provider(provider, msg)\n            update_status(msg.id, 'delivered')\n            return\n        except Exception:\n            continue\n    move_to_dlq(msg)\n</code></pre>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Notifications%20Hub/#9-references","title":"9. References","text":"<ul> <li>Notification Systems at Scale</li> <li>Idempotency in Messaging</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Parking%20Lot/","title":"Parking Lot System Design (Deep Dive)","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Parking%20Lot/#1-problem-statement-scope","title":"1. Problem Statement &amp; Scope","text":"<p>Design a scalable, multi-floor parking lot system supporting various spot types (regular, compact, handicapped, EV, etc.), dynamic pricing, and real-time spot allocation. The system must handle park/unpark, nearest spot allocation, billing, reservations, and operational edge cases.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Parking%20Lot/#2-functional-non-functional-requirements","title":"2. Functional &amp; Non-Functional Requirements","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Parking%20Lot/#functional-requirements","title":"Functional Requirements","text":"<ul> <li>Park/unpark vehicle (with ticket issuance and validation)</li> <li>Find and allocate nearest suitable spot by vehicle type</li> <li>Track tickets, entry/exit times, and calculate fees</li> <li>Support reservations and dynamic pricing</li> <li>Admin APIs for lot status, spot management, and reporting</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Parking%20Lot/#non-functional-requirements","title":"Non-Functional Requirements","text":"<ul> <li>Scalability: Support 10,000+ spots, 100+ floors, and high QPS at entry/exit</li> <li>Reliability: No ticket/spot loss, robust against hardware failures</li> <li>Low Latency: &lt;100ms for park/unpark operations</li> <li>Auditability: All transactions and events logged</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Parking%20Lot/#3-core-concepts-data-model","title":"3. Core Concepts &amp; Data Model","text":"<ul> <li>Entities:<ul> <li><code>ParkingLot</code>: Top-level container for all floors</li> <li><code>Floor</code>: Contains multiple <code>Spot</code> objects</li> <li><code>Spot</code>: {id, type, isFree, floorId, reservedFor}</li> <li><code>Vehicle</code>: {id, type, licensePlate, owner}</li> <li><code>Ticket</code>: {ticketId, vehicleId, spotId, entryTime, exitTime, status, fee}</li> <li><code>Reservation</code>: {reservationId, spotId, vehicleId, reservedFrom, reservedTo}</li> </ul> </li> <li>Allocator: Pluggable strategy (nearest, cheapest, reserved, etc.)</li> <li>Billing: Dynamic pricing, discounts, lost ticket handling</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Parking%20Lot/#4-high-level-architecture","title":"4. High-Level Architecture","text":"<pre><code>graph TD\n    EntryGate --&gt;|Scan/Issue Ticket| TicketingSystem\n    TicketingSystem --&gt; Allocator\n    Allocator --&gt; SpotDB\n    SpotDB --&gt; Allocator\n    Allocator --&gt;|Assign Spot| DisplayBoard\n    ExitGate --&gt;|Scan Ticket| TicketingSystem\n    TicketingSystem --&gt; Billing\n    Billing --&gt; PaymentGateway\n    AdminPanel --&gt; SpotDB\n</code></pre> <p>Components: - Entry/Exit Gates: Hardware with QR/barcode scanners - Ticketing System: Issues, validates, and tracks tickets - Allocator: Finds optimal spot (nearest, reserved, etc.) - SpotDB: Stores real-time spot status (in-memory + persistent DB) - Billing: Calculates fees, applies discounts, handles lost tickets - Admin Panel: For monitoring, reporting, and manual overrides</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Parking%20Lot/#5-detailed-workflows","title":"5. Detailed Workflows","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Parking%20Lot/#a-parking-a-vehicle","title":"a) Parking a Vehicle","text":"<ol> <li>Vehicle arrives at entry gate</li> <li>System scans license plate or issues new ticket</li> <li>Allocator finds nearest available spot of required type</li> <li>Spot is reserved and displayed to driver</li> <li>Ticket is updated with spotId, entryTime</li> <li>Spot status updated in SpotDB (atomic operation)</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Parking%20Lot/#b-unparking-a-vehicle","title":"b) Unparking a Vehicle","text":"<ol> <li>Vehicle arrives at exit gate, presents ticket</li> <li>System fetches ticket, calculates duration and fee</li> <li>Payment processed (cash/card/app)</li> <li>Spot marked as free, ticket closed</li> <li>All events logged for audit</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Parking%20Lot/#c-reservation-flow","title":"c) Reservation Flow","text":"<ol> <li>User reserves spot via app/website</li> <li>System blocks spot for reservation window</li> <li>On arrival, reservation is validated and spot is assigned</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Parking%20Lot/#d-lost-ticket-handling","title":"d) Lost Ticket Handling","text":"<ol> <li>User reports lost ticket at exit</li> <li>System verifies vehicle via license plate/camera</li> <li>Admin override or maximum fee applied</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Parking%20Lot/#6-scaling-fault-tolerance-and-trade-offs","title":"6. Scaling, Fault Tolerance, and Trade-offs","text":"<ul> <li>Scaling:<ul> <li>Use sharded SpotDB for large lots</li> <li>In-memory cache for real-time spot status, with periodic DB sync</li> <li>Async event processing for ticketing and billing</li> </ul> </li> <li>Fault Tolerance:<ul> <li>Redundant entry/exit hardware</li> <li>Persistent logs for all transactions</li> <li>Graceful fallback to manual mode on system failure</li> </ul> </li> <li>Trade-offs:<ul> <li>Nearest-spot allocation is fast but may not optimize for exit speed</li> <li>Dynamic pricing increases complexity but maximizes revenue</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Parking%20Lot/#7-api-interface-design","title":"7. API &amp; Interface Design","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Parking%20Lot/#user-apis","title":"User APIs","text":"<ul> <li><code>POST /park</code>: Park vehicle, returns ticket and spot info</li> <li><code>POST /unpark</code>: Unpark vehicle, returns fee</li> <li><code>GET /status</code>: Get lot/floor/spot status</li> <li><code>POST /reserve</code>: Reserve spot</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Parking%20Lot/#admin-apis","title":"Admin APIs","text":"<ul> <li><code>GET /report</code>: Usage, revenue, occupancy</li> <li><code>POST /override</code>: Manual spot/ticket override</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Parking%20Lot/#8-security-operational-considerations","title":"8. Security &amp; Operational Considerations","text":"<ul> <li>Security:<ul> <li>Secure entry/exit with cameras and ticket validation</li> <li>Prevent ticket reuse and fraud</li> </ul> </li> <li>Monitoring:<ul> <li>Real-time dashboards for occupancy, revenue, and incidents</li> </ul> </li> <li>Disaster Recovery:<ul> <li>Regular DB backups, failover hardware</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Parking%20Lot/#9-best-practices-industry-insights","title":"9. Best Practices &amp; Industry Insights","text":"<ul> <li>Use atomic operations for spot allocation to avoid double-booking</li> <li>Prefer in-memory cache for real-time status, but always persist to DB</li> <li>Integrate with payment gateways for seamless billing</li> <li>Use event sourcing for auditability and replay</li> <li>Design for manual override in all critical paths</li> </ul> <p>This design is inspired by real-world systems like Park+ and NEXPA, and can be extended for EV charging, valet, and smart parking integrations.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Payment%20Gateway%20%28Cards-UPI%29%20with%20Idempotency/","title":"Payment Gateway (Cards UPI) with Idempotency","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Payment%20Gateway%20%28Cards-UPI%29%20with%20Idempotency/#payment-gateway-cardsupi-with-idempotency","title":"Payment Gateway (Cards/UPI) with Idempotency","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Payment%20Gateway%20%28Cards-UPI%29%20with%20Idempotency/#1-problem-statement-requirements","title":"1. Problem Statement &amp; Requirements","text":"<p>Design a highly available, idempotent payment gateway for cards and UPI, supporting retries, webhooks, and double-charge prevention.</p> <p>Functional Requirements: - Authorize, capture, refund, and void payments - Support idempotency keys for all operations - Retry and backoff on failures - Webhook notifications for status changes - Support multiple payment connectors (cards, UPI, wallets)</p> <p>Non-Functional Requirements: - 1\u20135k TPS - Five-nines (99.999%) availability on core path - PCI DSS compliance - Low-latency (p99 &lt; 200ms)</p> <p>Assumptions: - All payment operations are atomic and idempotent - Outbox/event sourcing for reliable notifications</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Payment%20Gateway%20%28Cards-UPI%29%20with%20Idempotency/#2-high-level-architecture","title":"2. High-Level Architecture","text":"<p>Components: - API Gateway: Receives payment requests, validates input - Idempotency Store: Tracks idempotency keys and operation results - Orchestrator (State Machine): Manages payment state transitions - Acquirer Connectors: Integrates with card/UPI networks - Event Outbox: Stores events for reliable webhook delivery - Webhook Dispatcher: Sends notifications to clients - Storage: Postgres (core), Redis (idempotency), S3 (receipts)</p> <p>Architecture Diagram: <pre><code> [API] -&gt; [Idempotency Store] -&gt; [Orchestrator] -&gt; [Acquirer] -&gt; [Outbox] -&gt; [Webhook]\n</code></pre></p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Payment%20Gateway%20%28Cards-UPI%29%20with%20Idempotency/#3-data-model-state-machine","title":"3. Data Model &amp; State Machine","text":"<ul> <li>Payment: { id, amount, currency, status, idempotency_key, ... }</li> <li>Idempotency Key: { key, operation, result, expiry }</li> <li>Event: { id, type, payload, status }</li> <li>State Machine: States: INIT \u2192 AUTHORIZED \u2192 CAPTURED/VOIDED \u2192 REFUNDED</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Payment%20Gateway%20%28Cards-UPI%29%20with%20Idempotency/#4-key-workflows","title":"4. Key Workflows","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Payment%20Gateway%20%28Cards-UPI%29%20with%20Idempotency/#a-payment-request","title":"a) Payment Request","text":"<ol> <li>API receives request with idempotency key</li> <li>Checks idempotency store; if present, returns stored result</li> <li>If new, creates payment, stores key, starts orchestrator</li> <li>Orchestrator transitions state (authorize, capture, etc.)</li> <li>On each state change, writes event to outbox</li> <li>Webhook dispatcher delivers notifications</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Payment%20Gateway%20%28Cards-UPI%29%20with%20Idempotency/#b-retry-backoff","title":"b) Retry &amp; Backoff","text":"<ol> <li>On failure, orchestrator persists state and schedules retry</li> <li>Idempotency key ensures no double-processing</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Payment%20Gateway%20%28Cards-UPI%29%20with%20Idempotency/#c-webhook-delivery","title":"c) Webhook Delivery","text":"<ol> <li>Outbox stores events until acknowledged by client</li> <li>Retries with exponential backoff</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Payment%20Gateway%20%28Cards-UPI%29%20with%20Idempotency/#5-scaling-reliability","title":"5. Scaling &amp; Reliability","text":"<ul> <li>Stateless API: Horizontally scalable</li> <li>Idempotency Store: Redis for low-latency lookups</li> <li>Outbox Pattern: Guarantees at-least-once delivery</li> <li>Failover: Use leader election for orchestrator</li> <li>Monitoring: Track double-charge, latency, webhook failures</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Payment%20Gateway%20%28Cards-UPI%29%20with%20Idempotency/#6-risk-points-mitigations","title":"6. Risk Points &amp; Mitigations","text":"<ul> <li>Double-charge: Idempotency key scoped to operation</li> <li>Lost Webhooks: Outbox with retries</li> <li>Partial State: Persist state transitions atomically</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Payment%20Gateway%20%28Cards-UPI%29%20with%20Idempotency/#7-best-practices-extensions","title":"7. Best Practices &amp; Extensions","text":"<ul> <li>Use UUIDs for idempotency keys</li> <li>Encrypt sensitive data at rest and in transit</li> <li>PCI DSS compliance for card data</li> <li>Support for SCA (Strong Customer Authentication)</li> <li>Integrate with fraud detection</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Payment%20Gateway%20%28Cards-UPI%29%20with%20Idempotency/#8-example-pseudocode-idempotency-check","title":"8. Example Pseudocode (Idempotency Check)","text":"<pre><code>def process_payment(request):\n    key = request.idempotency_key\n    result = idempotency_store.get(key)\n    if result:\n        return result\n    # Process payment\n    result = orchestrate_payment(request)\n    idempotency_store.set(key, result)\n    return result\n</code></pre>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Payment%20Gateway%20%28Cards-UPI%29%20with%20Idempotency/#9-references","title":"9. References","text":"<ul> <li>Idempotency in Payments</li> <li>Outbox Pattern</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Portfolio%20Risk%20Calculation/","title":"Portfolio Risk Calculation","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Portfolio%20Risk%20Calculation/#portfolio-risk-calculation-intraday-vargreeks","title":"Portfolio Risk Calculation (Intraday VaR/Greeks)","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Portfolio%20Risk%20Calculation/#1-problem-statement-requirements","title":"1. Problem Statement &amp; Requirements","text":"<p>Design a scalable, low-latency system to compute portfolio risk metrics (VaR, Greeks) in real time as market data updates.</p> <p>Functional Requirements: - Recalculate Greeks/VaR on market updates - Support portfolio hierarchies (accounts, desks, books) - SLAs per desk (customizable latency/accuracy) - Expose risk metrics via API/UI - Support ad-hoc and scheduled risk runs</p> <p>Non-Functional Requirements: - 10\u2013100k positions per run - 10\u2013100 updates/sec - p99 &lt; 1\u20132s for risk recompute - High availability, auditability</p> <p>Assumptions: - Positions and market data are available in real time - Compute grid is available for parallelization</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Portfolio%20Risk%20Calculation/#2-high-level-architecture","title":"2. High-Level Architecture","text":"<p>Components: - Market Data Feed: Real-time price updates - Change Data Subscription: Triggers risk recompute on price/position change - Dependency Graph Engine: Tracks which portfolios/positions are affected - Sensitivity Engine: Computes Greeks, VaR, and other risk metrics - Compute Grid: Parallelizes risk calculations - Result Cache: Stores latest risk results for fast queries - API/UI: Exposes risk metrics to users - Storage: RDBMS for positions, Redis/Pinot for results, S3 for artifacts</p> <p>Architecture Diagram: <pre><code> [Market Data] -&gt; [Dependency Graph] -&gt; [Sensitivity Engine] -&gt; [Compute Grid] -&gt; [Result Cache/API]\n</code></pre></p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Portfolio%20Risk%20Calculation/#3-data-model-dependency-management","title":"3. Data Model &amp; Dependency Management","text":"<ul> <li>Position: { id, portfolio_id, instrument, qty, ... }</li> <li>Portfolio: { id, parent_id, ... }</li> <li>Dependency Graph: Maps which positions/portfolios are affected by a price change</li> <li>Risk Result: { portfolio_id, VaR, Greeks, timestamp, ... }</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Portfolio%20Risk%20Calculation/#4-key-workflows","title":"4. Key Workflows","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Portfolio%20Risk%20Calculation/#a-real-time-risk-recompute","title":"a) Real-time Risk Recompute","text":"<ol> <li>Market data update triggers change-data event</li> <li>Dependency graph engine determines affected portfolios/positions</li> <li>Sensitivity engine computes new risk metrics (VaR, Greeks)</li> <li>Results cached and published to API/UI</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Portfolio%20Risk%20Calculation/#b-ad-hocscheduled-risk-run","title":"b) Ad-hoc/Scheduled Risk Run","text":"<ol> <li>User/API requests risk run for a portfolio or desk</li> <li>System fetches latest positions and market data</li> <li>Runs sensitivity engine, caches and returns results</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Portfolio%20Risk%20Calculation/#c-result-storage-audit","title":"c) Result Storage &amp; Audit","text":"<ol> <li>Results written to Redis/Pinot for fast queries</li> <li>Artifacts (full risk reports) archived to S3</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Portfolio%20Risk%20Calculation/#5-scaling-reliability","title":"5. Scaling &amp; Reliability","text":"<ul> <li>Parallelization: Use compute grid (Kubernetes, Spark, Ray) for large portfolios</li> <li>DAG Scheduling: Only recompute affected nodes in dependency graph</li> <li>Memoization: Cache intermediate results to avoid redundant computation</li> <li>Monitoring: Track latency, error rates, compute utilization</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Portfolio%20Risk%20Calculation/#6-bottlenecks-mitigations","title":"6. Bottlenecks &amp; Mitigations","text":"<ul> <li>Fan-out Recompute: Use DAG to minimize recompute scope</li> <li>Data Staleness: Use event-driven updates for freshness</li> <li>Compute Spikes: Autoscale compute grid</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Portfolio%20Risk%20Calculation/#7-best-practices-extensions","title":"7. Best Practices &amp; Extensions","text":"<ul> <li>Use vectorized math libraries for speed</li> <li>Audit logs for all risk runs</li> <li>Support what-if scenarios and stress tests</li> <li>Integrate with trade capture and P&amp;L systems</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Portfolio%20Risk%20Calculation/#8-example-pseudocode-dependency-graph","title":"8. Example Pseudocode (Dependency Graph)","text":"<pre><code>class DependencyGraph:\n    def __init__(self):\n        self.edges = defaultdict(set)  # symbol -&gt; set(portfolio_ids)\n    def add_dependency(self, symbol, portfolio_id):\n        self.edges[symbol].add(portfolio_id)\n    def get_affected(self, symbol):\n        return self.edges.get(symbol, set())\n</code></pre>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Portfolio%20Risk%20Calculation/#9-references","title":"9. References","text":"<ul> <li>VaR Calculation</li> <li>DAG Scheduling</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20Chat%20%2B%20Notifications/","title":"Real-time Chat + Notifications","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20Chat%20%2B%20Notifications/#1-problem-statement-scope","title":"1. Problem Statement &amp; Scope","text":"<p>Design a scalable, low-latency chat platform supporting 1:1 and group messaging, user presence, read receipts, and push notifications. The system must handle millions of concurrent users, guarantee message delivery, and provide a seamless experience across devices.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20Chat%20%2B%20Notifications/#2-requirements","title":"2. Requirements","text":"<ul> <li>Functional Requirements:<ul> <li>Send/receive messages in real time (1:1, group).</li> <li>Show user presence (online/offline/away).</li> <li>Read receipts and typing indicators.</li> <li>Persist chat history and support search.</li> <li>Push notifications for offline users.</li> </ul> </li> <li>Non-Functional Requirements:<ul> <li>Scalability: Millions of concurrent users, 100k+ QPS.</li> <li>Low Latency: &lt;100ms end-to-end delivery.</li> <li>Reliability: No message loss, at-least-once delivery.</li> <li>Security: End-to-end encryption (optional).</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20Chat%20%2B%20Notifications/#3-capacity-estimation","title":"3. Capacity Estimation","text":"<ul> <li>Concurrent Users: 10M.</li> <li>Message Rate: 100k/sec peak.</li> <li>Storage: 1B messages/day, 1KB/message = 1TB/day.</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20Chat%20%2B%20Notifications/#4-high-level-architecture-diagram","title":"4. High-Level Architecture Diagram","text":"<p>Code snippet</p> <p><code>graph TD     A[Client] --&gt; B[WebSocket Gateway];     B --&gt; C[Presence Service];     B --&gt; D[Chat Service];     D --&gt; E[Message Store (Cassandra/ScyllaDB)];     D --&gt; F[Kafka/Event Bus];     F --&gt; G[Fan-out Service];     G --&gt; H[Push Notification Service];     D --&gt; I[Search Service];     C --&gt; J[Presence DB/Cache];</code></p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20Chat%20%2B%20Notifications/#5-data-schema-api-design","title":"5. Data Schema &amp; API Design","text":"<ul> <li>API:<ul> <li>WebSocket: <code>send_message</code>, <code>receive_message</code>, <code>presence_update</code>, <code>typing</code>, etc.</li> <li>REST: <code>GET /v1/conversations</code>, <code>GET /v1/messages</code>, etc.</li> </ul> </li> <li>Data Models:<ul> <li>Messages: <code>message_id, conversation_id, sender_id, content, timestamp, status</code></li> <li>Conversations: <code>conversation_id, participants, last_message_id, ...</code></li> <li>Presence: <code>user_id, status, last_seen</code></li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20Chat%20%2B%20Notifications/#6-detailed-component-breakdown","title":"6. Detailed Component Breakdown","text":"<ul> <li>WebSocket Gateway: Maintains persistent connections, authenticates users, routes messages to Chat Service.</li> <li>Presence Service: Tracks user status, updates presence in real time, and notifies interested clients.</li> <li>Chat Service: Core logic for message delivery, persistence, and fan-out. Handles message ordering and deduplication.</li> <li>Message Store: Scalable NoSQL DB (Cassandra/ScyllaDB) for chat history.</li> <li>Kafka/Event Bus: Decouples message ingestion from fan-out and notification.</li> <li>Fan-out Service: Delivers messages to all recipients (online/offline), triggers push notifications as needed.</li> <li>Push Notification Service: Integrates with APNs/FCM for mobile push.</li> <li>Search Service: Indexes messages for fast retrieval.</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20Chat%20%2B%20Notifications/#7-end-to-end-flow-message-send-delivery","title":"7. End-to-End Flow (Message Send &amp; Delivery)","text":"<p>Code snippet</p> <p>`sequenceDiagram     participant UserA     participant Gateway     participant ChatSvc     participant MessageStore     participant Kafka     participant Fanout     participant PushSvc     participant UserB</p> <pre><code>UserA-&gt;&gt;Gateway: send_message\nGateway-&gt;&gt;ChatSvc: Forward message\nChatSvc-&gt;&gt;MessageStore: Persist message\nChatSvc-&gt;&gt;Kafka: Publish event\nKafka-&gt;&gt;Fanout: Consume event\nFanout-&gt;&gt;UserB: Deliver message (if online)\nFanout-&gt;&gt;PushSvc: Push notification (if offline)\nPushSvc--&gt;&gt;UserB: Mobile push\nUserB-&gt;&gt;Gateway: ack/read_receipt\nGateway-&gt;&gt;ChatSvc: Update status\n</code></pre> <p>`</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20Chat%20%2B%20Notifications/#8-bottlenecks-fault-tolerance-and-trade-offs","title":"8. Bottlenecks, Fault Tolerance, and Trade-offs","text":"<ul> <li>Bottleneck: WebSocket Gateway:<ul> <li>Horizontally scalable, stateless. Use sticky sessions or consistent hashing.</li> </ul> </li> <li>Message Store:<ul> <li>NoSQL DB for high write throughput. Partition by conversation_id.</li> </ul> </li> <li>Fan-out:<ul> <li>Kafka decouples ingestion from delivery. Enables retries and at-least-once delivery.</li> </ul> </li> <li>Trade-offs:<ul> <li>Eventual consistency for presence/read receipts. Strong consistency for message delivery.</li> <li>Push notifications may be delayed by mobile OS.</li> </ul> </li> </ul> <p>This architecture is used by leading chat apps (WhatsApp, Slack, Messenger) for reliability and scale.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20Fraud%20Detection/","title":"Real time Fraud Detection","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20Fraud%20Detection/#real-time-fraud-detection-rules-ml","title":"Real-time Fraud Detection (Rules + ML)","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20Fraud%20Detection/#1-problem-statement-requirements","title":"1. Problem Statement &amp; Requirements","text":"<p>Design a real-time fraud detection system for financial transactions, combining rules and ML models, with async review and high throughput.</p> <p>Functional Requirements: - Score transactions inline (real-time) - Combine rules engine and ML model for decisioning - Support async review queue for flagged cases - Integrate with feature store for real-time features - Emit decisions to downstream systems (Kafka, logs)</p> <p>Non-Functional Requirements: - 5\u201310k TPS online scoring - p99 &lt; 50ms latency - High availability, explainability, auditability</p> <p>Assumptions: - Features are precomputed and available in online store - Model serving supports A/B testing and versioning</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20Fraud%20Detection/#2-high-level-architecture","title":"2. High-Level Architecture","text":"<p>Components: - Transaction Ingest: Receives and validates transactions - Feature Fetcher: Retrieves features from online store (Redis/Scylla) - Rules Engine: Applies business rules (e.g., velocity, blacklists) - Model Serving: Scores transaction using ML model (A/B, canary) - Decision Engine: Combines rules/model, makes allow/challenge/deny decision - Case Service: Queues flagged cases for manual review - Event Emitter: Publishes results to Kafka/logs - Storage: Online (Redis/Scylla), offline (Parquet/warehouse)</p> <p>Architecture Diagram: <pre><code> [Tx] -&gt; [Feature Fetch] -&gt; [Rules Engine] -&gt; [Model] -&gt; [Decision] -&gt; [Case/Log]\n</code></pre></p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20Fraud%20Detection/#3-data-model-feature-store","title":"3. Data Model &amp; Feature Store","text":"<ul> <li>Transaction: { id, user_id, amount, ts, ... }</li> <li>Feature Vector: { user_id, avg_txn_amt, velocity, ... }</li> <li>Decision: { tx_id, score, action, reason, model_version }</li> <li>Case: { tx_id, features, decision, status }</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20Fraud%20Detection/#4-key-workflows","title":"4. Key Workflows","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20Fraud%20Detection/#a-real-time-scoring","title":"a) Real-time Scoring","text":"<ol> <li>Transaction arrives at ingest</li> <li>Feature fetcher retrieves features</li> <li>Rules engine applies business logic</li> <li>Model serving scores transaction</li> <li>Decision engine combines results</li> <li>If flagged, case is queued for review</li> <li>Emit decision to Kafka/logs</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20Fraud%20Detection/#b-async-review","title":"b) Async Review","text":"<ol> <li>Analyst reviews flagged cases in case service</li> <li>Updates status, triggers notifications</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20Fraud%20Detection/#c-model-ab-testing","title":"c) Model A/B Testing","text":"<ol> <li>Model serving supports multiple versions</li> <li>Traffic split for A/B or canary</li> <li>Metrics collected for evaluation</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20Fraud%20Detection/#5-scaling-reliability","title":"5. Scaling &amp; Reliability","text":"<ul> <li>Horizontal Scaling: Stateless services, scale by QPS</li> <li>Feature Store: Redis/Scylla for low-latency fetch</li> <li>Model Serving: Containerized, autoscaled</li> <li>Monitoring: Latency, false positive/negative rates, model drift</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20Fraud%20Detection/#6-trade-offs-alternatives","title":"6. Trade-offs &amp; Alternatives","text":"<ul> <li>Consistency: Point-in-time correctness for features</li> <li>Latency vs Accuracy: More features/models = higher latency</li> <li>Explainability: Rules are explainable, models less so</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20Fraud%20Detection/#7-best-practices-extensions","title":"7. Best Practices &amp; Extensions","text":"<ul> <li>Use feature store for online/offline parity</li> <li>Audit logs for all decisions</li> <li>Support for real-time and batch scoring</li> <li>Integrate with feedback loop for model retraining</li> <li>Add explainability and reason codes</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20Fraud%20Detection/#8-example-pseudocode-decision-engine","title":"8. Example Pseudocode (Decision Engine)","text":"<pre><code>def score_transaction(tx):\n    features = fetch_features(tx.user_id)\n    rule_result = rules_engine(tx, features)\n    model_score = model_serve(tx, features)\n    if rule_result == 'deny' or model_score &lt; 0.2:\n        action = 'deny'\n    elif rule_result == 'challenge' or model_score &lt; 0.5:\n        action = 'challenge'\n    else:\n        action = 'allow'\n    return action\n</code></pre>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20Fraud%20Detection/#9-references","title":"9. References","text":"<ul> <li>Feature Store</li> <li>Fraud Detection at Scale</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20Market%20Data%20Fan-out/","title":"Real time Market Data Fan out","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20Market%20Data%20Fan-out/#real-time-market-data-fan-out-ticks-thousands-of-clients","title":"Real-time Market Data Fan-out (Ticks \u2192 Thousands of Clients)","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20Market%20Data%20Fan-out/#1-problem-statement-requirements","title":"1. Problem Statement &amp; Requirements","text":"<p>Design a real-time market data fan-out system to ingest, normalize, and distribute high-frequency financial tick data to thousands of downstream clients and services.</p> <p>Functional Requirements: - Ingest vendor UDP/TCP feeds (multiple formats) - Normalize and partition by symbol/instrument - Multicast to internal services and external clients (websockets, APIs) - Per-symbol and per-client filtering - Handle slow consumers gracefully (drop, backpressure) - Hot/cold storage for ticks</p> <p>Non-Functional Requirements: - 1\u20135M messages/sec ingress - 1\u201310k downstream clients - p99 &lt; 5\u201320ms end-to-end latency - High availability, zero data loss on core path</p> <p>Assumptions: - Kernel bypass (DPDK/XDP) optional for ultra-low latency - Internal network is high-throughput, low-latency</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20Market%20Data%20Fan-out/#2-high-level-architecture","title":"2. High-Level Architecture","text":"<p>Components: - Feed Handler: Parses vendor UDP/TCP feeds, normalizes to internal format - Normalizer: Cleanses, enriches, and partitions data by symbol - Broker: High-throughput message bus (Kafka/Pulsar/Disruptor) - Fan-out Hubs: Per-client or per-group ring buffers for downstream consumers - Websocket/API Edge: Exposes data to external clients - Slow Consumer Handler: Monitors lag, applies drop/backpressure - Storage: Hot cache (Redis/Memcached), cold store (Parquet+S3/Iceberg, ClickHouse/Pinot)</p> <p>Architecture Diagram: <pre><code> [Feed Handler] -&gt; [Normalizer] -&gt; [Broker] -&gt; [Fan-out Hubs] -&gt; [WS/API Edge]\n                                             |\n                                             v\n                                         [Storage]\n</code></pre></p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20Market%20Data%20Fan-out/#3-data-model-partitioning","title":"3. Data Model &amp; Partitioning","text":"<ul> <li>Tick Message: { symbol, price, size, ts, ... }</li> <li>Partitioning: By symbol (topic/partition in broker)</li> <li>Per-client Buffer: Ring buffer or queue for each client/consumer group</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20Market%20Data%20Fan-out/#4-key-workflows","title":"4. Key Workflows","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20Market%20Data%20Fan-out/#a-ingestion-normalization","title":"a) Ingestion &amp; Normalization","text":"<ol> <li>Feed Handler receives UDP/TCP packets</li> <li>Parses and normalizes to internal tick format</li> <li>Passes to Normalizer for cleansing, enrichment</li> <li>Publishes to Broker (partitioned by symbol)</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20Market%20Data%20Fan-out/#b-fan-out-to-clients","title":"b) Fan-out to Clients","text":"<ol> <li>Fan-out Hub subscribes to relevant partitions/topics</li> <li>Maintains per-client ring buffer (fixed size)</li> <li>Applies per-symbol and per-client filters</li> <li>Sends to client via websocket/API</li> <li>If client lags, applies drop policy or disconnects</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20Market%20Data%20Fan-out/#c-storage","title":"c) Storage","text":"<ol> <li>Hot ticks cached in Redis/Mem for fast access</li> <li>Cold ticks written to Parquet+S3/Iceberg or OLAP DB</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20Market%20Data%20Fan-out/#5-scaling-reliability","title":"5. Scaling &amp; Reliability","text":"<ul> <li>Horizontal Scaling: Multiple Feed Handlers, Normalizers, Fan-out Hubs</li> <li>Partitioning: By symbol for parallelism</li> <li>Backpressure: Broker and ring buffers apply backpressure to slow consumers</li> <li>Zero-copy: Use direct buffers, kernel bypass for low latency</li> <li>Monitoring: Track lag, dropped messages, latency, throughput</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20Market%20Data%20Fan-out/#6-bottlenecks-mitigations","title":"6. Bottlenecks &amp; Mitigations","text":"<ul> <li>GC Pauses: Use off-heap buffers, fixed pools</li> <li>Buffer Bloat: Fixed-size ring buffers, drop policy</li> <li>Nagle/Coalesce: Disable Nagle, tune kernel net (RPS/RFS)</li> <li>Slow Consumers: Drop or disconnect laggards</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20Market%20Data%20Fan-out/#7-best-practices-extensions","title":"7. Best Practices &amp; Extensions","text":"<ul> <li>Use blue/green deployment for zero downtime</li> <li>Partition by symbol for scalability</li> <li>Kernel bypass (DPDK/XDP) for ultra-low latency</li> <li>Per-client metrics and alerting</li> <li>Integrate with risk/analytics systems</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20Market%20Data%20Fan-out/#8-example-pseudocode-fan-out-hub","title":"8. Example Pseudocode (Fan-out Hub)","text":"<pre><code>class FanoutHub:\n    def __init__(self):\n        self.clients = {}\n    def subscribe(self, client, symbols):\n        self.clients[client] = {'symbols': set(symbols), 'buffer': RingBuffer(1000)}\n    def on_tick(self, tick):\n        for client, info in self.clients.items():\n            if tick.symbol in info['symbols']:\n                if not info['buffer'].full():\n                    info['buffer'].push(tick)\n                else:\n                    # Drop or disconnect\n                    pass\n</code></pre>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20Market%20Data%20Fan-out/#9-references","title":"9. References","text":"<ul> <li>Kafka for Market Data</li> <li>Zero-Copy Networking</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20P%26L%20and%20Exposure%20Dashboard/","title":"Real time P&L and Exposure Dashboard","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20P%26L%20and%20Exposure%20Dashboard/#real-time-pl-exposure-dashboard","title":"Real-time P&amp;L &amp; Exposure Dashboard","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20P%26L%20and%20Exposure%20Dashboard/#1-problem-statement-requirements","title":"1. Problem Statement &amp; Requirements","text":"<p>Design a real-time dashboard for P&amp;L and exposure, aggregating tick data and positions for books, traders, and desks.</p> <p>Functional Requirements: - Ingest tick updates and position changes - Compute live P&amp;L and exposures per book/trader - Support drill-down and aggregation by hierarchy - Serve data via API and websocket for dashboards - Pre-materialize views for fast queries</p> <p>Non-Functional Requirements: - 100k updates/sec - Fan-out to 1k+ users - p99 &lt; 100ms for dashboard queries - High availability, auditability</p> <p>Assumptions: - Tick and position data are available in real time - OLAP store for aggregates</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20P%26L%20and%20Exposure%20Dashboard/#2-high-level-architecture","title":"2. High-Level Architecture","text":"<p>Components: - Tick Ingest: Receives real-time price updates - Position Service: Tracks positions per book/trader - Stream Processor: Aggregates P&amp;L and exposures (Flink/Spark) - Aggregation Cache: OLAP DB (Pinot/ClickHouse) for pre-materialized views - API Service: Serves queries and websocket updates - Websocket Gateway: Pushes updates to dashboards</p> <p>Architecture Diagram: <pre><code> [Tick Ingest] + [Position Service] -&gt; [Stream Processor] -&gt; [Aggregation Cache] -&gt; [API/Websocket]\n</code></pre></p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20P%26L%20and%20Exposure%20Dashboard/#3-data-model-aggregation","title":"3. Data Model &amp; Aggregation","text":"<ul> <li>Tick: { symbol, price, ts }</li> <li>Position: { book_id, symbol, qty, ... }</li> <li>P&amp;L Aggregate: { book_id, pnl, exposure, ts }</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20P%26L%20and%20Exposure%20Dashboard/#4-key-workflows","title":"4. Key Workflows","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20P%26L%20and%20Exposure%20Dashboard/#a-real-time-aggregation","title":"a) Real-time Aggregation","text":"<ol> <li>Tick and position updates ingested</li> <li>Stream processor joins ticks with positions</li> <li>Computes P&amp;L and exposures per book/trader</li> <li>Writes aggregates to OLAP cache</li> <li>API/websocket serves pre-materialized views</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20P%26L%20and%20Exposure%20Dashboard/#b-drill-down-query","title":"b) Drill-down &amp; Query","text":"<ol> <li>User queries dashboard for book/trader</li> <li>API fetches aggregates from OLAP</li> <li>Websocket pushes updates for live view</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20P%26L%20and%20Exposure%20Dashboard/#5-scaling-reliability","title":"5. Scaling &amp; Reliability","text":"<ul> <li>Sharding: By symbol/book for parallelism</li> <li>Pre-materialization: OLAP DB for low-latency queries</li> <li>Websocket Fan-out: Scalable push to 1k+ users</li> <li>Monitoring: Latency, update lag, user connections</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20P%26L%20and%20Exposure%20Dashboard/#6-bottlenecks-mitigations","title":"6. Bottlenecks &amp; Mitigations","text":"<ul> <li>Hot Symbols: Shard and rebalance to avoid skew</li> <li>OLAP Write Latency: Use batch writes, partitioning</li> <li>Websocket Scale: Use pub/sub and connection pooling</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20P%26L%20and%20Exposure%20Dashboard/#7-best-practices-extensions","title":"7. Best Practices &amp; Extensions","text":"<ul> <li>Use time-windowed aggregations for P&amp;L</li> <li>Audit logs for all updates</li> <li>Support for historical replay and what-if analysis</li> <li>Integrate with risk and trade capture systems</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20P%26L%20and%20Exposure%20Dashboard/#8-example-pseudocode-aggregation","title":"8. Example Pseudocode (Aggregation)","text":"<pre><code>def aggregate_pnl(ticks, positions):\n    pnl = defaultdict(float)\n    for tick in ticks:\n        for pos in positions:\n            if pos.symbol == tick.symbol:\n                pnl[pos.book_id] += (tick.price - pos.entry_price) * pos.qty\n    return pnl\n</code></pre>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Real-time%20P%26L%20and%20Exposure%20Dashboard/#9-references","title":"9. References","text":"<ul> <li>OLAP for Real-time Analytics</li> <li>Streaming Aggregation</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Restaurant%20Delivery%20%28Match%20Orders%20%E2%86%94%20Riders%29/","title":"Restaurant Delivery (Match Orders \u2194 Riders)","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Restaurant%20Delivery%20%28Match%20Orders%20%E2%86%94%20Riders%29/#1-problem-statement-scope","title":"1. Problem Statement &amp; Scope","text":"<p>Design a scalable backend for a food delivery platform that matches orders with available riders in real time. The system must optimize for fast delivery, live tracking, dynamic pricing, and high availability during peak demand.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Restaurant%20Delivery%20%28Match%20Orders%20%E2%86%94%20Riders%29/#2-requirements","title":"2. Requirements","text":"<ul> <li>Functional Requirements:<ul> <li>Ingest real-time rider locations (GPS updates).</li> <li>Accept and manage new food orders.</li> <li>Assign best rider to each order using a scoring model (ETA, proximity, load).</li> <li>Live tracking for users and restaurants.</li> <li>Dynamic/surge pricing based on demand.</li> </ul> </li> <li>Non-Functional Requirements:<ul> <li>Scalability: 1M+ orders/day, 100k+ concurrent riders.</li> <li>Low Latency: &lt;1s for assignment.</li> <li>Reliability: No lost orders, high uptime.</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Restaurant%20Delivery%20%28Match%20Orders%20%E2%86%94%20Riders%29/#3-capacity-estimation","title":"3. Capacity Estimation","text":"<ul> <li>Orders: 1M/day (~12/sec avg, 1k/sec peak).</li> <li>Riders: 100k active.</li> <li>Location Updates: 1/min/rider = 100k/min.</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Restaurant%20Delivery%20%28Match%20Orders%20%E2%86%94%20Riders%29/#4-high-level-architecture-diagram","title":"4. High-Level Architecture Diagram","text":"<p>Code snippet</p> <p><code>graph TD     A[User App] --&gt; B[Order Service];     C[Rider App] --&gt; D[Telemetry Service];     B --&gt; E[Assignment/Dispatch Service];     D --&gt; E;     E --&gt; F[Geo-Index Service];     E --&gt; G[ETA Service];     E --&gt; H[Pricing Service];     E --&gt; I[Orders DB];     E --&gt; J[Rider Profile DB];     E --&gt; K[Notification Service];</code></p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Restaurant%20Delivery%20%28Match%20Orders%20%E2%86%94%20Riders%29/#5-data-schema-api-design","title":"5. Data Schema &amp; API Design","text":"<ul> <li>API:<ul> <li><code>POST /v1/orders</code>: Place new order.</li> <li><code>POST /v1/riders/location</code>: Update rider location.</li> <li><code>GET /v1/orders/{order_id}/status</code>: Track order.</li> </ul> </li> <li>Data Models:<ul> <li>Orders: <code>order_id, user_id, restaurant_id, status, assigned_rider, ...</code></li> <li>Riders: <code>rider_id, location, status, capacity, ...</code></li> <li>Geo-Index: Spatial index for fast proximity search.</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Restaurant%20Delivery%20%28Match%20Orders%20%E2%86%94%20Riders%29/#6-detailed-component-breakdown","title":"6. Detailed Component Breakdown","text":"<ul> <li>Order Service: Handles order creation, status, and user notifications.</li> <li>Telemetry Service: Ingests and stores real-time rider locations.</li> <li>Assignment/Dispatch Service: Runs matching algorithm, assigns riders, and triggers notifications.</li> <li>Geo-Index Service: Maintains spatial index for fast nearest-neighbor queries.</li> <li>ETA Service: Estimates delivery times using traffic, distance, and rider load.</li> <li>Pricing Service: Calculates dynamic pricing based on demand/supply.</li> <li>Notification Service: Sends updates to users, riders, and restaurants.</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Restaurant%20Delivery%20%28Match%20Orders%20%E2%86%94%20Riders%29/#7-end-to-end-flow-order-assignment","title":"7. End-to-End Flow (Order Assignment)","text":"<p>Code snippet</p> <p>`sequenceDiagram     participant User     participant OrderSvc     participant Telemetry     participant Dispatch     participant GeoIndex     participant Rider     participant Notification</p> <pre><code>User-&gt;&gt;OrderSvc: Place order\nOrderSvc-&gt;&gt;Dispatch: New order event\nTelemetry-&gt;&gt;Dispatch: Rider location update\nDispatch-&gt;&gt;GeoIndex: Find nearby riders\nGeoIndex--&gt;&gt;Dispatch: Candidate riders\nDispatch-&gt;&gt;Dispatch: Score &amp; select best rider\nDispatch-&gt;&gt;Rider: Assign order\nDispatch-&gt;&gt;OrderSvc: Update order status\nDispatch-&gt;&gt;Notification: Notify user/restaurant\nRider-&gt;&gt;OrderSvc: Accept/reject\nOrderSvc-&gt;&gt;Dispatch: Update status\n</code></pre> <p>`</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Restaurant%20Delivery%20%28Match%20Orders%20%E2%86%94%20Riders%29/#8-bottlenecks-fault-tolerance-and-trade-offs","title":"8. Bottlenecks, Fault Tolerance, and Trade-offs","text":"<ul> <li>Bottleneck: Geo-Index:<ul> <li>Use in-memory spatial index (e.g., Redis Geo) for fast lookups. Partition by city/region.</li> </ul> </li> <li>Assignment Algorithm:<ul> <li>Greedy (fast) vs. batch (optimal). Greedy is simple, batch is more efficient but adds latency.</li> </ul> </li> <li>Reliability:<ul> <li>All state changes are persisted. Use retries and dead-letter queues for failed assignments.</li> </ul> </li> <li>Trade-offs:<ul> <li>Greedy matching is fast but may be suboptimal. Batch matching is optimal but slower.</li> <li>Real-time tracking is resource-intensive but improves user experience.</li> </ul> </li> </ul> <p>This design is used by Uber Eats, DoorDash, and Swiggy for real-time order-to-rider matching.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Search%20Autocomplete%20with%20Typo%20Tolerance/","title":"Search Autocomplete with Typo Tolerance","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Search%20Autocomplete%20with%20Typo%20Tolerance/#search-autocomplete-with-typo-tolerance","title":"Search Autocomplete with Typo Tolerance","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Search%20Autocomplete%20with%20Typo%20Tolerance/#1-problem-statement-requirements","title":"1. Problem Statement &amp; Requirements","text":"<p>Design a high-performance, typo-tolerant search autocomplete system for a web-scale consumer application (e.g., e-commerce, search engine).</p> <p>Functional Requirements: - Suggest completions for user input in real time (sub-50ms latency) - Support prefix and fuzzy (typo-tolerant) matching - Rank suggestions by popularity, recency, and context - Handle large vocabularies (1\u201310M+ tokens) - Support multi-language and Unicode</p> <p>Non-Functional Requirements: - 10\u201350k QPS sustained - High availability (99.99%) - Horizontal scalability - Low memory footprint per node</p> <p>Assumptions: - Data is periodically rebuilt offline and loaded into memory - Popularity/CTR stats are updated asynchronously</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Search%20Autocomplete%20with%20Typo%20Tolerance/#2-high-level-architecture","title":"2. High-Level Architecture","text":"<p>Components: - Frontend API: Receives user queries, returns suggestions - Autocomplete Engine: Performs prefix/fuzzy lookup and ranking - Index Builder: Offline job to build DAWG/Trie and BK-tree - Popularity Service: Tracks CTR, updates ranking weights - Cache Layer: Hot cache for most frequent queries - Data Store: Stores raw tokens, stats, and index snapshots</p> <p>Architecture Diagram: <pre><code>        +-----------+         +-------------------+         +-----------------+\nUser -&gt; | Frontend  | &lt;-----&gt; | Autocomplete API  | &lt;-----&gt; | Autocomplete    |\n        +-----------+         +-------------------+         | Engine (Trie/   |\n                                                           | BK-tree/Ranker) |\n                                                           +-----------------+\n                                                                 ^\n                                                                 |\n        +-------------------+         +-----------------+        |\n        | Popularity/CTR    | &lt;-----&gt; | Index Builder   | &lt;------+\n        | Stats Service     |         +-----------------+\n        +-------------------+\n</code></pre></p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Search%20Autocomplete%20with%20Typo%20Tolerance/#3-data-model-indexing","title":"3. Data Model &amp; Indexing","text":"<ul> <li>Trie/DAWG: For fast prefix search; each node stores child pointers, end-of-word, and popularity counters.</li> <li>BK-tree: For fuzzy/typo-tolerant search (edit distance \u2264 2); each node stores a word and children by edit distance.</li> <li>Popularity Table: Maps tokens to CTR, last access, and context features.</li> <li>Cache: LRU or LFU for hot queries and results.</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Search%20Autocomplete%20with%20Typo%20Tolerance/#4-key-workflows","title":"4. Key Workflows","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Search%20Autocomplete%20with%20Typo%20Tolerance/#a-query-handling","title":"a) Query Handling","text":"<ol> <li>User types query; API receives partial input.</li> <li>Check hot cache for query; if hit, return suggestions.</li> <li>If miss, perform prefix search in Trie/DAWG.</li> <li>If not enough results, expand with fuzzy search (BK-tree, edit distance \u2264 2).</li> <li>Rank results by popularity, recency, and context.</li> <li>Return top-N suggestions (e.g., 10).</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Search%20Autocomplete%20with%20Typo%20Tolerance/#b-index-build-refresh","title":"b) Index Build &amp; Refresh","text":"<ol> <li>Offline job ingests new tokens, builds Trie/DAWG and BK-tree.</li> <li>Serializes index to disk; API nodes reload on update.</li> <li>Popularity stats merged from logs/analytics.</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Search%20Autocomplete%20with%20Typo%20Tolerance/#c-popularityctr-update","title":"c) Popularity/CTR Update","text":"<ol> <li>User selects a suggestion; event sent to Popularity Service.</li> <li>CTR and recency stats updated asynchronously.</li> <li>Periodic batch jobs update ranking weights in index.</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Search%20Autocomplete%20with%20Typo%20Tolerance/#5-scaling-reliability","title":"5. Scaling &amp; Reliability","text":"<ul> <li>Sharding: Partition index by first character or hash for horizontal scaling.</li> <li>Replication: Multiple API nodes for HA; index reload on failover.</li> <li>Cache: Multi-level (local LRU, distributed Redis/Memcached for hot queries).</li> <li>Bulk Rebuild: Blue/green index deployment to avoid downtime.</li> <li>Monitoring: Latency, QPS, cache hit rate, memory usage.</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Search%20Autocomplete%20with%20Typo%20Tolerance/#6-trade-offs-alternatives","title":"6. Trade-offs &amp; Alternatives","text":"<ul> <li>Memory vs Recall: Larger index = more recall, but higher memory. Use pruning and compression.</li> <li>Prefix vs Fuzzy: Fuzzy search is slower; limit edit distance and result count.</li> <li>Popularity Lag: CTR updates are eventually consistent; may lag real-time.</li> <li>Offline vs Online Indexing: Offline is faster and safer; online allows instant updates but is complex.</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Search%20Autocomplete%20with%20Typo%20Tolerance/#7-best-practices-extensions","title":"7. Best Practices &amp; Extensions","text":"<ul> <li>Use DAWG for minimal memory prefix index; BK-tree for fuzzy.</li> <li>Precompute and cache top queries.</li> <li>Use async logging for CTR updates.</li> <li>Support language-specific tokenization and normalization.</li> <li>Integrate with analytics for query trends.</li> <li>Add abuse prevention (rate limits, spam filtering).</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Search%20Autocomplete%20with%20Typo%20Tolerance/#8-example-pseudocode-trie-node","title":"8. Example Pseudocode (Trie Node)","text":"<pre><code>class TrieNode:\n    def __init__(self):\n        self.children = {}\n        self.is_end = False\n        self.popularity = 0\n\ndef insert(root, word, popularity):\n    node = root\n    for c in word:\n        if c not in node.children:\n            node.children[c] = TrieNode()\n        node = node.children[c]\n    node.is_end = True\n    node.popularity = popularity\n\ndef search_prefix(root, prefix):\n    node = root\n    for c in prefix:\n        if c not in node.children:\n            return []\n        node = node.children[c]\n    return collect_words(node, prefix)\n\ndef collect_words(node, prefix):\n    results = []\n    if node.is_end:\n        results.append((prefix, node.popularity))\n    for c, child in node.children.items():\n        results.extend(collect_words(child, prefix + c))\n    return results\n</code></pre>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Search%20Autocomplete%20with%20Typo%20Tolerance/#9-references","title":"9. References","text":"<ul> <li>DAWG/Trie</li> <li>BK-tree</li> <li>Autocomplete at Scale</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Short-video%20Feed%20%28TikTok-style%29/","title":"Short-video Feed (TikTok-style)","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Short-video%20Feed%20%28TikTok-style%29/#1-problem-statement-scope","title":"1. Problem Statement &amp; Scope","text":"<p>Design a scalable backend for a short-video mobile app (like TikTok) that delivers a personalized, infinite feed. The system must support low-latency video delivery, real-time user interactions, and high availability for millions of users.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Short-video%20Feed%20%28TikTok-style%29/#2-requirements","title":"2. Requirements","text":"<ul> <li>Functional Requirements:<ul> <li>Generate personalized, infinite video feeds per user.</li> <li>Support user interactions: like, comment, share, follow.</li> <li>Real-time event ingestion for engagement signals.</li> <li>Low TTFB (time to first byte) for video playback.</li> </ul> </li> <li>Non-Functional Requirements:<ul> <li>Scalability: 100M+ users, 1M QPS.</li> <li>Low Latency: &lt;100ms feed load, &lt;1s video start.</li> <li>Availability: 99.99% uptime.</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Short-video%20Feed%20%28TikTok-style%29/#3-capacity-estimation","title":"3. Capacity Estimation","text":"<ul> <li>Users: 100M.</li> <li>Videos: 1B+.</li> <li>Feed Requests: 1M QPS.</li> <li>Video Size: 5MB avg, 5PB total.</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Short-video%20Feed%20%28TikTok-style%29/#4-high-level-architecture-diagram","title":"4. High-Level Architecture Diagram","text":"<p>Code snippet</p> <p><code>graph TD     A[User] --&gt; B[API Gateway];     B --&gt; C[Feed Orchestrator];     C --&gt; D[Candidate Generators];     C --&gt; E[Feature Service];     C --&gt; F[Ranker];     F --&gt; G[Filtering/Composition];     G --&gt; H[CDN (Video Assets)];     C --&gt; I[Event Ingestion];     I --&gt; J[Analytics/ML];</code></p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Short-video%20Feed%20%28TikTok-style%29/#5-data-schema-api-design","title":"5. Data Schema &amp; API Design","text":"<ul> <li>API:<ul> <li><code>GET /v1/feed</code>: Fetch personalized feed.</li> <li><code>POST /v1/videos/{video_id}/like</code>: Like a video.</li> <li><code>POST /v1/videos/{video_id}/comment</code>: Comment on a video.</li> </ul> </li> <li>Data Models:<ul> <li>Videos: <code>video_id, uploader_id, url, metadata, features</code></li> <li>Users: <code>user_id, profile, preferences, history</code></li> <li>Events: <code>event_id, user_id, video_id, type, ts</code></li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Short-video%20Feed%20%28TikTok-style%29/#6-detailed-component-breakdown","title":"6. Detailed Component Breakdown","text":"<ul> <li>Feed Orchestrator: Entry point for feed requests. Coordinates candidate generation, ranking, and filtering.</li> <li>Candidate Generators: Generate a pool of potential videos (fresh, trending, followed, etc.).</li> <li>Feature Service: Computes user/video features for ranking (e.g., embeddings, engagement).</li> <li>Ranker: ML model ranks candidates for personalization.</li> <li>Filtering/Composition: Removes seen/ineligible videos, composes final feed.</li> <li>CDN: Delivers video assets with low latency.</li> <li>Event Ingestion: Streams user interactions to analytics/ML for feedback loop.</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Short-video%20Feed%20%28TikTok-style%29/#7-end-to-end-flow-feed-generation","title":"7. End-to-End Flow (Feed Generation)","text":"<p>Code snippet</p> <p>`sequenceDiagram     participant User     participant APIGW     participant Orchestrator     participant CandidateGen     participant FeatureSvc     participant Ranker     participant Filter     participant CDN</p> <pre><code>User-&gt;&gt;APIGW: GET /feed\nAPIGW-&gt;&gt;Orchestrator: Forward request\nOrchestrator-&gt;&gt;CandidateGen: Get candidates\nCandidateGen--&gt;&gt;Orchestrator: Candidate list\nOrchestrator-&gt;&gt;FeatureSvc: Get features\nFeatureSvc--&gt;&gt;Orchestrator: Features\nOrchestrator-&gt;&gt;Ranker: Rank candidates\nRanker--&gt;&gt;Orchestrator: Ranked list\nOrchestrator-&gt;&gt;Filter: Filter/compose\nFilter--&gt;&gt;Orchestrator: Final feed\nOrchestrator-&gt;&gt;APIGW: Return feed\nAPIGW-&gt;&gt;User: Show feed\nUser-&gt;&gt;CDN: Fetch video asset\nCDN--&gt;&gt;User: Stream video\n</code></pre> <p>`</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Short-video%20Feed%20%28TikTok-style%29/#8-bottlenecks-fault-tolerance-and-trade-offs","title":"8. Bottlenecks, Fault Tolerance, and Trade-offs","text":"<ul> <li>Bottleneck: Feed Generation:<ul> <li>Use precomputed feeds for cold start, real-time for active users.</li> </ul> </li> <li>Video Delivery:<ul> <li>CDN ensures low-latency, global delivery. Multi-CDN for redundancy.</li> </ul> </li> <li>Personalization:<ul> <li>ML ranking is compute-intensive. Use feature stores and caching.</li> </ul> </li> <li>Trade-offs:<ul> <li>Real-time feeds are more personalized but costlier. Precomputed feeds are faster but less fresh.</li> </ul> </li> </ul> <p>This design is used by TikTok, Instagram Reels, and YouTube Shorts for scalable, personalized video feeds.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Splitwise-like%20Expense%20Splitter/","title":"Splitwise-like Expense Splitter","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Splitwise-like%20Expense%20Splitter/#1-problem-statement-scope","title":"1. Problem Statement &amp; Scope","text":"<p>Design a system to track group expenses, balances, and simplify debt among users (like Splitwise). The system must support adding expenses, calculating balances, and settling up efficiently, even for large groups and multiple currencies.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Splitwise-like%20Expense%20Splitter/#2-requirements","title":"2. Requirements","text":"<ul> <li>Functional Requirements:<ul> <li>Add expenses (equal, unequal, percent split).</li> <li>Track balances per user and group.</li> <li>Simplify debts (minimize cash flow between users).</li> <li>Settle up (record payments, mark debts as settled).</li> </ul> </li> <li>Non-Functional Requirements:<ul> <li>Scalability: 1M+ users, 100k+ groups.</li> <li>Accuracy: Handle rounding, currency conversion.</li> <li>Reliability: No lost transactions.</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Splitwise-like%20Expense%20Splitter/#3-capacity-estimation","title":"3. Capacity Estimation","text":"<ul> <li>Users: 1M.</li> <li>Groups: 100k.</li> <li>Expenses: 10M/month.</li> <li>Storage: Each expense ~200B, 10M = 2GB/month.</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Splitwise-like%20Expense%20Splitter/#4-high-level-architecture-diagram","title":"4. High-Level Architecture Diagram","text":"<p>Code snippet</p> <p><code>graph TD     A[User App] --&gt; B[API Gateway];     B --&gt; C[Expense Service];     C --&gt; D[Balance Service];     C --&gt; E[Settlement Engine];     C --&gt; F[Notification Service];     D --&gt; G[User DB];     C --&gt; H[Group DB];     C --&gt; I[Expense DB];     E --&gt; J[Payment Service];</code></p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Splitwise-like%20Expense%20Splitter/#5-data-schema-api-design","title":"5. Data Schema &amp; API Design","text":"<ul> <li>API:<ul> <li><code>POST /v1/groups/{group_id}/expenses</code>: Add expense.</li> <li><code>GET /v1/groups/{group_id}/balances</code>: Get balances.</li> <li><code>POST /v1/groups/{group_id}/settle</code>: Settle up.</li> </ul> </li> <li>Data Models:<ul> <li>User: <code>user_id, name, email, ...</code></li> <li>Group: <code>group_id, name, members, ...</code></li> <li>Expense: <code>expense_id, group_id, paid_by, amount, split, currency, ts</code></li> <li>BalanceSheet: <code>group_id, user_id, balance</code></li> <li>Settlement: <code>settlement_id, group_id, from_user, to_user, amount, ts</code></li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Splitwise-like%20Expense%20Splitter/#6-detailed-component-breakdown","title":"6. Detailed Component Breakdown","text":"<ul> <li>Expense Service: Handles adding expenses, validates splits, updates balances.</li> <li>Balance Service: Calculates and stores per-user balances for each group.</li> <li>Settlement Engine: Runs min-cash-flow algorithm to minimize number of payments needed to settle all debts.</li> <li>Notification Service: Notifies users of new expenses, settlements, or reminders.</li> <li>User/Group/Expense DBs: Store all persistent data.</li> <li>Payment Service: (Optional) Integrates with payment gateways for real money settlements.</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Splitwise-like%20Expense%20Splitter/#7-end-to-end-flow-add-expense-settle-up","title":"7. End-to-End Flow (Add Expense &amp; Settle Up)","text":"<p>Code snippet</p> <p>`sequenceDiagram     participant User     participant API     participant ExpenseSvc     participant BalanceSvc     participant SettlementEng     participant Notification</p> <pre><code>User-&gt;&gt;API: Add expense\nAPI-&gt;&gt;ExpenseSvc: Validate &amp; record\nExpenseSvc-&gt;&gt;BalanceSvc: Update balances\nExpenseSvc-&gt;&gt;Notification: Notify group\nUser-&gt;&gt;API: Settle up\nAPI-&gt;&gt;SettlementEng: Run min-cash-flow\nSettlementEng-&gt;&gt;BalanceSvc: Update balances\nSettlementEng-&gt;&gt;Notification: Notify users\n</code></pre> <p>`</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Splitwise-like%20Expense%20Splitter/#8-bottlenecks-fault-tolerance-and-trade-offs","title":"8. Bottlenecks, Fault Tolerance, and Trade-offs","text":"<ul> <li>Bottleneck: Settlement Algorithm:<ul> <li>Min-cash-flow is O(N^2) for large groups. Use heuristics or batch settlements for scale.</li> </ul> </li> <li>Accuracy:<ul> <li>Rounding and currency conversion can cause small errors. Use high-precision types and audit logs.</li> </ul> </li> <li>Reliability:<ul> <li>All transactions are persisted. Use idempotency keys for safe retries.</li> </ul> </li> <li>Trade-offs:<ul> <li>Simpler algorithms are faster but may not minimize payments. More complex ones are optimal but slower.</li> </ul> </li> </ul> <p>This design is used by Splitwise and similar apps for group expense management and debt simplification.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Threshold%20Alerting%20Engine/","title":"Threshold Alerting Engine","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Threshold%20Alerting%20Engine/#problem-statement","title":"Problem Statement","text":"<p>On time-series inputs, trigger alerts (e.g., CPU&gt;90% for 5m) with debounce.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Threshold%20Alerting%20Engine/#functional-requirements","title":"Functional Requirements","text":"<ul> <li>Rules per metric</li> <li>Conditions across time windows</li> <li>Suppress duplicates (debounce)</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Threshold%20Alerting%20Engine/#core-concepts","title":"Core Concepts","text":"<ul> <li><code>Rule(metric, predicate, window, duration)</code></li> <li><code>Evaluator</code> keeps rolling window</li> <li><code>Notifier</code> (email/webhook)</li> <li>Debounce logic</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Threshold%20Alerting%20Engine/#high-level-design","title":"High-Level Design","text":"<ul> <li>Rules:<ul> <li>Each rule: metric, predicate, window, duration</li> </ul> </li> <li>Evaluator:<ul> <li>Maintains rolling window of values</li> <li>Triggers alert if condition met for duration</li> </ul> </li> <li>Notifier:<ul> <li>Sends alert (email/webhook)</li> <li>Debounce to suppress duplicates</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Threshold%20Alerting%20Engine/#step-by-step-solution","title":"Step-by-Step Solution","text":"<ol> <li>Define Rule, Evaluator, Notifier classes</li> <li>Evaluator: rolling window logic</li> <li>Debounce: suppress duplicate alerts</li> <li>API: add rule, ingest metric, get alerts</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Threshold%20Alerting%20Engine/#edge-cases","title":"Edge Cases","text":"<ul> <li>Flapping metrics</li> <li>Overlapping rules</li> <li>Missed alerts on downtime</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Ticketing%20%28High%20Contention%29/","title":"Ticketing (High Contention)","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Ticketing%20%28High%20Contention%29/#1-problem-statement-scope","title":"1. Problem Statement &amp; Scope","text":"<p>Design a ticketing system for high-demand events (e.g., concerts, sports) that can handle massive traffic spikes, prevent overselling, and ensure fairness. The system must support temporary seat holds, payment, and confirmation, with strong consistency and resilience to failures.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Ticketing%20%28High%20Contention%29/#2-requirements","title":"2. Requirements","text":"<ul> <li>Functional Requirements:<ul> <li>Users can view available seats in real time.</li> <li>Place temporary holds on seats (cart/hold window).</li> <li>Confirm purchase after payment.</li> <li>Release holds on timeout or user abandon.</li> <li>Waitlist/queue for overflow demand.</li> </ul> </li> <li>Non-Functional Requirements:<ul> <li>Scalability: Handle 1M+ concurrent users during peak.</li> <li>Fairness: Prevent bots, ensure first-come-first-served.</li> <li>Consistency: No overselling, strong seat allocation.</li> <li>Availability: Survive flash crowds, DDoS.</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Ticketing%20%28High%20Contention%29/#3-capacity-estimation","title":"3. Capacity Estimation","text":"<ul> <li>Peak Users: 1M concurrent.</li> <li>Seats/Event: 50k.</li> <li>Hold Window: 5 minutes.</li> <li>Purchase Rate: 10k/sec peak.</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Ticketing%20%28High%20Contention%29/#4-high-level-architecture-diagram","title":"4. High-Level Architecture Diagram","text":"<p>Code snippet</p> <p><code>graph TD     A[User] --&gt; B[CDN/WAF];     B --&gt; C[Virtual Waiting Room];     C --&gt; D[Ticket Service];     D --&gt; E[Redis (Seat Holds)];     D --&gt; F[Postgres (Durable State)];     D --&gt; G[Payment Service];     D --&gt; H[Notification Service];     D --&gt; I[Queue/Waitlist Service];</code></p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Ticketing%20%28High%20Contention%29/#5-data-schema-api-design","title":"5. Data Schema &amp; API Design","text":"<ul> <li>API:<ul> <li><code>GET /v1/events/{event_id}/seats</code>: View seat map.</li> <li><code>POST /v1/events/{event_id}/hold</code>: Place hold.</li> <li><code>POST /v1/events/{event_id}/purchase</code>: Confirm purchase.</li> </ul> </li> <li>Data Models:<ul> <li>Seats: <code>seat_id, event_id, status (available/held/sold), hold_expiry, user_id</code></li> <li>Holds (Redis): <code>hold_id, seat_ids, user_id, expires_at</code></li> <li>Orders (Postgres): <code>order_id, user_id, seat_ids, status, payment_id</code></li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Ticketing%20%28High%20Contention%29/#6-detailed-component-breakdown","title":"6. Detailed Component Breakdown","text":"<ul> <li>CDN/WAF: Absorbs DDoS, caches static content.</li> <li>Virtual Waiting Room: Throttles entry, prevents overload, enforces fairness.</li> <li>Ticket Service: Core logic for seat holds, purchase, and release. Uses Redis for fast holds, Postgres for durability.</li> <li>Redis (Seat Holds): In-memory, expiring keys for temporary holds.</li> <li>Postgres (Durable State): Source of truth for sold seats and orders.</li> <li>Payment Service: Handles payment and refunds.</li> <li>Notification Service: Sends confirmation, reminders, or waitlist updates.</li> <li>Queue/Waitlist Service: Manages overflow demand.</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Ticketing%20%28High%20Contention%29/#7-end-to-end-flow-seat-hold-purchase","title":"7. End-to-End Flow (Seat Hold &amp; Purchase)","text":"<p>Code snippet</p> <p>`sequenceDiagram     participant User     participant WaitingRoom     participant TicketSvc     participant Redis     participant Postgres     participant Payment     participant Notification</p> <pre><code>User-&gt;&gt;WaitingRoom: Enter event\nWaitingRoom-&gt;&gt;TicketSvc: Allow entry\nTicketSvc-&gt;&gt;Redis: Place seat hold\nRedis--&gt;&gt;TicketSvc: Hold confirmed\nTicketSvc-&gt;&gt;User: Show hold, start timer\nUser-&gt;&gt;TicketSvc: Purchase\nTicketSvc-&gt;&gt;Payment: Process payment\nPayment--&gt;&gt;TicketSvc: Success/Fail\nalt Success\n    TicketSvc-&gt;&gt;Postgres: Mark seat(s) sold\n    TicketSvc-&gt;&gt;Redis: Remove hold\n    TicketSvc-&gt;&gt;Notification: Send confirmation\nelse Fail\n    TicketSvc-&gt;&gt;Redis: Release hold\n    TicketSvc-&gt;&gt;User: Show error\nend\n</code></pre> <p>`</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Ticketing%20%28High%20Contention%29/#8-bottlenecks-fault-tolerance-and-trade-offs","title":"8. Bottlenecks, Fault Tolerance, and Trade-offs","text":"<ul> <li>Bottleneck: Redis/DB:<ul> <li>Redis for speed, Postgres for durability. Use optimistic locking for seat updates.</li> </ul> </li> <li>Fairness:<ul> <li>Virtual waiting room and rate limiting prevent unfair access.</li> </ul> </li> <li>Consistency:<ul> <li>Optimistic locking ensures no double-sell. Redis expiry releases abandoned holds.</li> </ul> </li> <li>Trade-offs:<ul> <li>Speed vs. consistency. Strong consistency for seat allocation, eventual for notifications.</li> <li>In-memory holds are fast but require careful expiry handling.</li> </ul> </li> </ul> <p>This design is used by major ticketing platforms to handle flash sales and high contention events.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Timeseries%20Database/","title":"Timeseries Database","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Timeseries%20Database/#timeseries-database-downsampling-retention","title":"Timeseries Database (Downsampling + Retention)","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Timeseries%20Database/#1-problem-statement-requirements","title":"1. Problem Statement &amp; Requirements","text":"<p>Design a scalable, multi-tenant timeseries database (TSDB) for high write throughput, efficient range queries, retention, and downsampling.</p> <p>Functional Requirements: - Ingest high-frequency timeseries data (metrics, logs, IoT, etc.) - Support multi-tenant isolation - Range queries over time and labels - Retention/TTL and automatic data expiry - Downsampling/rollups for older data - Support for tags/labels and flexible schema</p> <p>Non-Functional Requirements: - 1\u201310M datapoints/sec writes - Query p95 &lt; 500ms for recent data - High availability, horizontal scalability</p> <p>Assumptions: - Data is append-only, immutable after ingest - Hot/cold storage tiers for cost efficiency</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Timeseries%20Database/#2-high-level-architecture","title":"2. High-Level Architecture","text":"<p>Components: - Ingest Tier: Accepts writes, batches, and deduplicates - Write-Ahead Log (WAL): Ensures durability before flush - Memtable: In-memory buffer for fast ingest - Storage Engine: Sharded, time-partitioned LSM/columnar store - Compactor: Merges, downsample, and evicts old data - Query Engine: Executes range, aggregation, and label queries - Retention Manager: Enforces TTL and tiering</p> <p>Architecture Diagram: <pre><code> [Ingest] -&gt; [WAL] -&gt; [Memtable] -&gt; [Storage] -&gt; [Compactor] -&gt; [Query Engine]\n</code></pre></p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Timeseries%20Database/#3-data-model-partitioning","title":"3. Data Model &amp; Partitioning","text":"<ul> <li>Timeseries: { metric, labels, points[] }</li> <li>Point: { ts, value }</li> <li>Labels: { key: value, ... } for multi-dimensional queries</li> <li>Sharding: By tenant, metric, and time window</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Timeseries%20Database/#4-key-workflows","title":"4. Key Workflows","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Timeseries%20Database/#a-write-path","title":"a) Write Path","text":"<ol> <li>Ingest tier receives batch of points</li> <li>Appends to WAL for durability</li> <li>Buffers in memtable (sorted by time)</li> <li>On flush, writes to LSM/columnar storage</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Timeseries%20Database/#b-compaction-downsampling","title":"b) Compaction &amp; Downsampling","text":"<ol> <li>Compactor merges small files, removes duplicates</li> <li>Downsamples old data (e.g., 1s\u21921m\u21921h)</li> <li>Moves cold data to cheaper storage</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Timeseries%20Database/#c-query-path","title":"c) Query Path","text":"<ol> <li>Query engine parses range/label query</li> <li>Reads from memtable, then storage (hot/cold)</li> <li>Applies aggregation, downsampling as needed</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Timeseries%20Database/#d-retention-ttl","title":"d) Retention &amp; TTL","text":"<ol> <li>Retention manager scans for expired data</li> <li>Deletes or moves to cold storage</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Timeseries%20Database/#5-scaling-reliability","title":"5. Scaling &amp; Reliability","text":"<ul> <li>Horizontal Scaling: Shard by tenant/metric/time</li> <li>Replication: For HA and durability</li> <li>Tiered Storage: SSD for hot, object store for cold</li> <li>Monitoring: Ingest lag, compaction, query latency</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Timeseries%20Database/#6-trade-offs-alternatives","title":"6. Trade-offs &amp; Alternatives","text":"<ul> <li>Write Amplification: LSM/compaction increases writes, but enables fast ingest</li> <li>Query Speed: Columnar/LSM enables fast range queries, but may slow random access</li> <li>Indexing: Time-partitioned and label inverted indices for efficient queries</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Timeseries%20Database/#7-best-practices-extensions","title":"7. Best Practices &amp; Extensions","text":"<ul> <li>Use background rollups for downsampling</li> <li>Tiered storage for cost efficiency</li> <li>Support for schema evolution and label cardinality control</li> <li>Integrate with Prometheus/OTel for metrics ingest</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Timeseries%20Database/#8-example-pseudocode-downsampling","title":"8. Example Pseudocode (Downsampling)","text":"<pre><code>def downsample(points, interval):\n    buckets = defaultdict(list)\n    for p in points:\n        bucket = p.ts // interval\n        buckets[bucket].append(p.value)\n    return [(bucket*interval, sum(vals)/len(vals)) for bucket, vals in buckets.items()]\n</code></pre>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Timeseries%20Database/#9-references","title":"9. References","text":"<ul> <li>LSM Trees</li> <li>Prometheus TSDB</li> <li>ClickHouse for Timeseries</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Trade%20Capture%20and%20Reconciliation/","title":"Trade Capture and Reconciliation","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Trade%20Capture%20and%20Reconciliation/#trade-capture-reconciliation","title":"Trade Capture &amp; Reconciliation","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Trade%20Capture%20and%20Reconciliation/#1-problem-statement-requirements","title":"1. Problem Statement &amp; Requirements","text":"<p>Design a robust trade capture and reconciliation system to ingest, deduplicate, persist, and reconcile trade executions with custodians.</p> <p>Functional Requirements: - Ingest executions from multiple venues - Deduplicate and canonicalize trades - Persist all trades with audit trail - End-of-day reconciliation with custodian/counterparty - Exception workflow for mismatches</p> <p>Non-Functional Requirements: - 100\u2013500k messages/day - Correctness &gt; performance - High auditability, schema evolution support</p> <p>Assumptions: - All venues provide unique trade IDs or can be canonicalized - Reconciliation is batch (EOD)</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Trade%20Capture%20and%20Reconciliation/#2-high-level-architecture","title":"2. High-Level Architecture","text":"<p>Components: - Venue Ingest: Receives and parses trade executions - Canonicalizer: Normalizes trade format, deduplicates - Idempotency Layer: Ensures no double-inserts - Durable Log: Write-ahead log for all trades - Reconciliation Job: Compares internal and custodian records - Exception Workflow: Handles mismatches, manual review - Storage: RDBMS (audit), data lake (raw)</p> <p>Architecture Diagram: <pre><code> [Venue Ingest] -&gt; [Canonicalizer] -&gt; [Idempotency] -&gt; [Durable Log] -&gt; [Reconciliation] -&gt; [Exception Workflow]\n</code></pre></p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Trade%20Capture%20and%20Reconciliation/#3-data-model-canonicalization","title":"3. Data Model &amp; Canonicalization","text":"<ul> <li>Trade: { id, venue, symbol, qty, price, ts, ... }</li> <li>Canonical Trade: Normalized, deduped trade record</li> <li>Reconciliation Record: { trade_id, status, details }</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Trade%20Capture%20and%20Reconciliation/#4-key-workflows","title":"4. Key Workflows","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Trade%20Capture%20and%20Reconciliation/#a-trade-ingestion","title":"a) Trade Ingestion","text":"<ol> <li>Venue Ingest receives trade execution</li> <li>Canonicalizer normalizes and deduplicates</li> <li>Idempotency layer checks for duplicates</li> <li>Trade written to durable log and RDBMS</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Trade%20Capture%20and%20Reconciliation/#b-end-of-day-reconciliation","title":"b) End-of-day Reconciliation","text":"<ol> <li>Reconciliation job fetches internal and custodian trades</li> <li>Compares by trade ID, symbol, qty, price</li> <li>Matches marked as reconciled; mismatches to exception workflow</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Trade%20Capture%20and%20Reconciliation/#c-exception-handling","title":"c) Exception Handling","text":"<ol> <li>Mismatches queued for manual review</li> <li>Analyst resolves, updates status</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Trade%20Capture%20and%20Reconciliation/#5-scaling-reliability","title":"5. Scaling &amp; Reliability","text":"<ul> <li>Batch Processing: EOD jobs for reconciliation</li> <li>Idempotency: Versioned upserts for deduplication</li> <li>Schema Evolution: Use CDC and schema registry</li> <li>Audit Trail: All changes logged</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Trade%20Capture%20and%20Reconciliation/#6-trade-offs-alternatives","title":"6. Trade-offs &amp; Alternatives","text":"<ul> <li>Strict Schema vs Flexibility: Use schema registry for evolution</li> <li>Batch vs Real-time Reconciliation: Batch is simpler, real-time is possible but complex</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Trade%20Capture%20and%20Reconciliation/#7-best-practices-extensions","title":"7. Best Practices &amp; Extensions","text":"<ul> <li>Use versioned upserts for idempotency</li> <li>CDC for schema evolution</li> <li>Exception workflow for all mismatches</li> <li>Integrate with downstream reporting and analytics</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Trade%20Capture%20and%20Reconciliation/#8-example-pseudocode-reconciliation","title":"8. Example Pseudocode (Reconciliation)","text":"<pre><code>def reconcile(internal_trades, custodian_trades):\n    matched, mismatched = [], []\n    custodian_map = {t.id: t for t in custodian_trades}\n    for t in internal_trades:\n        if t.id in custodian_map and t == custodian_map[t.id]:\n            matched.append(t)\n        else:\n            mismatched.append(t)\n    return matched, mismatched\n</code></pre>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Trade%20Capture%20and%20Reconciliation/#9-references","title":"9. References","text":"<ul> <li>Trade Reconciliation</li> <li>CDC &amp; Schema Registry</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/URL%20Shortener%20%28Core%29/","title":"URL Shortener (Core)","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/URL%20Shortener%20%28Core%29/#problem-statement","title":"Problem Statement","text":"<p>Shorten URLs, expand codes, and track clicks. Prevent malicious loops.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/URL%20Shortener%20%28Core%29/#functional-requirements","title":"Functional Requirements","text":"<ul> <li><code>shorten(url, custom?)</code>, <code>expand(code)</code>, basic stats</li> <li>Prevent malicious loops</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/URL%20Shortener%20%28Core%29/#core-concepts","title":"Core Concepts","text":"<ul> <li><code>CodeGenerator</code> (base62 of counter or hash+collision)</li> <li><code>UrlMapping(code, longUrl, createdAt, owner)</code></li> <li><code>Store</code>, <code>StatsService</code></li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/URL%20Shortener%20%28Core%29/#high-level-design","title":"High-Level Design","text":"<ul> <li>Shortening:<ul> <li>Generate code (base62 of counter or hash)</li> <li>Store mapping in DB (code \u2192 longUrl)</li> <li>Support custom aliases (check for collision)</li> </ul> </li> <li>Expanding:<ul> <li>Lookup code in DB, return longUrl</li> <li>Track click stats (increment counter)</li> </ul> </li> <li>Malicious Loops:<ul> <li>Validate longUrl is not a shortener domain</li> </ul> </li> <li>Caching:<ul> <li>Cache code\u2192longUrl for fast redirects</li> <li>TTL for dead links</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/URL%20Shortener%20%28Core%29/#step-by-step-solution","title":"Step-by-Step Solution","text":"<ol> <li>CodeGenerator: base62 encode counter/hash</li> <li>Store: mapping and stats</li> <li>API: shorten, expand, stats endpoints</li> <li>Validation: check for loops, dead links</li> </ol>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/URL%20Shortener%20%28Core%29/#edge-cases","title":"Edge Cases","text":"<ul> <li>Custom alias collision</li> <li>Expired/deleted links</li> <li>Invalid URLs</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/URL%20Shortener%20%28Global%29/","title":"URL Shortener (Global)","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/URL%20Shortener%20%28Global%29/#1-problem-statement-scope","title":"1. Problem Statement &amp; Scope","text":"<p>Design a global URL shortening service (like bit.ly or tinyurl.com) that generates short aliases for long URLs and provides fast, highly available redirection. The system must handle billions of URLs, massive read traffic, and provide analytics.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/URL%20Shortener%20%28Global%29/#2-requirements","title":"2. Requirements","text":"<ul> <li>Functional Requirements:<ul> <li>Users can submit a long URL and receive a unique, short URL.</li> <li>Optionally support custom aliases.</li> <li>Accessing the short URL redirects to the original long URL.</li> <li>Track click analytics (usage, geo, referrer).</li> </ul> </li> <li>Non-Functional Requirements:<ul> <li>Latency: Redirects must be extremely fast (p99 &lt; 30ms).</li> <li>Availability: Five-nines (99.999%) for redirects.</li> <li>Scalability: 50k QPS reads, billions of URLs.</li> <li>Durability: No lost mappings.</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/URL%20Shortener%20%28Global%29/#3-capacity-estimation","title":"3. Capacity Estimation","text":"<ul> <li>Write Rate: 10 new URLs/sec.</li> <li>Read Rate: 50,000 redirects/sec (read/write = 5000:1).</li> <li>Storage: 10B URLs * 600B = 6TB (sharded DB).</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/URL%20Shortener%20%28Global%29/#4-high-level-architecture-diagram","title":"4. High-Level Architecture Diagram","text":"<p>Code snippet</p> <p><code>graph TD     subgraph \"Write Path (Shorten)\"         A[User] --&gt; B[API Service];         B --&gt; C[Code Generation Service];         B --&gt; D[Database (Sharded)];     end     subgraph \"Read Path (Redirect)\"         E[User] --&gt; F[Edge CDN/PoP];         F --&gt; G[Redirector Service];         G --&gt; H[Cache (Redis)];         H --&gt; D;     end     subgraph \"Analytics Path (Async)\"         G -- fire-and-forget --&gt; I[Message Bus (Kafka)];         I --&gt; J[Stream Processor];         J --&gt; K[Analytics DB (ClickHouse)];     end</code></p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/URL%20Shortener%20%28Global%29/#5-data-schema-api-design","title":"5. Data Schema &amp; API Design","text":"<ul> <li>API:<ul> <li><code>POST /v1/shorten</code>: <code>{long_url, custom_alias?}</code> \u2192 <code>{short_url}</code></li> <li><code>GET /{short_code}</code>: Redirect endpoint.</li> </ul> </li> <li>Data Models:<ul> <li>URLs Table: <code>short_code, long_url, user_id, created_at, ...</code></li> <li>Analytics Table: <code>short_code, ts, ip, geo, referrer, ...</code></li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/URL%20Shortener%20%28Global%29/#6-detailed-component-breakdown","title":"6. Detailed Component Breakdown","text":"<ul> <li>API Service: Handles URL shortening requests, validates input, and stores mappings.</li> <li>Code Generation Service: Generates unique short codes, checks for collisions, supports custom aliases.</li> <li>Database (Sharded): Stores mappings, sharded for scale.</li> <li>Edge CDN/PoP: Caches redirects close to users for low latency.</li> <li>Redirector Service: Looks up short code, issues HTTP 301/302 redirect.</li> <li>Cache (Redis): Caches hot mappings for fast lookup.</li> <li>Message Bus (Kafka): Streams click events for analytics.</li> <li>Stream Processor: Aggregates analytics, writes to analytics DB.</li> <li>Analytics DB (ClickHouse): Stores and serves analytics queries.</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/URL%20Shortener%20%28Global%29/#7-end-to-end-flow-shorten-redirect","title":"7. End-to-End Flow (Shorten &amp; Redirect)","text":"<p>Code snippet</p> <p>`sequenceDiagram     participant User     participant API     participant CodeGen     participant DB     participant CDN     participant Redirector     participant Cache     participant Kafka     participant Analytics</p> <pre><code>User-&gt;&gt;API: POST /shorten\nAPI-&gt;&gt;CodeGen: Generate code\nCodeGen-&gt;&gt;DB: Store mapping\nDB--&gt;&gt;API: Ack\nAPI--&gt;&gt;User: Return short_url\nUser-&gt;&gt;CDN: GET /{short_code}\nCDN-&gt;&gt;Redirector: Lookup\nRedirector-&gt;&gt;Cache: Check cache\nalt Hit\n    Cache--&gt;&gt;Redirector: Return long_url\nelse Miss\n    Redirector-&gt;&gt;DB: Lookup\n    DB--&gt;&gt;Redirector: Return long_url\n    Redirector-&gt;&gt;Cache: Set cache\nend\nRedirector--&gt;&gt;User: HTTP 301/302\nRedirector-&gt;&gt;Kafka: Log click\nKafka-&gt;&gt;Analytics: Aggregate\n</code></pre> <p>`</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/URL%20Shortener%20%28Global%29/#8-bottlenecks-fault-tolerance-and-trade-offs","title":"8. Bottlenecks, Fault Tolerance, and Trade-offs","text":"<ul> <li>Bottleneck: DB/Cache:<ul> <li>Use sharding and caching for scale. CDN for global low latency.</li> </ul> </li> <li>Code Generation:<ul> <li>Ensure uniqueness, avoid collisions. Use random or hash-based codes.</li> </ul> </li> <li>Analytics:<ul> <li>Async, eventual consistency. Use stream processing for scale.</li> </ul> </li> <li>Trade-offs:<ul> <li>Write path can be eventually consistent. Read path must be highly available and fast.</li> </ul> </li> </ul> <p>This design is used by Bitly, TinyURL, and other global URL shorteners.         - <code>short_code VARCHAR(8) PRIMARY KEY,</code>         - <code>long_url TEXT,</code>         - <code>created_at TIMESTAMP</code>     - The choice of <code>short_code</code> as the primary key is perfect for a sharded system, as random-looking codes will distribute the load evenly.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/URL%20Shortener%20%28Global%29/#6-detailed-component-breakdown_1","title":"6. Detailed Component Breakdown","text":"<ul> <li>API Service (Write Path): Receives the long URL. It calls the Code Generation Service to get a unique short code, then writes the mapping (<code>short_code</code> -&gt; <code>long_url</code>) to the database. If a custom alias is requested, it first checks the DB for its availability.</li> <li>Code Generation Service: This is a critical component that must produce unique short codes without being a bottleneck.<ul> <li>Strategy 1 (Snowflake-style): Use a distributed unique ID generator (like Twitter's Snowflake) to get a 64-bit integer. Then, Base62-encode this integer <code>[a-zA-Z0-9]</code>. This produces a ~7-character code, is guaranteed to be unique, and doesn't require a database check.</li> <li>Strategy 2 (Pre-generation): Have a background job that generates millions of random, unused codes and stores them in a queue (e.g., in Redis). The API service just pops a code from this queue when needed.</li> </ul> </li> <li>Redirector Service (Read Path): A fleet of lightweight, stateless servers deployed globally. Their only job is to handle <code>GET /{short_code}</code> requests.<ol> <li>First, check a multi-layered cache (e.g., local in-memory, then a regional Redis cluster).</li> <li>If it's a cache miss, query the database to get the <code>long_url</code>.</li> <li>Populate the cache with the result.</li> <li>Return a <code>301</code> or <code>302</code> redirect.</li> <li>Asynchronously publish a click event to Kafka for analytics.</li> </ol> </li> <li>Cache: The most important part of the read path. A very high cache hit rate (&gt;99%) is expected. This shields the database from the massive read traffic. Caching can happen at multiple levels: browser, CDN edge, and the service's regional Redis cluster.</li> <li>Analytics Pipeline: A standard streaming pipeline. The fire-and-forget approach ensures that analytics processing adds zero latency to the user-facing redirect.</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/URL%20Shortener%20%28Global%29/#7-end-to-end-flow-redirect","title":"7. End-to-End Flow (Redirect)","text":"<p>Code snippet</p> <p>`sequenceDiagram     participant UserBrowser     participant EdgeCDN     participant RedirectorSvc     participant RedisCache     participant Database</p> <pre><code>UserBrowser-&gt;&gt;EdgeCDN: GET /aBcDeF\nNote over EdgeCDN: Cache MISS\nEdgeCDN-&gt;&gt;RedirectorSvc: GET /aBcDeF\n\nRedirectorSvc-&gt;&gt;RedisCache: GET short_code:aBcDeF\nNote over RedisCache: Cache MISS\nRedisCache--&gt;&gt;RedirectorSvc: nil\n\nRedirectorSvc-&gt;&gt;Database: SELECT long_url WHERE short_code='aBcDeF'\nDatabase--&gt;&gt;RedirectorSvc: \"http://very.long.url/...\"\n\nRedirectorSvc-&gt;&gt;RedisCache: SET short_code:aBcDeF \"http://...\"\n\nNote over RedirectorSvc: Asynchronously log click to Kafka\nRedirectorSvc--&gt;&gt;EdgeCDN: 302 Found, Location: \"http://...\"\nEdgeCDN--&gt;&gt;UserBrowser: 302 Found, Location: \"http://...\"`\n</code></pre>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/URL%20Shortener%20%28Global%29/#8-bottlenecks-fault-tolerance-and-trade-offs_1","title":"8. Bottlenecks, Fault Tolerance, and Trade-offs","text":"<ul> <li>Bottleneck: Write Path Code Generation: If we used a naive approach of generating a random code and checking the DB for uniqueness, we would face high latency and collisions at scale. The Snowflake/Base62 approach avoids this central contention.</li> <li>Fault Tolerance:<ul> <li>Read Path: The read path is highly resilient. If the database is temporarily unavailable, the system can continue to serve redirects for all cached entries, degrading gracefully.</li> <li>Write Path: The write path is less critical. If it's down for a few minutes, users cannot create new short URLs, but existing ones continue to work.</li> </ul> </li> <li>Key Trade-offs:<ul> <li>Redirect Type (301 vs. 302):<ul> <li><code>301 Moved Permanently</code>: The browser caches this response aggressively. The next time the user clicks the link, the browser may go directly to the long URL without ever contacting our service again. This is great for reducing server load but terrible for analytics and makes it impossible to ever change the destination URL.</li> <li><code>302 Found</code> (or <code>307 Temporary Redirect</code>): The browser is instructed that this redirect is temporary and it should always check the short URL first. This ensures our service is hit every time, allowing for 100% accurate analytics and the ability to edit the destination. The trade-off is higher traffic to our servers. For most commercial shorteners, 302/307 is the correct choice.</li> </ul> </li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Vector%20Search%20Service/","title":"Vector Search Service","text":""},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Vector%20Search%20Service/#1-problem-statement-scope","title":"1. Problem Statement &amp; Scope","text":"<p>Design a scalable, low-latency vector search service for semantic search over 100M+ items using high-dimensional embeddings. The system must support fast k-NN queries, incremental updates, and metadata filtering, with high availability and horizontal scalability.</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Vector%20Search%20Service/#2-requirements","title":"2. Requirements","text":"<ul> <li>Functional Requirements:<ul> <li>Ingest and index high-dimensional vectors (e.g., 768D, 1536D).</li> <li>Support k-NN search with optional metadata filters.</li> <li>Incremental updates (add, delete, update vectors).</li> <li>Return top-k most similar items for a query vector.</li> </ul> </li> <li>Non-Functional Requirements:<ul> <li>Latency: &lt;100ms/query for 100M+ items.</li> <li>Scalability: Scale to billions of vectors via sharding.</li> <li>Availability: 99.99% uptime.</li> <li>Consistency: Eventual for index, strong for metadata.</li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Vector%20Search%20Service/#3-capacity-estimation","title":"3. Capacity Estimation","text":"<ul> <li>Corpus Size: 100M vectors, 1536D, float32 = ~600MB/1M vectors, ~60GB total.</li> <li>Query Rate: 10k QPS.</li> <li>Index Size: With metadata, ~100GB total.</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Vector%20Search%20Service/#4-high-level-architecture-diagram","title":"4. High-Level Architecture Diagram","text":"<p>Code snippet</p> <p><code>graph TD     A[Client] --&gt; B[API Gateway];     B --&gt; C[Embedding Model Service];     B --&gt; D[Query Router];     D --&gt; E[Shard 1 (Faiss/HNSW)];     D --&gt; F[Shard 2 (Faiss/HNSW)];     D --&gt; G[Shard N (Faiss/HNSW)];     E --&gt; H[Metadata Store];     F --&gt; H;     G --&gt; H;     D --&gt; I[Aggregator/Ranker];     I --&gt; J[Result];</code></p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Vector%20Search%20Service/#5-data-schema-api-design","title":"5. Data Schema &amp; API Design","text":"<ul> <li>API:<ul> <li><code>POST /v1/search</code>: <code>{query_vector, k, filters}</code></li> <li><code>POST /v1/index</code>: <code>{item_id, vector, metadata}</code></li> <li><code>DELETE /v1/index/{item_id}</code></li> </ul> </li> <li>Data Models:<ul> <li>Vector Index: HNSW/IVF-PQ, sharded by item_id hash.</li> <li>Metadata Store: <code>item_id, metadata fields...</code></li> </ul> </li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Vector%20Search%20Service/#6-detailed-component-breakdown","title":"6. Detailed Component Breakdown","text":"<ul> <li>Embedding Model Service: Converts raw data (text, image) to vectors.</li> <li>API Gateway: Handles authentication, rate limiting, and forwards requests.</li> <li>Query Router: Routes search requests to relevant shards, aggregates results.</li> <li>Shard (Faiss/HNSW): In-memory or SSD-based vector index for fast k-NN search.</li> <li>Metadata Store: Stores item metadata for filtering and re-ranking.</li> <li>Aggregator/Ranker: Merges results from shards, applies filters, sorts by similarity.</li> </ul>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Vector%20Search%20Service/#7-end-to-end-flow-search-query","title":"7. End-to-End Flow (Search Query)","text":"<p>Code snippet</p> <p>`sequenceDiagram     participant Client     participant APIGW     participant Embed     participant Router     participant Shard1     participant Shard2     participant Agg</p> <pre><code>Client-&gt;&gt;APIGW: POST /v1/search\nAPIGW-&gt;&gt;Embed: Get query vector\nEmbed--&gt;&gt;APIGW: Return vector\nAPIGW-&gt;&gt;Router: Forward search\nRouter-&gt;&gt;Shard1: k-NN search\nRouter-&gt;&gt;Shard2: k-NN search\nShard1--&gt;&gt;Router: Top-k results\nShard2--&gt;&gt;Router: Top-k results\nRouter-&gt;&gt;Agg: Aggregate, filter, rank\nAgg--&gt;&gt;APIGW: Final results\nAPIGW--&gt;&gt;Client: Return top-k\n</code></pre> <p>`</p>"},{"location":"hld/DE%20Shaw%20HLD%20with%20Implementations/Vector%20Search%20Service/#8-bottlenecks-fault-tolerance-and-trade-offs","title":"8. Bottlenecks, Fault Tolerance, and Trade-offs","text":"<ul> <li>Bottleneck: Shard Memory/CPU:<ul> <li>Use SSD-based indexes for larger-than-memory datasets. Horizontal sharding for scale.</li> </ul> </li> <li>Recall vs. Latency:<ul> <li>HNSW/IVF-PQ trade off accuracy for speed. Tune parameters per use case.</li> </ul> </li> <li>Fault Tolerance:<ul> <li>Replicate shards, use stateless routers. Failed shard = partial results, degrade gracefully.</li> </ul> </li> <li>Trade-offs:<ul> <li>Eventual consistency for index updates. Strong consistency for metadata.</li> <li>SSD-based search is slower but cheaper than RAM.</li> </ul> </li> </ul> <p>This design is used by modern semantic search engines (e.g., Pinecone, Weaviate, OpenAI) for large-scale vector search.</p>"},{"location":"lld/de-shaw/","title":"DE Shaw","text":"<ul> <li>Authentication (Login Signup + Sessions &amp; 2FA)</li> <li>LRU Cache with TTL and Write-Back</li> <li>Token-Bucket Rate Limiter (Multi-Tenant)</li> <li>Cron-like Job Scheduler (Priority + Retry)</li> <li>Publisher\u2013Subscriber Notification Service</li> <li>Thread-Safe Limit Order Book (Equities)</li> <li>Basic Matching Engine (with Market Orders)</li> <li>Market Data Fan-out (Feed Handler)</li> <li>Rolling Time-Window Aggregator (VWAP EMA)</li> <li>Feature Flag Service (Local)</li> <li>Distributed ID Generator (Snowflake-like)</li> <li>URL Shortener (Core)</li> <li>Parking Lot</li> <li>Elevator Controller (N Elevators)</li> <li>Splitwise-like Expense Splitter</li> <li>Meeting Room Scheduler</li> <li>Chat (1_1 + Typing + Read Receipts)</li> <li>In-Memory File System (Simplified)</li> <li>Threshold Alerting Engine</li> <li>Metrics Store (Append-only + Compaction)</li> </ul>"},{"location":"lld/module1/","title":"Most Frequently Asked LLD Questions (SDE 2 &amp; Senior)","text":"<p>This module contains in-depth solutions to the most frequently asked Low-Level Design (LLD) questions at SDE 2 and senior levels in top tech companies (e.g., Google, Amazon, Microsoft, Uber, etc.). Each question is covered in a dedicated file in the <code>module1/</code> directory, with detailed requirements, architecture, API, workflows, code, and testing.</p>"},{"location":"lld/module1/#index","title":"Index","text":"<ul> <li>Design a Scalable Rate Limiter</li> <li>Design a Thread-Safe LRU Cache</li> <li>Design a Notification/Observer System</li> <li>Design a File Storage Service (Dropbox/Google Drive)</li> <li>Design a Ride-Sharing Matching Service (Uber)</li> <li>Design a News Feed System (Facebook/Twitter)</li> <li>Design a Hotel Booking System</li> <li>Design a Calendar/Meeting Scheduler</li> <li>Design a Payment Wallet System</li> <li>Design a Distributed Lock Service</li> </ul> <p>Each file provides a deep-dive, industry-grade LLD solution.</p>"},{"location":"lld/overview/","title":"High-Level Design (HLD) Overview","text":"<p>This section provides a bird\u2019s-eye view of system architectures, their major components, interactions, and key design decisions.</p>"},{"location":"lld/overview/#what-is-high-level-design","title":"What is High-Level Design?","text":"<p>High-Level Design (HLD) covers: - System architecture and main components - Data flow between subsystems - Technology stack choices - Major APIs and integrations - Non-functional considerations (scalability, fault-tolerance, security, etc.)</p>"},{"location":"lld/overview/#contents","title":"Contents","text":"<ul> <li>DE Shaw</li> <li>Module</li> <li>Common Questions</li> </ul>"},{"location":"lld/overview/#when-to-use-hld","title":"When to use HLD?","text":"<ul> <li>During initial project scoping</li> <li>For design reviews and presentations</li> <li>When comparing architecture alternatives</li> </ul> <p>Start with <code>architecture.md</code> for an example system!</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Authentication%20%28Login%20Signup%20%2B%20Sessions%20%26%202FA%29/","title":"Authentication (Login Signup + Sessions &amp; 2FA)","text":"<p>This problem requires designing a robust authentication service. We'll build the core logic for user management, session handling, and security features like 2FA and brute-force protection.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Authentication%20%28Login%20Signup%20%2B%20Sessions%20%26%202FA%29/#1-system-overview-scope-clarification","title":"1. System Overview &amp; Scope Clarification","text":"<p>We are designing the backend service responsible for user identity and access management.</p> <p>Functional Requirements (FR):</p> <ul> <li>Signup: New users can register with an email and password.</li> <li>Login: Registered users can log in using their credentials.</li> <li>Logout: Users can terminate their active session.</li> <li>Password Reset: Users can request a password reset link via email and set a new password.</li> <li>Sessions: Successful login creates a session token, which must be validated for subsequent requests. Sessions must expire.</li> <li>Two-Factor Authentication (2FA): Users can optionally enable Time-based One-Time Password (TOTP) for enhanced security.</li> <li>Brute-Force Protection: After a configurable number of failed login attempts (<code>N</code>), the user's account should be temporarily locked.</li> </ul> <p>Non-Functional Requirements (NFR):</p> <ul> <li>Security: Passwords must be stored securely using a strong, salted hashing algorithm (e.g., BCrypt). Session IDs and 2FA secrets must be secure.</li> <li>Performance: Session validation should have minimal latency (critical path for most authenticated API calls).</li> <li>Auditability: Key events (login success/failure, password change, 2FA setup) should be logged for security analysis.</li> </ul> <p>Assumptions:</p> <ul> <li>External services like <code>EmailService</code> and a persistent database are available but will be represented by interfaces (Dependency Inversion).</li> <li>We will use in-memory data stores for users and sessions to make the example self-contained and testable. In a production system, these would be backed by a database (e.g., PostgreSQL) and a distributed cache (e.g., Redis).</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Authentication%20%28Login%20Signup%20%2B%20Sessions%20%26%202FA%29/#2-core-components-and-class-design","title":"2. Core Components and Class Design","text":"<p>We'll use a service-oriented architecture, with a central <code>AuthService</code> orchestrating various components.</p> <ul> <li>Models (Data Transfer Objects):<ul> <li><code>User</code>: Represents a user's identity and security-related state.</li> <li><code>Session</code>: Represents a user's authenticated session.</li> </ul> </li> <li>Services (Business Logic):<ul> <li><code>AuthService</code>: The main facade for all authentication operations.</li> <li><code>PasswordHasher</code>: An interface for hashing and verifying passwords (Strategy Pattern).</li> <li><code>TotpService</code>: An interface for generating and verifying TOTP codes.</li> <li><code>TokenService</code>: Generates and validates short-lived tokens for actions like password resets.</li> <li><code>EmailService</code>: An interface for sending emails.</li> </ul> </li> <li>Stores (Data Access):<ul> <li><code>UserRepository</code>: Interface for CRUD operations on <code>User</code> objects.</li> <li><code>SessionRepository</code>: Interface for CRUD operations on <code>Session</code> objects.</li> </ul> </li> <li>Utilities:<ul> <li><code>RateLimiter</code>: Manages login attempts to prevent brute-force attacks.</li> </ul> </li> </ul> <p>Class Diagram (Textual Representation):</p> <pre><code>PasswordHasher (interface)         UserRepository (interface)         SessionRepository (interface)\n        |                                   |                                 |\n        v                                   v                                 v\n   BCryptHasher                   InMemoryUserRepo                   InMemorySessionRepo\n\n         |                                   |                                 |\n         +-------------------+   +-----------+-----------+   +-----------------+\n                             |   |                       |   |\n                             v   v                       v   v\n                         +------------------+        TotpService (interface)\n                         |   AuthService    |                |\n                         +------------------+                v\n                         | +signup()        |           DefaultTotp\n                         | +login()         |\n                         | +logout()        |        EmailService (interface)\n                         | +enable2FA()     |\n                         | +verifyTOTP()    |\n                         | +resetPassword() |\n                         +------------------+\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Authentication%20%28Login%20Signup%20%2B%20Sessions%20%26%202FA%29/#3-api-design-authservice","title":"3. API Design (<code>AuthService</code>)","text":"<p>We'll define clear method signatures for our main service, including custom exceptions for specific error states.</p> <p>Java</p> <pre><code>// Custom Exceptions\nclass UserAlreadyExistsException extends Exception { ... }\nclass UserNotFoundException extends Exception { ... }\nclass InvalidCredentialsException extends Exception { ... }\nclass AccountLockedException extends Exception { ... }\nclass TwoFactorRequiredException extends Exception {\n    public final String userId; // To know which user needs to verify\n}\nclass InvalidTokenException extends Exception { ... }\n\n// Main Service Interface\ninterface AuthService {\n    // Signup\n    User signup(String email, String password) throws UserAlreadyExistsException;\n\n    // Login Flow\n    Session login(String email, String password) throws UserNotFoundException, InvalidCredentialsException, AccountLockedException, TwoFactorRequiredException;\n    Session verifyLoginWithTotp(String userId, String totpCode) throws UserNotFoundException, InvalidCredentialsException;\n\n    // Logout\n    void logout(String sessionId);\n\n    // Session Management\n    Optional&lt;Session&gt; validateSession(String sessionId);\n\n    // 2FA Management\n    String generate2FASecret(String userId) throws UserNotFoundException;\n    void enable2FA(String userId, String totpCode) throws UserNotFoundException, InvalidCredentialsException;\n\n    // Password Reset\n    void requestPasswordReset(String email) throws UserNotFoundException;\n    void completePasswordReset(String resetToken, String newPassword) throws InvalidTokenException;\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Authentication%20%28Login%20Signup%20%2B%20Sessions%20%26%202FA%29/#4-key-workflows","title":"4. Key Workflows","text":"<p>a) User Login (with Brute-Force and 2FA)</p> <ol> <li>Client: Calls <code>AuthService.login(email, password)</code>.</li> <li>AuthService: a. Retrieves the <code>User</code> from the <code>UserRepository</code> by email. If not found, throws <code>UserNotFoundException</code>. b. Checks if the account is locked (<code>user.getLockedUntil()</code> is in the future). If so, throws <code>AccountLockedException</code>. c. Calls <code>PasswordHasher.verify(password, user.getPasswordHash())</code>. d. On Failure: i. Atomically increments <code>failedAttempts</code> for the user. ii. If <code>failedAttempts</code> exceeds the threshold (e.g., 5), it sets <code>lockedUntil</code> to a future time (e.g., now + 15 minutes). iii. Saves the updated user state. iv. Throws <code>InvalidCredentialsException</code>. e. On Success: i. Resets <code>failedAttempts</code> to 0 and clears <code>lockedUntil</code>. ii. Checks if <code>user.is2FAEnabled()</code>. iii. If 2FA is ON: Throws <code>TwoFactorRequiredException</code> containing the <code>userId</code>. The client must now prompt the user for their TOTP code and call <code>verifyLoginWithTotp()</code>. iv. If 2FA is OFF: Creates a new <code>Session</code> with a secure random ID, links it to the <code>userId</code>, sets an expiry time, saves it to <code>SessionRepository</code>, and returns the <code>Session</code> object.</li> </ol> <p>b) Password Reset</p> <ol> <li>Client: Calls <code>AuthService.requestPasswordReset(email)</code>.</li> <li>AuthService: a. Finds the user by email. b. Calls <code>TokenService.generate(userId, duration)</code> to create a short-lived, signed token (e.g., a JWT). c. Calls <code>EmailService.send(...)</code> with a reset link containing this token.</li> <li>User: Clicks the link in the email.</li> <li>Client: Presents a form and calls <code>AuthService.completePasswordReset(token, newPassword)</code>.</li> <li>AuthService: a. Calls <code>TokenService.validate(token)</code> to verify its signature and expiry. If invalid, throws <code>InvalidTokenException</code>. b. Extracts the <code>userId</code> from the validated token. c. Hashes the <code>newPassword</code> using <code>PasswordHasher</code>. d. Updates the user's <code>passwordHash</code> in the <code>UserRepository</code>. e. (Best Practice) Invalidates all existing sessions for that user by deleting them from the <code>SessionRepository</code>.</li> </ol>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Authentication%20%28Login%20Signup%20%2B%20Sessions%20%26%202FA%29/#5-code-implementation-java","title":"5. Code Implementation (Java)","text":"<p>Below is a complete, runnable implementation. For brevity, dependencies like a TOTP library or a JWT library are mocked or simplified.</p> <p>Dependencies (conceptual - for a real project, add these to <code>pom.xml</code> or <code>build.gradle</code>):</p> <ul> <li><code>org.mindrot:jbcrypt</code>: For BCrypt password hashing.</li> <li><code>dev.samstevens.totp:totp</code>: For TOTP generation and verification.</li> <li>A testing framework like JUnit 5.</li> </ul> <p>File Structure:</p> <p><code>src/ \u2514\u2500\u2500 main/     \u2514\u2500\u2500 java/         \u2514\u2500\u2500 auth/             \u251c\u2500\u2500 models/             \u2502   \u251c\u2500\u2500 User.java             \u2502   \u2514\u2500\u2500 Session.java             \u251c\u2500\u2500 services/             \u2502   \u251c\u2500\u2500 AuthService.java             \u2502   \u251c\u2500\u2500 PasswordHasher.java             \u2502   \u251c\u2500\u2500 BCryptPasswordHasher.java             \u2502   \u2514\u2500\u2500 ... (TotpService, TokenService, etc.)             \u251c\u2500\u2500 repositories/             \u2502   \u251c\u2500\u2500 UserRepository.java             \u2502   \u251c\u2500\u2500 SessionRepository.java             \u2502   \u2514\u2500\u2500 InMemoryUserRepository.java             \u2502   \u2514\u2500\u2500 InMemorySessionRepository.java             \u2514\u2500\u2500 exceptions/                 \u2514\u2500\u2500 ... (Custom exceptions)</code></p> <p>Core Code Snippets:</p> <p><code>User.java</code> (Model)</p> <pre><code>import java.util.concurrent.atomic.AtomicInteger;\n\npublic class User {\n    private final String id;\n    private final String email;\n    private String passwordHash;\n    private boolean twoFactorEnabled;\n    private String totpSecret;\n    private long lockedUntil;\n    private final AtomicInteger failedLoginAttempts = new AtomicInteger(0);\n    // ...constructors, getters, setters...\n}\n</code></pre> <p><code>Session.java</code> (Model)</p> <pre><code>import java.time.Instant;\n\npublic class Session {\n    private final String sessionId;\n    private final String userId;\n    private final Instant expiresAt;\n    // ...constructors, getters...\n}\n</code></pre> <p><code>PasswordHasher.java</code> (Interface and Implementation)</p> <pre><code>public interface PasswordHasher {\n    String hash(String password);\n    boolean verify(String password, String hash);\n}\n\npublic class BCryptPasswordHasher implements PasswordHasher {\n    public String hash(String password) {\n        return org.mindrot.jbcrypt.BCrypt.hashpw(password, org.mindrot.jbcrypt.BCrypt.gensalt());\n    }\n    public boolean verify(String password, String hash) {\n        return org.mindrot.jbcrypt.BCrypt.checkpw(password, hash);\n    }\n}\n</code></pre> <p><code>TotpService.java</code> (Interface and Mock Implementation)</p> <pre><code>public interface TotpService {\n    String generateSecret();\n    boolean verify(String secret, String code);\n}\n\npublic class MockTotpService implements TotpService {\n    public String generateSecret() { return \"SECRET\"; }\n    public boolean verify(String secret, String code) { return code.equals(\"123456\"); }\n}\n</code></pre> <p><code>UserRepository.java</code> (Interface and In-Memory Implementation)</p> <pre><code>import java.util.concurrent.ConcurrentHashMap;\n\npublic interface UserRepository {\n    User findByEmail(String email);\n    User findById(String id);\n    void save(User user);\n}\n\npublic class InMemoryUserRepository implements UserRepository {\n    private final ConcurrentHashMap&lt;String, User&gt; byId = new ConcurrentHashMap&lt;&gt;();\n    private final ConcurrentHashMap&lt;String, User&gt; byEmail = new ConcurrentHashMap&lt;&gt;();\n    public User findByEmail(String email) { return byEmail.get(email); }\n    public User findById(String id) { return byId.get(id); }\n    public void save(User user) {\n        byId.put(user.getId(), user);\n        byEmail.put(user.getEmail(), user);\n    }\n}\n</code></pre> <p><code>SessionRepository.java</code> (Interface and In-Memory Implementation)</p> <pre><code>import java.util.concurrent.ConcurrentHashMap;\n\npublic interface SessionRepository {\n    void save(Session session);\n    Session findById(String sessionId);\n    void deleteByUserId(String userId);\n}\n\npublic class InMemorySessionRepository implements SessionRepository {\n    private final ConcurrentHashMap&lt;String, Session&gt; byId = new ConcurrentHashMap&lt;&gt;();\n    public void save(Session session) { byId.put(session.getSessionId(), session); }\n    public Session findById(String sessionId) { return byId.get(sessionId); }\n    public void deleteByUserId(String userId) {\n        byId.values().removeIf(s -&gt; s.getUserId().equals(userId));\n    }\n}\n</code></pre> <p><code>AuthService.java</code> (Core Logic)</p> <pre><code>import java.time.Instant;\nimport java.util.Optional;\nimport java.util.UUID;\n\npublic class AuthServiceImpl implements AuthService {\n    private final UserRepository userRepo;\n    private final SessionRepository sessionRepo;\n    private final PasswordHasher hasher;\n    private final TotpService totpService;\n    // ...TokenService, EmailService omitted for brevity...\n\n    public AuthServiceImpl(UserRepository userRepo, SessionRepository sessionRepo, PasswordHasher hasher, TotpService totpService) {\n        this.userRepo = userRepo;\n        this.sessionRepo = sessionRepo;\n        this.hasher = hasher;\n        this.totpService = totpService;\n    }\n\n    public User signup(String email, String password) throws UserAlreadyExistsException {\n        if (userRepo.findByEmail(email) != null) throw new UserAlreadyExistsException();\n        User user = new User(UUID.randomUUID().toString(), email, hasher.hash(password));\n        userRepo.save(user);\n        return user;\n    }\n\n    public Session login(String email, String password) throws UserNotFoundException, InvalidCredentialsException, AccountLockedException, TwoFactorRequiredException {\n        User user = userRepo.findByEmail(email);\n        if (user == null) throw new UserNotFoundException();\n        if (user.getLockedUntil() &gt; System.currentTimeMillis()) throw new AccountLockedException();\n        if (!hasher.verify(password, user.getPasswordHash())) {\n            int attempts = user.getFailedLoginAttempts().incrementAndGet();\n            if (attempts &gt; 5) {\n                user.setLockedUntil(System.currentTimeMillis() + 15 * 60 * 1000);\n            }\n            userRepo.save(user);\n            throw new InvalidCredentialsException();\n        }\n        user.getFailedLoginAttempts().set(0);\n        user.setLockedUntil(0);\n        userRepo.save(user);\n        if (user.isTwoFactorEnabled()) throw new TwoFactorRequiredException(user.getId());\n        Session session = new Session(UUID.randomUUID().toString(), user.getId(), Instant.now().plusSeconds(3600));\n        sessionRepo.save(session);\n        return session;\n    }\n\n    public Session verifyLoginWithTotp(String userId, String totpCode) throws UserNotFoundException, InvalidCredentialsException {\n        User user = userRepo.findById(userId);\n        if (user == null) throw new UserNotFoundException();\n        if (!totpService.verify(user.getTotpSecret(), totpCode)) throw new InvalidCredentialsException();\n        Session session = new Session(UUID.randomUUID().toString(), user.getId(), Instant.now().plusSeconds(3600));\n        sessionRepo.save(session);\n        return session;\n    }\n\n    public void logout(String sessionId) {\n        // Remove session (not shown)\n    }\n\n    public Optional&lt;Session&gt; validateSession(String sessionId) {\n        Session s = sessionRepo.findById(sessionId);\n        if (s == null || s.getExpiresAt().isBefore(Instant.now())) return Optional.empty();\n        return Optional.of(s);\n    }\n\n    public String generate2FASecret(String userId) throws UserNotFoundException {\n        User user = userRepo.findById(userId);\n        if (user == null) throw new UserNotFoundException();\n        String secret = totpService.generateSecret();\n        user.setTotpSecret(secret);\n        userRepo.save(user);\n        return secret;\n    }\n\n    public void enable2FA(String userId, String totpCode) throws UserNotFoundException, InvalidCredentialsException {\n        User user = userRepo.findById(userId);\n        if (user == null) throw new UserNotFoundException();\n        if (!totpService.verify(user.getTotpSecret(), totpCode)) throw new InvalidCredentialsException();\n        user.setTwoFactorEnabled(true);\n        userRepo.save(user);\n    }\n\n    public void requestPasswordReset(String email) throws UserNotFoundException {\n        // Omitted for brevity\n    }\n    public void completePasswordReset(String resetToken, String newPassword) throws InvalidTokenException {\n        // Omitted for brevity\n    }\n}\n</code></pre> <p>Testing (JUnit 5)</p> <pre><code>import org.junit.jupiter.api.*;\nimport static org.junit.jupiter.api.Assertions.*;\n\npublic class AuthServiceTest {\n    private AuthServiceImpl authService;\n    @BeforeEach\n    void setup() {\n        authService = new AuthServiceImpl(new InMemoryUserRepository(), new InMemorySessionRepository(), new BCryptPasswordHasher(), new MockTotpService());\n    }\n    @Test\n    void testSignupAndLogin() throws Exception {\n        User user = authService.signup(\"test@example.com\", \"password\");\n        assertNotNull(user);\n        Session session = authService.login(\"test@example.com\", \"password\");\n        assertNotNull(session);\n    }\n    @Test\n    void testBruteForceLockout() throws Exception {\n        authService.signup(\"a@b.com\", \"pw\");\n        for (int i = 0; i &lt; 6; i++) {\n            try { authService.login(\"a@b.com\", \"wrong\"); } catch (InvalidCredentialsException | AccountLockedException ignored) {}\n        }\n        assertThrows(AccountLockedException.class, () -&gt; authService.login(\"a@b.com\", \"pw\"));\n    }\n    // ...more tests for 2FA, password reset, etc...\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Basic%20Matching%20Engine%20%28with%20Market%20Orders%29/","title":"Basic Matching Engine (with Market Orders)","text":"<p>Here, we elevate the <code>OrderBook</code> data structure into a full-fledged <code>MatchingEngine</code>. The key changes are supporting more complex order types (specifically market orders), handling all outcomes like partial fills, and, most importantly, producing a stream of events that communicates every action to the outside world.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Basic%20Matching%20Engine%20%28with%20Market%20Orders%29/#1-system-overview-scope-clarification","title":"1. System Overview &amp; Scope Clarification","text":"<p>A Matching Engine is the active component that drives a market. It takes order submission and cancellation requests as inputs and produces trades and order status updates as outputs. We will extend our previous <code>OrderBook</code> by wrapping it in a class that understands different order types and communicates its actions via an event bus.</p> <p>Functional Requirements (FR):</p> <ul> <li>Support Limit Orders: As per the previous design.</li> <li>Support Market Orders: A market order is an instruction to buy or sell a specified quantity at the best available price(s) on the opposite side of the book immediately. Market orders never rest on the book.</li> <li>Generate Trade Events: Whenever a match occurs, a <code>Trade</code> event must be published, detailing the price, quantity, and parties involved.</li> <li>Generate Order Update Events: Every order's lifecycle must be tracked and communicated. This includes events for acceptance (<code>ACK</code>), partial fills, full fills, and cancellations.</li> <li>Event Bus: Provide a mechanism for downstream systems (like risk management, position keeping, market data feeds) to subscribe to these events.</li> </ul> <p>Non-Functional Requirements &amp; Design Notes:</p> <ul> <li>Maintain Determinism &amp; Low Latency: The single-threaded core model from the previous problem must be preserved.</li> <li>Price Protection: A crucial safety feature. The engine should reject market orders that would execute at a price drastically different from the last known market price (e.g., last trade price or a Volume-Weighted Average Price - VWAP). This prevents a single large order from causing a \"flash crash\".</li> <li>Circuit Breakers: The engine should have hooks to allow an external system to halt all trading activity if market volatility or technical issues are detected.</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Basic%20Matching%20Engine%20%28with%20Market%20Orders%29/#2-core-components-and-class-design","title":"2. Core Components and Class Design","text":"<p>We will reuse the <code>OrderBook</code> and its internal structures, but the logic will be orchestrated by the <code>MatchingEngine</code>, which also introduces an eventing system.</p> <ul> <li><code>Order</code> (Modified): We add an <code>OrderType</code> enum.<ul> <li><code>enum OrderType { LIMIT, MARKET }</code></li> <li>A <code>MARKET</code> order might have its <code>price</code> field set to 0 or a sentinel value.</li> </ul> </li> <li><code>MarketEvent</code> (New Hierarchy): A sealed interface to represent all possible outputs from the engine.</li> </ul> <p>Java</p> <pre><code>public sealed interface MarketEvent {\n    long timestamp();\n}\npublic record Trade(long timestamp, long price, long quantity, long aggressingOrderId, long restingOrderId, Side aggressingSide) implements MarketEvent {}\npublic record OrderUpdate(long timestamp, long orderId, OrderStatus status, long remainingQuantity) implements MarketEvent {}\npublic enum OrderStatus { ACCEPTED, PARTIALLY_FILLED, FILLED, CANCELLED, REJECTED }\n</code></pre> <ul> <li><code>EventBus</code> (New): An interface for publishing events. A simple implementation will use a <code>BlockingQueue</code> to hand off events to a publisher thread, ensuring the matching thread is never blocked.</li> <li><code>MatchingEngine</code> (New Wrapper): The central component.<ul> <li>Contains an <code>OrderBook</code> instance.</li> <li>Contains an <code>EventBus</code> instance.</li> <li>Runs the single-threaded command processing loop.</li> <li>Holds logic to handle different <code>OrderType</code>s.</li> <li>Integrates checks for circuit breakers and price protection.</li> </ul> </li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Basic%20Matching%20Engine%20%28with%20Market%20Orders%29/#3-api-design-command-and-event-driven","title":"3. API Design (Command and Event-Driven)","text":"<p>The interaction model remains the same: external threads submit commands to a queue, and the engine emits events. The <code>AddOrder</code> command is now richer as it includes the <code>OrderType</code>.</p> <p>Input: <code>BlockingQueue&lt;OrderBookCommand&gt;</code>Output: <code>EventBus</code> publishing a stream of <code>MarketEvent</code>s</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Basic%20Matching%20Engine%20%28with%20Market%20Orders%29/#4-key-workflows-executed-by-the-matchingengine-thread","title":"4. Key Workflows (Executed by the <code>MatchingEngine</code> thread)","text":"<p>The main loop processes one command at a time. The <code>processAddOrder</code> logic becomes more sophisticated.</p> <p><code>processAddOrder(Order newOrder)</code> Workflow:</p> <ol> <li>Pre-flight Checks: a. Check if a circuit breaker is active. If so, reject the order (publish <code>OrderUpdate</code> with <code>REJECTED</code> status) and stop. b. Perform basic validation (e.g., quantity &gt; 0). If invalid, reject.</li> <li>Acknowledge Acceptance: Publish an <code>OrderUpdate</code> event with status <code>ACCEPTED</code>. This confirms the order has been received and is being processed.</li> <li>Handle by Order Type:<ul> <li>If <code>newOrder.type == LIMIT</code>: a. The logic is similar to before, but instead of printing trades, the <code>OrderBook</code>'s matching methods now return a <code>List&lt;Trade&gt;</code>. b. The <code>MatchingEngine</code> receives this list and publishes each <code>Trade</code> to the <code>EventBus</code>. c. For each trade, it also publishes <code>OrderUpdate</code> events for both the aggressing and resting orders involved (<code>PARTIALLY_FILLED</code> or <code>FILLED</code>). d. If the limit order is not fully filled, it rests on the book.</li> <li>If <code>newOrder.type == MARKET</code>: a. Price Protection Check: Compare the best price on the opposite side of the book with a reference price. If the slippage is too high, reject the entire order by publishing an <code>OrderUpdate</code> with status <code>REJECTED</code> (e.g., \"Market price protection trip\"). b. Begin matching against the opposite side of the book, starting from the best price. c. Consume all available quantity at the best price level, generating <code>Trade</code> and <code>OrderUpdate</code> events as you go. d. Move to the next-best price level and repeat until the market order is fully filled. e. Outcome 1: Fully Filled. The order's quantity becomes zero. Publish a final <code>OrderUpdate</code> for the market order with status <code>FILLED</code>. f. Outcome 2: Partially Filled. The order still has quantity, but the opposite side of the book is now empty. A market order cannot rest, so the remaining quantity is cancelled. Publish a final <code>OrderUpdate</code> for the market order with status <code>CANCELLED</code>.</li> </ul> </li> </ol>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Basic%20Matching%20Engine%20%28with%20Market%20Orders%29/#5-code-implementation-java","title":"5. Code Implementation (Java)","text":"<p>This shows the new <code>MatchingEngine</code> class and the modifications to handle market orders.</p> <p><code>Order</code> and <code>MarketEvent</code> definitions</p> <p>Java</p> <pre><code>public enum OrderType { LIMIT, MARKET }\npublic enum OrderStatus { ACCEPTED, PARTIALLY_FILLED, FILLED, CANCELLED, REJECTED }\n\npublic class Order {\n    long orderId; Side side; OrderType type; long price; long quantity;\n    // ... constructor and getters ...\n}\n\npublic sealed interface MarketEvent { long timestamp(); }\npublic record Trade(long timestamp, long price, long quantity, /*...other fields...*/) implements MarketEvent {}\npublic record OrderUpdate(long timestamp, long orderId, OrderStatus status, long remainingQuantity) implements MarketEvent {}\n\n// Simple EventBus for decoupling\npublic interface EventBus { void publish(MarketEvent event); }\n</code></pre> <p><code>MatchingEngine.java</code> (Simplified Logic)</p> <p>Java</p> <pre><code>import java.util.List;\nimport java.util.ArrayList;\n\npublic class MatchingEngine {\n    private final OrderBook orderBook;\n    private final EventBus eventBus;\n\n    public MatchingEngine(EventBus eventBus) {\n        this.orderBook = new OrderBook(); // Our data structure from the previous problem\n        this.eventBus = eventBus;\n    }\n\n    public void processAddOrder(Order newOrder) {\n        // Assume pre-flight checks (circuit breaker, etc.) pass\n        eventBus.publish(new OrderUpdate(System.nanoTime(), newOrder.orderId, OrderStatus.ACCEPTED, newOrder.quantity));\n\n        List&lt;Trade&gt; trades = new ArrayList&lt;&gt;();\n        if (newOrder.type == OrderType.LIMIT) {\n            trades = orderBook.matchLimitOrder(newOrder);\n        } else if (newOrder.type == OrderType.MARKET) {\n            // Price protection check would go here\n            trades = orderBook.matchMarketOrder(newOrder);\n        }\n\n        // Publish all generated events\n        for (Trade trade : trades) {\n            eventBus.publish(trade);\n            // Publish updates for resting orders that were hit\n            eventBus.publish(createUpdateForRestingOrder(trade));\n        }\n\n        // Publish final status for the aggressing order\n        if (newOrder.quantity == 0) {\n            eventBus.publish(new OrderUpdate(System.nanoTime(), newOrder.orderId, OrderStatus.FILLED, 0));\n        } else if (trades.isEmpty()) {\n            // No trades occurred, order rests (only for LIMIT)\n            if(newOrder.type == OrderType.LIMIT) orderBook.restOrder(newOrder);\n        } else {\n            // Partial fill\n            eventBus.publish(new OrderUpdate(System.nanoTime(), newOrder.orderId, OrderStatus.PARTIALLY_FILLED, newOrder.quantity));\n            if(newOrder.type == OrderType.LIMIT) orderBook.restOrder(newOrder);\n            else { // Unfilled market order portion is cancelled\n                 eventBus.publish(new OrderUpdate(System.nanoTime(), newOrder.orderId, OrderStatus.CANCELLED, 0));\n            }\n        }\n    }\n\n    private OrderUpdate createUpdateForRestingOrder(Trade trade) {\n        // Logic to find the resting order from the trade, check its remaining quantity,\n        // and create a FILLED or PARTIALLY_FILLED update.\n        return null; // Placeholder\n    }\n\n    // The OrderBook's matching methods would now be modified to return List&lt;Trade&gt;\n    // instead of printing to console.\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Basic%20Matching%20Engine%20%28with%20Market%20Orders%29/#6-testing-key-scenarios","title":"6. Testing (Key Scenarios)","text":"<p>Testing the matching engine is primarily about verifying the event stream.</p> <ul> <li>Scenario: Market order partially fills and exhausts the book.<ol> <li>Setup: <code>SELL 100 @ 101</code>.</li> <li>Action: Submit <code>BUY MARKET 150</code>.</li> <li>Expected Event Stream:<ol> <li><code>OrderUpdate(marketBuyId, ACCEPTED, 150)</code></li> <li><code>Trade(price=101, qty=100, ...)</code></li> <li><code>OrderUpdate(restingSellId, FILLED, 0)</code></li> <li><code>OrderUpdate(marketBuyId, PARTIALLY_FILLED, 50)</code></li> <li><code>OrderUpdate(marketBuyId, CANCELLED, 0)</code> (because no more liquidity)</li> </ol> </li> </ol> </li> <li>Scenario: Market order fills across multiple price levels.<ol> <li>Setup: <code>SELL 100 @ 101</code>, <code>SELL 100 @ 102</code>.</li> <li>Action: Submit <code>BUY MARKET 150</code>.</li> <li>Expected Event Stream:<ol> <li><code>OrderUpdate(marketBuyId, ACCEPTED, 150)</code></li> <li><code>Trade(price=101, qty=100, ...)</code></li> <li><code>OrderUpdate(restingSellId_1, FILLED, 0)</code></li> <li><code>OrderUpdate(marketBuyId, PARTIALLY_FILLED, 50)</code></li> <li><code>Trade(price=102, qty=50, ...)</code></li> <li><code>OrderUpdate(restingSellId_2, PARTIALLY_FILLED, 50)</code></li> <li><code>OrderUpdate(marketBuyId, FILLED, 0)</code></li> </ol> </li> </ol> </li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Basic%20Matching%20Engine%20%28with%20Market%20Orders%29/#7-extensions-and-real-world-considerations","title":"7. Extensions and Real-World Considerations","text":"<ul> <li>IOC and FOK Orders:<ul> <li>Immediate-Or-Cancel (IOC): Behaves like a market or limit order, but any portion that does not fill immediately is cancelled instead of resting. The logic is similar to a market order, but it can have a limit price.</li> <li>Fill-Or-Kill (FOK): The entire order must be filled immediately, otherwise the entire order is cancelled. This requires a \"probing\" step to check if enough volume is available before executing any trades.</li> </ul> </li> <li>Self-Trade Prevention (STP): A crucial feature. Before matching two orders, the engine checks if they belong to the same client/trader. If they do, the exchange's rules determine what happens. Often, the incoming order is cancelled to prevent a \"wash trade\".</li> <li>Sophisticated Price Protection: Instead of a simple check, production systems use a reference price like the Volume-Weighted Average Price (VWAP) over a recent time window and define collars (e.g., +/- 5%) outside of which a market order will be rejected.</li> <li>Low-Latency Eventing: The <code>EventBus</code> is on the critical path for communicating what happened. High-performance implementations use things like shared memory (<code>Aeron</code>) or ring buffers (<code>Disruptor</code>) to pass events to other threads with minimal latency and no garbage generation.</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Chat%20%281_1%20%2B%20Typing%20%2B%20Read%20Receipts%29/","title":"Chat (1:1 + Typing + Read Receipts)","text":"<p>This problem requires designing a simple, in-memory chat service supporting 1:1 messaging, typing indicators, and read/delivery receipts.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Chat%20%281_1%20%2B%20Typing%20%2B%20Read%20Receipts%29/#1-system-overview-scope-clarification","title":"1. System Overview &amp; Scope Clarification","text":"<p>We are designing a backend service for real-time chat between two users, with ephemeral state (no persistence required for this round).</p> <p>Functional Requirements (FR): - Send message between two users. - Delivery and read receipts per message. - Typing indicator (user is typing). - Idempotent resend support.</p> <p>Non-Functional Requirements (NFR): - Low latency (real-time experience). - In-memory only (stateless, for demo). - Thread-safe for concurrent users.</p> <p>Assumptions: - All state is in-memory (e.g., for interview/demo). - No authentication or persistence required. - Each conversation is between two users.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Chat%20%281_1%20%2B%20Typing%20%2B%20Read%20Receipts%29/#2-core-components-and-class-design","title":"2. Core Components and Class Design","text":"<ul> <li>User: Represents a chat user.</li> <li>Conversation: Holds participants and messages.</li> <li>Message: Represents a chat message and its state.</li> <li>ChatService: Main API for sending messages, typing, and receipts.</li> <li>PresenceService: Tracks typing/read status (in-memory).</li> <li>Delivery: Observer for delivery/read events.</li> </ul> <p>Class Diagram (Textual Representation):</p> <pre><code>+-------------+      +--------------+\n|   User      |      | Conversation |\n+-------------+      +--------------+\n| id, name    |      | id           |\n+-------------+      | participants |\n                     | messages     |\n                     +--------------+\n                            ^\n                            |\n                     +--------------+\n                     |   Message    |\n                     +--------------+\n                     | id, text     |\n                     | senderId     |\n                     | ts           |\n                     | deliveredTo  |\n                     | readBy       |\n                     +--------------+\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Chat%20%281_1%20%2B%20Typing%20%2B%20Read%20Receipts%29/#3-api-design-chatservice","title":"3. API Design (<code>ChatService</code>)","text":"<p>Java</p> <pre><code>class ChatService {\n    void sendMessage(String convId, String senderId, String text);\n    void typing(String convId, String userId);\n    void markDelivered(String convId, String msgId, String userId);\n    void markRead(String convId, String msgId, String userId);\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Chat%20%281_1%20%2B%20Typing%20%2B%20Read%20Receipts%29/#4-key-workflows","title":"4. Key Workflows","text":"<p>a) Send Message 1. User calls <code>sendMessage(convId, senderId, text)</code>. 2. Service creates a new Message, adds to Conversation. 3. Notifies recipient (observer pattern).</p> <p>b) Typing Indicator 1. User calls <code>typing(convId, userId)</code>. 2. PresenceService updates typing state. 3. Notifies other participant.</p> <p>c) Delivery/Read Receipts 1. Recipient client calls <code>markDelivered</code>/<code>markRead</code>. 2. Message state updated; sender notified.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Chat%20%281_1%20%2B%20Typing%20%2B%20Read%20Receipts%29/#5-code-implementation-java","title":"5. Code Implementation (Java)","text":"<pre><code>import java.util.*;\nimport java.util.concurrent.ConcurrentHashMap;\n\nclass User {\n    String id;\n    String name;\n}\n\nclass Message {\n    String id;\n    String text;\n    String senderId;\n    long ts;\n    Set&lt;String&gt; deliveredTo = new HashSet&lt;&gt;();\n    Set&lt;String&gt; readBy = new HashSet&lt;&gt;();\n    // ...constructors, getters, setters...\n}\n\nclass Conversation {\n    String id;\n    List&lt;User&gt; participants = new ArrayList&lt;&gt;();\n    List&lt;Message&gt; messages = new ArrayList&lt;&gt;();\n}\n\nclass PresenceService {\n    private final Map&lt;String, Set&lt;String&gt;&gt; typing = new ConcurrentHashMap&lt;&gt;();\n    public void setTyping(String convId, String userId) {\n        typing.computeIfAbsent(convId, k -&gt; new HashSet&lt;&gt;()).add(userId);\n    }\n    public Set&lt;String&gt; getTyping(String convId) {\n        return typing.getOrDefault(convId, Collections.emptySet());\n    }\n}\n\ninterface DeliveryObserver {\n    void onDelivered(String convId, String msgId, String userId);\n    void onRead(String convId, String msgId, String userId);\n}\n\nclass ChatService {\n    private final Map&lt;String, Conversation&gt; conversations = new ConcurrentHashMap&lt;&gt;();\n    private final PresenceService presence = new PresenceService();\n    private final List&lt;DeliveryObserver&gt; observers = new ArrayList&lt;&gt;();\n    public void sendMessage(String convId, String senderId, String text) {\n        Conversation conv = conversations.get(convId);\n        if (conv == null) throw new RuntimeException(\"No conversation\");\n        Message msg = new Message();\n        msg.id = UUID.randomUUID().toString();\n        msg.text = text;\n        msg.senderId = senderId;\n        msg.ts = System.currentTimeMillis();\n        conv.messages.add(msg);\n        // Notify observers (delivery)\n        for (DeliveryObserver o : observers) o.onDelivered(convId, msg.id, senderId);\n    }\n    public void typing(String convId, String userId) {\n        presence.setTyping(convId, userId);\n        // Notify other participant (not shown)\n    }\n    public void markDelivered(String convId, String msgId, String userId) {\n        Conversation conv = conversations.get(convId);\n        for (Message m : conv.messages) {\n            if (m.id.equals(msgId)) m.deliveredTo.add(userId);\n        }\n        for (DeliveryObserver o : observers) o.onDelivered(convId, msgId, userId);\n    }\n    public void markRead(String convId, String msgId, String userId) {\n        Conversation conv = conversations.get(convId);\n        for (Message m : conv.messages) {\n            if (m.id.equals(msgId)) m.readBy.add(userId);\n        }\n        for (DeliveryObserver o : observers) o.onRead(convId, msgId, userId);\n    }\n    public void addObserver(DeliveryObserver o) { observers.add(o); }\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Chat%20%281_1%20%2B%20Typing%20%2B%20Read%20Receipts%29/#6-testing-junit-5","title":"6. Testing (JUnit 5)","text":"<pre><code>import org.junit.jupiter.api.*;\nimport static org.junit.jupiter.api.Assertions.*;\n\npublic class ChatServiceTest {\n    @Test\n    void testSendAndDeliver() {\n        // Setup users, conversation, service\n        // Send message, mark delivered/read, assert state\n    }\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Chat%20%281_1%20%2B%20Typing%20%2B%20Read%20Receipts%29/#7-extensions-and-edge-cases","title":"7. Extensions and Edge Cases","text":"<ul> <li>Add group chat, message ordering, and persistence.</li> <li>Handle duplicate message delivery (idempotency).</li> <li>Add authentication and security for production.</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Cron-like%20Job%20Scheduler%20%28Priority%20%2B%20Retry%29/","title":"Cron-like Job Scheduler (Priority + Retry)","text":"<p>We will design an in-process job scheduling system that can execute tasks based on various triggers (like cron expressions or intervals), handle execution priorities, and automatically retry failed jobs with a backoff strategy.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Cron-like%20Job%20Scheduler%20%28Priority%20%2B%20Retry%29/#1-system-overview-scope-clarification","title":"1. System Overview &amp; Scope Clarification","text":"<p>This system acts as a background task manager within a single application process. It's a powerful utility for automating recurring tasks, such as sending daily reports, performing data cleanup, or polling external services.</p> <p>Functional Requirements (FR):</p> <ul> <li>Job Scheduling:<ul> <li>Schedule jobs to run at a specific time (one-time).</li> <li>Schedule jobs to run at a fixed interval (e.g., every 5 minutes).</li> <li>Schedule jobs using cron expressions for complex schedules (e.g., \"at 2 AM on Mondays\").</li> </ul> </li> <li>Execution Control:<ul> <li>Priority: When multiple jobs are due at the same time, the one with the higher priority executes first.</li> <li>Retries: If a job fails (throws an exception), it should be automatically retried according to a configurable policy (e.g., \"up to 3 times with exponential backoff\").</li> <li>Pause/Resume: Allow individual jobs or the entire scheduler to be paused and resumed.</li> </ul> </li> </ul> <p>Non-Functional Requirements (NFR):</p> <ul> <li>Accuracy: Timers should be reasonably accurate, avoiding significant drift.</li> <li>Durability (Persistence): The scheduler should be able to persist its job definitions, so scheduled tasks are not lost if the application restarts.</li> <li>Resource Management: Use a managed thread pool to execute jobs, preventing resource exhaustion.</li> </ul> <p>Scope:</p> <ul> <li>This is an in-process scheduler, meaning it runs within a single JVM/application instance.</li> <li>We will not cover distributed scheduling (which requires coordination, consensus, and distributed state management).</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Cron-like%20Job%20Scheduler%20%28Priority%20%2B%20Retry%29/#2-core-components-and-class-design","title":"2. Core Components and Class Design","text":"<p>The design is centered around a main <code>Scheduler</code> loop that manages a priority queue of upcoming jobs and a pool of worker threads to execute them.</p> <ul> <li><code>Job</code>: A simple wrapper for a <code>Runnable</code> task, containing a unique ID and metadata like priority.</li> <li><code>Trigger</code>: An interface that determines the next execution time for a job.<ul> <li>Implementations: <code>CronTrigger</code>, <code>IntervalTrigger</code>, <code>OneTimeTrigger</code>.</li> <li>Key method: <code>Instant getNextFireTime(Instant lastFireTime)</code>.</li> </ul> </li> <li><code>RetryPolicy</code>: A class defining the retry behavior.<ul> <li>Attributes: <code>maxRetries</code>, <code>backoffStrategy</code> (e.g., FIXED, EXPONENTIAL).</li> <li>Key method: <code>Duration getNextRetryDelay(int currentAttempt)</code>.</li> </ul> </li> <li><code>JobDefinition</code>: A container that bundles a <code>Job</code>, its <code>Trigger</code>, and its <code>RetryPolicy</code>. This is what the user provides to the scheduler.</li> <li><code>ScheduledJob</code>: An internal, stateful object that the scheduler uses. It contains the <code>JobDefinition</code>, the calculated <code>nextFireTime</code>, and the current retry attempt count. This is the object that will be stored in our priority queue.</li> <li><code>JobStore</code>: An interface for persistence.<ul> <li>Implementations: <code>InMemoryJobStore</code>, <code>JdbcJobStore</code>.</li> <li>Methods: <code>save(jobDef)</code>, <code>loadAll()</code>, <code>delete(jobId)</code>.</li> </ul> </li> <li><code>Scheduler</code>: The core engine. It contains:<ul> <li>A <code>PriorityBlockingQueue&lt;ScheduledJob&gt;</code> acting as a min-heap, ordered primarily by <code>nextFireTime</code> and secondarily by priority.</li> <li>A <code>ThreadPoolExecutor</code> (worker pool).</li> <li>A single \"scheduler thread\" that pulls jobs from the queue and submits them to the worker pool.</li> </ul> </li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Cron-like%20Job%20Scheduler%20%28Priority%20%2B%20Retry%29/#3-detailed-class-design","title":"3. Detailed Class Design","text":"<pre><code>// Job.java\npublic class Job {\n    private final String id;\n    private final Runnable task;\n    private final int priority;\n\n    // constructor, getters\n}\n\n// Trigger.java\npublic interface Trigger {\n    Instant getNextFireTime(Instant lastFireTime);\n}\n\n// CronTrigger.java\npublic class CronTrigger implements Trigger {\n    private final String cronExpression;\n\n    // constructor\n    public Instant getNextFireTime(Instant lastFireTime) {\n        // parse cronExpression and calculate next fire time\n    }\n}\n\n// IntervalTrigger.java\npublic class IntervalTrigger implements Trigger {\n    private final Duration interval;\n\n    // constructor\n    public Instant getNextFireTime(Instant lastFireTime) {\n        // calculate next fire time based on interval\n    }\n}\n\n// OneTimeTrigger.java\npublic class OneTimeTrigger implements Trigger {\n    private final Instant fireTime;\n\n    // constructor\n    public Instant getNextFireTime(Instant lastFireTime) {\n        return fireTime;\n    }\n}\n\n// RetryPolicy.java\npublic class RetryPolicy {\n    private final int maxRetries;\n    private final BackoffStrategy backoffStrategy;\n\n    // constructor, getters\n    public Duration getNextRetryDelay(int currentAttempt) {\n        // calculate delay based on strategy\n    }\n}\n\n// JobDefinition.java\npublic class JobDefinition {\n    private final Job job;\n    private final Trigger trigger;\n    private final RetryPolicy retryPolicy;\n\n    // constructor, getters\n}\n\n// ScheduledJob.java\npublic class ScheduledJob implements Comparable&lt;ScheduledJob&gt; {\n    private final JobDefinition jobDefinition;\n    private Instant nextFireTime;\n    private int retryAttempt;\n\n    // constructor, getters, compareTo\n}\n\n// JobStore.java\npublic interface JobStore {\n    void save(JobDefinition jobDef);\n    List&lt;JobDefinition&gt; loadAll();\n    void delete(String jobId);\n}\n\n// InMemoryJobStore.java\npublic class InMemoryJobStore implements JobStore {\n    private final Map&lt;String, JobDefinition&gt; store = new HashMap&lt;&gt;();\n\n    public void save(JobDefinition jobDef) {\n        store.put(jobDef.getJob().getId(), jobDef);\n    }\n    public List&lt;JobDefinition&gt; loadAll() {\n        return new ArrayList&lt;&gt;(store.values());\n    }\n    public void delete(String jobId) {\n        store.remove(jobId);\n    }\n}\n\n// JdbcJobStore.java\npublic class JdbcJobStore implements JobStore {\n    private final DataSource dataSource;\n\n    // constructor\n    public void save(JobDefinition jobDef) {\n        // JDBC code to save jobDef\n    }\n    public List&lt;JobDefinition&gt; loadAll() {\n        // JDBC code to load all jobDefs\n    }\n    public void delete(String jobId) {\n        // JDBC code to delete jobDef by jobId\n    }\n}\n\n// Scheduler.java\npublic class Scheduler {\n    private final PriorityBlockingQueue&lt;ScheduledJob&gt; jobQueue;\n    private final ThreadPoolExecutor workerPool;\n    private final List&lt;ScheduledJob&gt; scheduledJobs;\n\n    public Scheduler(int poolSize) {\n        this.jobQueue = new PriorityBlockingQueue&lt;&gt;();\n        this.workerPool = (ThreadPoolExecutor) Executors.newFixedThreadPool(poolSize);\n        this.scheduledJobs = new ArrayList&lt;&gt;();\n    }\n\n    public void schedule(JobDefinition jobDef) {\n        // calculate initial nextFireTime\n        ScheduledJob scheduledJob = new ScheduledJob(jobDef, nextFireTime, 0);\n        jobQueue.add(scheduledJob);\n        scheduledJobs.add(scheduledJob);\n    }\n\n    public void start() {\n        // start the scheduler thread\n    }\n\n    public void stop() {\n        // stop the scheduler and worker pool\n    }\n\n    private void executeJob(ScheduledJob scheduledJob) {\n        // job execution logic, including retry handling\n    }\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Cron-like%20Job%20Scheduler%20%28Priority%20%2B%20Retry%29/#4-sequence-diagram-scheduling-a-job","title":"4. Sequence Diagram: Scheduling a Job","text":"<pre><code>User -&gt; Scheduler: schedule(jobDef)\nScheduler -&gt; JobQueue: add(scheduledJob)\nScheduler -&gt; WorkerPool: submit(job)\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Cron-like%20Job%20Scheduler%20%28Priority%20%2B%20Retry%29/#5-sequence-diagram-job-execution-and-retry","title":"5. Sequence Diagram: Job Execution and Retry","text":"<pre><code>Scheduler -&gt; JobQueue: poll()\nJobQueue -&gt; WorkerPool: take(scheduledJob)\nWorkerPool -&gt; Job: run()\nalt job fails\n    Scheduler -&gt; ScheduledJob: incrementRetry()\n    alt max retries not reached\n        Scheduler -&gt; JobQueue: add(scheduledJob)\n    else\n        Scheduler -&gt; JobStore: delete(jobId)\n    end\nend\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Cron-like%20Job%20Scheduler%20%28Priority%20%2B%20Retry%29/#6-considerations-for-distributed-system-extension","title":"6. Considerations for Distributed System Extension","text":"<ul> <li>Introduce a consensus mechanism (e.g., ZooKeeper, Raft) for job coordination.</li> <li>Store job definitions and states in a distributed database.</li> <li>Ensure exactly-once execution semantics, possibly using unique job tokens.</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Cron-like%20Job%20Scheduler%20%28Priority%20%2B%20Retry%29/#7-potential-enhancements","title":"7. Potential Enhancements","text":"<ul> <li>Dynamic Scaling: Adjust the pool size of the worker threads based on the system load.</li> <li>Job Priority Inversion Handling: Implement measures to prevent low-priority jobs from starving high-priority ones.</li> <li>More Triggers: Add triggers like <code>DailyTrigger</code>, <code>MonthlyTrigger</code>, or custom cron-like expressions.</li> <li>Web Interface: A simple UI to monitor and manage scheduled jobs.</li> <li>Alerting: Notify users/administrators of job failures or retries.</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Cron-like%20Job%20Scheduler%20%28Priority%20%2B%20Retry%29/#8-conclusion","title":"8. Conclusion","text":"<p>This document describes a robust cron-like job scheduler's design, focusing on priority-based execution and retry mechanisms. The proposed system is flexible, allowing various job triggers and providing strong guarantees on job execution. With careful consideration of the requirements and a clear design, this scheduler can be a vital component in any Java application needing background task processing.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Distributed%20ID%20Generator%20%28Snowflake-like%29/","title":"Distributed ID Generator (Snowflake-like)","text":"<p>This problem requires designing a distributed, sortable 64-bit ID generator (like Twitter Snowflake) that works across datacenters and workers.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Distributed%20ID%20Generator%20%28Snowflake-like%29/#1-system-overview-scope-clarification","title":"1. System Overview &amp; Scope Clarification","text":"<p>We are designing a backend service to generate unique, time-sortable IDs for distributed systems.</p> <p>Functional Requirements (FR): - Generate 64-bit IDs composed of timestamp, datacenter, worker, and sequence. - Ensure uniqueness and monotonicity within a millisecond. - Handle clock skew and rollover. - Thread-safe for concurrent requests.</p> <p>Non-Functional Requirements (NFR): - High throughput (10k+ IDs/sec per node). - Low latency (sub-millisecond per call). - Fault-tolerant: no duplicate IDs on restart. - Scalable: support for many datacenters and workers.</p> <p>Assumptions: - Each instance is assigned a unique datacenter and worker ID. - System clock is NTP-synchronized. - State can be persisted locally (for last timestamp).</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Distributed%20ID%20Generator%20%28Snowflake-like%29/#2-core-components-and-class-design","title":"2. Core Components and Class Design","text":"<ul> <li>IdGenerator: Main class for generating IDs.</li> <li>Clock: Abstraction for time (for testing/skew handling).</li> <li>Persistence: Interface to persist last timestamp (optional for in-memory demo).</li> </ul> <p>Class Diagram (Textual Representation):</p> <pre><code>+-------------------+\n|   IdGenerator     |\n+-------------------+\n| + nextId()        |\n| - lastTimestamp   |\n| - sequence        |\n| - workerId        |\n| - datacenterId    |\n+-------------------+\n        ^\n        |\n+-------------------+\n|     Clock         |\n+-------------------+\n| + now()           |\n+-------------------+\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Distributed%20ID%20Generator%20%28Snowflake-like%29/#3-api-design-idgenerator","title":"3. API Design (<code>IdGenerator</code>)","text":"<p>Java</p> <pre><code>class IdGenerator {\n    long nextId();\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Distributed%20ID%20Generator%20%28Snowflake-like%29/#4-key-workflows","title":"4. Key Workflows","text":"<p>a) ID Generation 1. Get current timestamp (ms). 2. If timestamp &lt; lastTimestamp: wait until lastTimestamp or throw error. 3. If timestamp == lastTimestamp: increment sequence; if sequence overflows, wait for next ms. 4. If timestamp &gt; lastTimestamp: reset sequence to 0. 5. Compose ID: <code>(timestamp &lt;&lt; 22) | (datacenterId &lt;&lt; 17) | (workerId &lt;&lt; 12) | sequence</code>. 6. Persist lastTimestamp.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Distributed%20ID%20Generator%20%28Snowflake-like%29/#5-code-implementation-java","title":"5. Code Implementation (Java)","text":"<pre><code>public class IdGenerator {\n    private final long workerId;\n    private final long datacenterId;\n    private long sequence = 0L;\n    private long lastTimestamp = -1L;\n    private static final long EPOCH = 1609459200000L; // 2021-01-01\n    private static final long WORKER_ID_BITS = 5L;\n    private static final long DATACENTER_ID_BITS = 5L;\n    private static final long SEQUENCE_BITS = 12L;\n    private static final long MAX_WORKER_ID = ~(-1L &lt;&lt; WORKER_ID_BITS);\n    private static final long MAX_DATACENTER_ID = ~(-1L &lt;&lt; DATACENTER_ID_BITS);\n    private static final long SEQUENCE_MASK = ~(-1L &lt;&lt; SEQUENCE_BITS);\n    public IdGenerator(long workerId, long datacenterId) {\n        if (workerId &gt; MAX_WORKER_ID || workerId &lt; 0) throw new IllegalArgumentException();\n        if (datacenterId &gt; MAX_DATACENTER_ID || datacenterId &lt; 0) throw new IllegalArgumentException();\n        this.workerId = workerId;\n        this.datacenterId = datacenterId;\n    }\n    public synchronized long nextId() {\n        long timestamp = System.currentTimeMillis();\n        if (timestamp &lt; lastTimestamp) {\n            throw new RuntimeException(\"Clock moved backwards\");\n        }\n        if (timestamp == lastTimestamp) {\n            sequence = (sequence + 1) &amp; SEQUENCE_MASK;\n            if (sequence == 0) {\n                // Sequence overflow, wait for next ms\n                while ((timestamp = System.currentTimeMillis()) &lt;= lastTimestamp) {}\n            }\n        } else {\n            sequence = 0L;\n        }\n        lastTimestamp = timestamp;\n        return ((timestamp - EPOCH) &lt;&lt; 22)\n            | (datacenterId &lt;&lt; 17)\n            | (workerId &lt;&lt; 12)\n            | sequence;\n    }\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Distributed%20ID%20Generator%20%28Snowflake-like%29/#6-testing-junit-5","title":"6. Testing (JUnit 5)","text":"<pre><code>import org.junit.jupiter.api.*;\nimport static org.junit.jupiter.api.Assertions.*;\n\npublic class IdGeneratorTest {\n    @Test\n    void testMonotonicity() {\n        IdGenerator gen = new IdGenerator(1, 1);\n        long prev = gen.nextId();\n        for (int i = 0; i &lt; 1000; i++) {\n            long id = gen.nextId();\n            assertTrue(id &gt; prev);\n            prev = id;\n        }\n    }\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Distributed%20ID%20Generator%20%28Snowflake-like%29/#7-concurrency-fault-tolerance-and-scalability","title":"7. Concurrency, Fault Tolerance, and Scalability","text":"<ul> <li>Use <code>synchronized</code> for thread safety.</li> <li>Persist lastTimestamp to disk for crash recovery.</li> <li>Assign worker/datacenter IDs via config or coordination service (e.g., Zookeeper).</li> <li>Use NTP for clock sync; monitor for skew.</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Elevator%20Controller%20%28N%20Elevators%29/","title":"Elevator Controller (N Elevators)","text":"<p>This problem requires designing a multi-elevator controller to efficiently schedule elevator cars and minimize wait times.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Elevator%20Controller%20%28N%20Elevators%29/#1-system-overview-scope-clarification","title":"1. System Overview &amp; Scope Clarification","text":"<p>We are designing a backend service to manage N elevators in a building, handling hall and cab calls, and optimizing scheduling.</p> <p>Functional Requirements (FR): - Handle hall (up/down) and cab (floor) calls. - Support multiple elevator states: IDLE, MOVING, DOOR_OPEN. - Assign calls to elevators using a scheduling algorithm. - Support group control and peak modes.</p> <p>Non-Functional Requirements (NFR): - Real-time responsiveness. - Scalable to large buildings (10+ elevators, 100+ floors). - Safety: door interlocks, overload protection.</p> <p>Assumptions: - Each elevator has a unique ID and state. - All state is in-memory for demo; production would use distributed state.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Elevator%20Controller%20%28N%20Elevators%29/#2-core-components-and-class-design","title":"2. Core Components and Class Design","text":"<ul> <li>Elevator: Represents an elevator car.</li> <li>Scheduler: Assigns calls to elevators.</li> <li>Call: Represents a hall or cab call.</li> <li>ElevatorState: Enum for IDLE, MOVING, DOOR_OPEN.</li> </ul> <p>Class Diagram (Textual Representation):</p> <pre><code>+-----------+      +-----------+\n| Elevator  |&lt;-----| Scheduler |\n+-----------+      +-----------+\n| id        |      | assign()  |\n| current   |      +-----------+\n| direction |\n| queue     |\n| state     |\n+-----------+\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Elevator%20Controller%20%28N%20Elevators%29/#3-api-design-scheduler","title":"3. API Design (<code>Scheduler</code>)","text":"<p>Java</p> <pre><code>class Scheduler {\n    void assign(Call call);\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Elevator%20Controller%20%28N%20Elevators%29/#4-key-workflows","title":"4. Key Workflows","text":"<p>a) Assign Call 1. Receive call (hall/cab). 2. Find best elevator (nearest, least busy, etc.). 3. Add call to elevator's queue. 4. Update elevator state.</p> <p>b) Elevator Movement 1. Elevator processes queue. 2. Moves to next floor, opens door, handles passengers. 3. Updates state.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Elevator%20Controller%20%28N%20Elevators%29/#5-code-implementation-java","title":"5. Code Implementation (Java)","text":"<pre><code>import java.util.*;\n\nenum ElevatorState { IDLE, MOVING, DOOR_OPEN }\nenum Direction { UP, DOWN, NONE }\n\nclass Call {\n    int floor;\n    Direction direction;\n    boolean isHallCall;\n    // ...constructors, getters...\n}\n\nclass Elevator {\n    int id;\n    int currentFloor;\n    Direction direction = Direction.NONE;\n    Queue&lt;Integer&gt; queue = new LinkedList&lt;&gt;();\n    ElevatorState state = ElevatorState.IDLE;\n    // ...constructors, methods...\n}\n\nclass Scheduler {\n    List&lt;Elevator&gt; elevators;\n    public void assign(Call call) {\n        // Find best elevator (nearest, idle, etc.)\n        Elevator best = null;\n        int minDist = Integer.MAX_VALUE;\n        for (Elevator e : elevators) {\n            int dist = Math.abs(e.currentFloor - call.floor);\n            if (dist &lt; minDist &amp;&amp; (e.state == ElevatorState.IDLE || e.direction == call.direction)) {\n                minDist = dist;\n                best = e;\n            }\n        }\n        if (best != null) best.queue.add(call.floor);\n    }\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Elevator%20Controller%20%28N%20Elevators%29/#6-testing-junit-5","title":"6. Testing (JUnit 5)","text":"<pre><code>import org.junit.jupiter.api.*;\nimport static org.junit.jupiter.api.Assertions.*;\n\npublic class ElevatorControllerTest {\n    @Test\n    void testAssignCall() {\n        // Setup elevators, scheduler, calls\n        // Assign call, assert queue\n    }\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Elevator%20Controller%20%28N%20Elevators%29/#7-extensions-and-edge-cases","title":"7. Extensions and Edge Cases","text":"<ul> <li>Add Look/SCAN algorithm for better scheduling.</li> <li>Handle peak/idle modes, group control.</li> <li>Add safety checks for doors, overload, etc.</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Feature%20Flag%20Service%20%28Local%29/","title":"Feature Flag Service (Local)","text":"<p>This problem requires designing an in-process feature flag (also known as a feature toggle) system. This service allows developers to modify system behavior without changing code, enabling practices like canary releases, A/B testing, and trunk-based development by decoupling feature deployment from code deployment.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Feature%20Flag%20Service%20%28Local%29/#1-system-overview-scope-clarification","title":"1. System Overview &amp; Scope Clarification","text":"<p>We are building a library or component that an application can use to check if a feature is enabled for a given context (e.g., a specific user or request). The configuration for these flags will be loaded from a local source (like a JSON file) and must be reloadable at runtime without an application restart (\"hot-reloading\").</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Feature%20Flag%20Service%20%28Local%29/#2-detailed-design","title":"2. Detailed Design","text":""},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Feature%20Flag%20Service%20%28Local%29/#21-feature-flag-structure","title":"2.1. Feature Flag Structure","text":"<p>Each feature flag will have the following attributes:</p> <ul> <li>Name: A unique identifier for the feature flag.</li> <li>Enabled: A boolean indicating if the feature is enabled.</li> <li>Rollout Percentage: An optional field to specify a percentage of users for gradual rollouts.</li> <li>Conditions: Optional rules based on user attributes or request parameters.</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Feature%20Flag%20Service%20%28Local%29/#22-configuration-storage","title":"2.2. Configuration Storage","text":"<p>Feature flags will be stored in a local JSON file with the following structure:</p> <pre><code>{\n  \"featureFlags\": [\n    {\n      \"name\": \"newFeature\",\n      \"enabled\": true,\n      \"rolloutPercentage\": 50,\n      \"conditions\": {\n        \"userId\": \"12345\"\n      }\n    }\n  ]\n}\n</code></pre> <p>The configuration file must be specified at service startup and cannot be changed without restarting the service.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Feature%20Flag%20Service%20%28Local%29/#23-api","title":"2.3. API","text":"<p>The service will provide the following API:</p> <ul> <li><code>isFeatureEnabled(featureName, context)</code>: Returns a boolean indicating if the feature is enabled for the given context.</li> <li><code>getAllFeatures()</code>: Returns a list of all feature flags and their statuses.</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Feature%20Flag%20Service%20%28Local%29/#24-hot-reloading","title":"2.4. Hot-reloading","text":"<p>The service will watch the configuration file for changes and automatically reload the feature flags without requiring a restart. This will be done using file system notifications.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Feature%20Flag%20Service%20%28Local%29/#3-implementation","title":"3. Implementation","text":""},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Feature%20Flag%20Service%20%28Local%29/#31-data-structures","title":"3.1. Data Structures","text":"<pre><code>class FeatureFlag:\n    def __init__(self, name, enabled, rollout_percentage=None, conditions=None):\n        self.name = name\n        self.enabled = enabled\n        self.rollout_percentage = rollout_percentage\n        self.conditions = conditions or {}\n\nclass FeatureFlagService:\n    def __init__(self, config_file):\n        self.config_file = config_file\n        self.feature_flags = {}\n        self.load_flags()\n\n    def load_flags(self):\n        with open(self.config_file, 'r') as f:\n            config = json.load(f)\n            for flag in config['featureFlags']:\n                self.feature_flags[flag['name']] = FeatureFlag(**flag)\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Feature%20Flag%20Service%20%28Local%29/#32-api-implementation","title":"3.2. API Implementation","text":"<pre><code>from flask import Flask, request, jsonify\n\napp = Flask(__name__)\nservice = FeatureFlagService('path/to/config.json')\n\n@app.route('/feature-flag/&lt;feature_name&gt;', methods=['GET'])\ndef is_feature_enabled(feature_name):\n    context = request.args.to_dict()\n    enabled = service.is_feature_enabled(feature_name, context)\n    return jsonify({\"enabled\": enabled})\n\n@app.route('/feature-flags', methods=['GET'])\ndef get_all_features():\n    flags = service.get_all_features()\n    return jsonify(flags)\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Feature%20Flag%20Service%20%28Local%29/#33-hot-reloading-implementation","title":"3.3. Hot-reloading Implementation","text":"<pre><code>import os\nimport time\n\nclass FeatureFlagService:\n    # ... existing methods ...\n\n    def watch_config_file(self):\n        last_mtime = os.path.getmtime(self.config_file)\n        while True:\n            time.sleep(1)\n            current_mtime = os.path.getmtime(self.config_file)\n            if current_mtime != last_mtime:\n                last_mtime = current_mtime\n                self.load_flags()\n\n    def start(self):\n        import threading\n        threading.Thread(target=self.watch_config_file, daemon=True).start()\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Feature%20Flag%20Service%20%28Local%29/#4-testing","title":"4. Testing","text":""},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Feature%20Flag%20Service%20%28Local%29/#41-unit-tests","title":"4.1. Unit Tests","text":"<ul> <li>Test loading feature flags from the configuration file.</li> <li>Test the <code>is_feature_enabled</code> and <code>get_all_features</code> methods.</li> <li>Test the hot-reloading functionality.</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Feature%20Flag%20Service%20%28Local%29/#42-integration-tests","title":"4.2. Integration Tests","text":"<ul> <li>Test the API endpoints with different scenarios (feature enabled/disabled, user in/out of rollout percentage, etc.).</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Feature%20Flag%20Service%20%28Local%29/#5-deployment","title":"5. Deployment","text":"<ul> <li>Package the service as a Docker container.</li> <li>Mount the configuration file as a read-only volume.</li> <li>Ensure the service has permission to read the configuration file and access the file system notifications.</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Feature%20Flag%20Service%20%28Local%29/#6-monitoring-logging","title":"6. Monitoring &amp; Logging","text":"<ul> <li>Integrate with a logging framework to log feature flag evaluations and configuration reloads.</li> <li>Expose metrics (e.g., number of times a feature is enabled/disabled) to a monitoring system.</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Feature%20Flag%20Service%20%28Local%29/#7-security-considerations","title":"7. Security Considerations","text":"<ul> <li>Validate and sanitize all inputs to the API to prevent injection attacks.</li> <li>Ensure the configuration file is not accessible from the outside world and is protected from unauthorized access.</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Feature%20Flag%20Service%20%28Local%29/#8-future-enhancements","title":"8. Future Enhancements","text":"<ul> <li>Support for nested conditions and more complex rules for feature enablement.</li> <li>Integration with a remote configuration service as an alternative to the local JSON file.</li> <li>A web-based dashboard for real-time monitoring and management of feature flags.</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/In-Memory%20File%20System%20%28Simplified%29/","title":"In-Memory File System (Simplified)","text":"<p>This problem requires designing an in-memory file system supporting basic file and directory operations.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/In-Memory%20File%20System%20%28Simplified%29/#1-system-overview-scope-clarification","title":"1. System Overview &amp; Scope Clarification","text":"<p>We are designing a backend service to support file and directory operations (mkdir, ls, create, read, write, move, delete) in memory.</p> <p>Functional Requirements (FR): - Support mkdir, ls, create, read, write, move, delete. - Hierarchical directory structure. - Path resolution (e.g., /a/b/c.txt).</p> <p>Non-Functional Requirements (NFR): - Fast (O(1) or O(logN) per op). - Thread-safe for concurrent access. - No persistence required (demo only).</p> <p>Assumptions: - All state is in-memory. - No permissions or journaling for this round.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/In-Memory%20File%20System%20%28Simplified%29/#2-core-components-and-class-design","title":"2. Core Components and Class Design","text":"<ul> <li>Node: Abstract base for File and Directory.</li> <li>File: Stores data and metadata.</li> <li>Directory: Contains children (files/directories).</li> <li>FileSystem: Main API for file ops and path resolution.</li> </ul> <p>Class Diagram (Textual Representation):</p> <pre><code>+----------+      +----------+\n|  Node    |&lt;-----| Directory|\n+----------+      +----------+\n| name     |      | children |\n+----------+      +----------+\n      ^\n      |\n+----------+\n|  File    |\n+----------+\n| data     |\n| meta     |\n+----------+\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/In-Memory%20File%20System%20%28Simplified%29/#3-api-design-filesystem","title":"3. API Design (<code>FileSystem</code>)","text":"<p>Java</p> <pre><code>class FileSystem {\n    void mkdir(String path);\n    void create(String path);\n    void write(String path, byte[] data);\n    byte[] read(String path);\n    void delete(String path);\n    List&lt;String&gt; ls(String path);\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/In-Memory%20File%20System%20%28Simplified%29/#4-key-workflows","title":"4. Key Workflows","text":"<p>a) mkdir / create 1. Parse path, traverse tree, create nodes as needed.</p> <p>b) read / write 1. Resolve path to File node. 2. Read or write data.</p> <p>c) ls 1. Resolve path to Directory node. 2. List children names.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/In-Memory%20File%20System%20%28Simplified%29/#5-code-implementation-java","title":"5. Code Implementation (Java)","text":"<pre><code>import java.util.*;\n\nabstract class Node {\n    String name;\n}\n\nclass File extends Node {\n    byte[] data;\n    Map&lt;String, String&gt; meta = new HashMap&lt;&gt;();\n}\n\nclass Directory extends Node {\n    Map&lt;String, Node&gt; children = new HashMap&lt;&gt;();\n}\n\nclass FileSystem {\n    private final Directory root = new Directory();\n    public FileSystem() { root.name = \"/\"; }\n    public void mkdir(String path) {\n        resolveOrCreate(path, true);\n    }\n    public void create(String path) {\n        String[] parts = path.split(\"/\");\n        Directory dir = (Directory)resolveOrCreate(String.join(\"/\", Arrays.copyOf(parts, parts.length-1)), true);\n        File file = new File();\n        file.name = parts[parts.length-1];\n        dir.children.put(file.name, file);\n    }\n    public void write(String path, byte[] data) {\n        File file = (File)resolve(path);\n        file.data = data;\n    }\n    public byte[] read(String path) {\n        File file = (File)resolve(path);\n        return file.data;\n    }\n    public void delete(String path) {\n        String[] parts = path.split(\"/\");\n        Directory dir = (Directory)resolve(String.join(\"/\", Arrays.copyOf(parts, parts.length-1)));\n        dir.children.remove(parts[parts.length-1]);\n    }\n    public List&lt;String&gt; ls(String path) {\n        Node node = resolve(path);\n        if (node instanceof Directory) return new ArrayList&lt;&gt;(((Directory)node).children.keySet());\n        else return List.of(node.name);\n    }\n    private Node resolve(String path) {\n        String[] parts = path.split(\"/\");\n        Node curr = root;\n        for (String p : parts) {\n            if (p.isEmpty()) continue;\n            if (!(curr instanceof Directory)) throw new RuntimeException(\"Not a directory\");\n            curr = ((Directory)curr).children.get(p);\n            if (curr == null) throw new RuntimeException(\"Not found\");\n        }\n        return curr;\n    }\n    private Node resolveOrCreate(String path, boolean isDir) {\n        String[] parts = path.split(\"/\");\n        Node curr = root;\n        for (String p : parts) {\n            if (p.isEmpty()) continue;\n            Directory dir = (Directory)curr;\n            curr = dir.children.get(p);\n            if (curr == null) {\n                curr = isDir ? new Directory() : new File();\n                curr.name = p;\n                dir.children.put(p, curr);\n            }\n        }\n        return curr;\n    }\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/In-Memory%20File%20System%20%28Simplified%29/#6-testing-junit-5","title":"6. Testing (JUnit 5)","text":"<pre><code>import org.junit.jupiter.api.*;\nimport static org.junit.jupiter.api.Assertions.*;\n\npublic class FileSystemTest {\n    @Test\n    void testCreateAndRead() {\n        FileSystem fs = new FileSystem();\n        fs.mkdir(\"/a\");\n        fs.create(\"/a/b.txt\");\n        fs.write(\"/a/b.txt\", \"hello\".getBytes());\n        assertArrayEquals(\"hello\".getBytes(), fs.read(\"/a/b.txt\"));\n    }\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/In-Memory%20File%20System%20%28Simplified%29/#7-extensions-and-edge-cases","title":"7. Extensions and Edge Cases","text":"<ul> <li>Add permissions, journaling, and persistence.</li> <li>Support for move/rename, symlinks, and quotas.</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/LRU%20Cache%20with%20TTL%20and%20Write-Back/","title":"LRU Cache with TTL and Write-Back","text":"<p>This problem requires designing a high-performance, thread-safe, in-memory cache that evicts items based on a Least Recently Used (LRU) policy, supports Time-To-Live (TTL) expiration, and provides an optional, asynchronous write-back mechanism to a backing store.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/LRU%20Cache%20with%20TTL%20and%20Write-Back/#1-system-overview-scope-clarification","title":"1. System Overview &amp; Scope Clarification","text":"<p>We are building a generic, in-memory key-value cache. It's a fundamental component in many systems for reducing latency and load on slower backend services like databases.</p> <p>Functional Requirements (FR):</p> <ul> <li><code>get(key)</code>: Retrieve a value. If the item has expired, it should be treated as a miss.</li> <li><code>put(key, value, ttl)</code>: Insert or update a key-value pair with an optional TTL.</li> <li><code>delete(key)</code>: Explicitly remove an item from the cache.</li> <li>LRU Eviction: When the cache reaches its capacity, the least recently used item must be removed to make space.</li> <li>TTL Expiration: Items with a TTL should become inaccessible after the duration has passed. Expiration should be checked lazily on access.</li> <li>Write-Back Caching: When a \"dirty\" item (one that has been <code>put</code> or modified) is evicted or deleted, it should be asynchronously written to a persistent backing store.</li> </ul> <p>Non-Functional Requirements (NFR):</p> <ul> <li>Performance: <code>get</code> and <code>put</code> operations should be O(1) on average.</li> <li>Thread-Safety: The cache must be safe to use from multiple concurrent threads.</li> </ul> <p>Assumptions:</p> <ul> <li>The <code>BackingStore</code> (e.g., a database client) will be provided via an interface.</li> <li>The cache will handle its own background thread management for the write-back process.</li> <li>We will use a \"write-through\" approach conceptually, where a <code>put</code> makes an entry \"dirty,\" and the write to the backing store is deferred until eviction.</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/LRU%20Cache%20with%20TTL%20and%20Write-Back/#2-core-components-and-class-design","title":"2. Core Components and Class Design","text":"<p>The classic implementation for an LRU cache uses a combination of a <code>HashMap</code> for fast O(1) lookups and a doubly linked list to maintain the O(1) ordering of items by recency.</p> <ul> <li><code>LRUCacheWithWriteBack&lt;K, V&gt;</code>: The main public class. It encapsulates all logic, including the data structures, locking, and the write-back worker.</li> <li><code>Node&lt;K, V&gt;</code>: A private inner class representing an entry in the cache. It holds the key, value, expiration time, a <code>dirty</code> flag for the write-back logic, and pointers (<code>prev</code>, <code>next</code>) for the doubly linked list.</li> <li><code>BackingStore&lt;K, V&gt;</code>: An interface that the user of our cache must implement. This decouples the cache from any specific database or storage technology. It will have a <code>write(key, value)</code> and <code>delete(key)</code> method.</li> <li>Write-Back Mechanism: This will be implemented using a <code>java.util.concurrent.BlockingQueue</code> to hold evicted dirty nodes and a dedicated <code>ExecutorService</code> (a single background thread) to consume from the queue and interact with the <code>BackingStore</code>.</li> </ul> <p>Class Diagram (Textual Representation):</p> <p><code>+--------------------------------+ |  LRUCacheWithWriteBack&lt;K, V&gt;   | |--------------------------------| | - capacity: int                | | - lock: ReentrantLock          | | - map: HashMap&lt;K, Node&lt;K, V&gt;&gt;  | | - head, tail: Node&lt;K, V&gt;       | | - backingStore: BackingStore   | | - writeBackQueue: BlockingQueue| | - writerExecutor: ExecutorSvc  | |--------------------------------| | + get(key): V                  | | + put(key, value, ttl, unit)   | | + delete(key): void            | | + shutdown(): void             | +--------------------------------+           |           | contains           v +--------------------------------+ |      &lt;&lt;private inner&gt;&gt;         | |         Node&lt;K, V&gt;             | |--------------------------------| | - key: K                       | | - value: V                     | | - expireAtNanos: long          | | - dirty: boolean               | | - prev, next: Node&lt;K, V&gt;       | +--------------------------------+           |           | uses           v +-----------------------------+ |      &lt;&lt;interface&gt;&gt;          | |     BackingStore&lt;K, V&gt;      | |-----------------------------| | + write(key, value): void   | | + delete(key): void         | +-----------------------------+</code></p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/LRU%20Cache%20with%20TTL%20and%20Write-Back/#3-api-design-lrucachewithwriteback","title":"3. API Design (<code>LRUCacheWithWriteBack</code>)","text":"<p>Java</p> <p>`public class LRUCacheWithWriteBack { <pre><code>// Constructor to initialize capacity and backing store.\npublic LRUCacheWithWriteBack(int capacity, BackingStore&lt;K, V&gt; backingStore);\n\n// Get a value from the cache. Returns null if not found or expired.\npublic V get(K key);\n\n// Put a value with a specific TTL. Marks the entry as dirty for write-back.\npublic void put(K key, V value, long ttl, TimeUnit unit);\n\n// Put a value with no expiration.\npublic void put(K key, V value);\n\n// Remove a value from the cache. If the item was dirty, it's queued for deletion from the backing store.\npublic void delete(K key);\n\n// Shuts down the write-back worker thread gracefully.\npublic void shutdown();\n</code></pre> <p>}`</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/LRU%20Cache%20with%20TTL%20and%20Write-Back/#4-key-workflows","title":"4. Key Workflows","text":"<p>a) <code>get(key)</code> Workflow</p> <ol> <li>Acquire the global <code>ReentrantLock</code>.</li> <li>Look up the <code>Node</code> in the <code>HashMap</code>. If not found, release the lock and return <code>null</code>.</li> <li>Check if the node is expired (<code>System.nanoTime() &gt; node.expireAtNanos</code>).<ul> <li>If expired, call a private <code>removeNode()</code> helper. This helper will remove it from the list and map. Crucially, expired items are NOT written back as their data is considered stale.</li> <li>Release lock and return <code>null</code>.</li> </ul> </li> <li>If the node is valid, move it to the front of the doubly linked list (marking it as most recently used).</li> <li>Release the lock and return the node's value.</li> </ol> <p>b) <code>put(key, value, ttl)</code> Workflow</p> <ol> <li>Acquire the global <code>ReentrantLock</code>.</li> <li>Check if the key already exists in the <code>HashMap</code>.<ul> <li>If it exists: Update the node's value, set its <code>dirty</code> flag to <code>true</code>, update its <code>expireAtNanos</code>, and move it to the front of the list.</li> <li>If it's new: a. Check if the cache is at capacity (<code>map.size() &gt;= capacity</code>). b. If so, evict the LRU item (the node just before <code>tail</code>). Call <code>removeNode()</code> on it. c. Inside <code>removeNode()</code>, if the evicted node was <code>dirty</code>, add it to the <code>writeBackQueue</code>. d. Create a new <code>Node</code> with the key, value, expiration, and <code>dirty = true</code>. e. Add the new node to the <code>HashMap</code> and insert it at the front of the list.</li> </ul> </li> <li>Release the lock.</li> </ol> <p>c) Write-Back Worker (Background Thread)</p> <ol> <li>The worker thread runs in a loop, calling <code>writeBackQueue.take()</code>. This call blocks until an item is available.</li> <li>When a <code>Node</code> is dequeued, the worker calls the appropriate <code>BackingStore</code> method. We can add a special marker for deletion vs. update. A simple way is to check if the <code>value</code> is null.</li> <li>It calls <code>backingStore.write(node.key, node.value)</code> or <code>backingStore.delete(node.key)</code>.</li> <li>This loop is wrapped in a <code>try-catch</code> block to handle exceptions from the <code>BackingStore</code> (e.g., database connection issues), allowing the worker to log the error and continue processing other items. A retry mechanism could be added here.</li> </ol>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/LRU%20Cache%20with%20TTL%20and%20Write-Back/#5-code-implementation-java","title":"5. Code Implementation (Java)","text":"<p>Java</p> <pre><code>import java.util.HashMap;\nimport java.util.Map;\nimport java.util.concurrent.*;\nimport java.util.concurrent.locks.ReentrantLock;\n\npublic class LRUCacheWithWriteBack&lt;K, V&gt; {\n\n    // Interface for the backing store\n    public interface BackingStore&lt;K, V&gt; {\n        void write(K key, V value);\n        void delete(K key);\n    }\n\n    private static class Node&lt;K, V&gt; {\n        final K key;\n        V value;\n        long expireAtNanos;\n        boolean dirty;\n        Node&lt;K, V&gt; prev, next;\n\n        Node(K key, V value, long expireAtNanos) {\n            this.key = key;\n            this.value = value;\n            this.expireAtNanos = expireAtNanos;\n            this.dirty = false;\n        }\n    }\n\n    private final int capacity;\n    private final BackingStore&lt;K, V&gt; backingStore;\n    private final Map&lt;K, Node&lt;K, V&gt;&gt; map;\n    private final Node&lt;K, V&gt; head, tail;\n    private final ReentrantLock lock = new ReentrantLock();\n\n    private final BlockingQueue&lt;Node&lt;K, V&gt;&gt; writeBackQueue;\n    private final ExecutorService writerExecutor;\n    private static final Node DELETED_MARKER = new Node&lt;&gt;(null, null, 0);\n\n    public LRUCacheWithWriteBack(int capacity, BackingStore&lt;K, V&gt; backingStore) {\n        this.capacity = capacity;\n        this.backingStore = backingStore;\n        this.map = new HashMap&lt;&gt;(capacity);\n        this.head = new Node&lt;&gt;(null, null, 0);\n        this.tail = new Node&lt;&gt;(null, null, 0);\n        head.next = tail;\n        tail.prev = head;\n\n        if (backingStore != null) {\n            this.writeBackQueue = new LinkedBlockingQueue&lt;&gt;();\n            this.writerExecutor = Executors.newSingleThreadExecutor(r -&gt; {\n                Thread t = new Thread(r, \"cache-writer-thread\");\n                t.setDaemon(true);\n                return t;\n            });\n            this.writerExecutor.submit(this::writeBackProcessor);\n        } else {\n            this.writeBackQueue = null;\n            this.writerExecutor = null;\n        }\n    }\n\n    public V get(K key) {\n        lock.lock();\n        try {\n            Node&lt;K, V&gt; node = map.get(key);\n            if (node == null) {\n                return null; // Cache miss\n            }\n            if (isExpired(node)) {\n                removeNode(node); // Lazy expiration\n                // Expired nodes are NOT written back\n                return null;\n            }\n            moveToFront(node);\n            return node.value;\n        } finally {\n            lock.unlock();\n        }\n    }\n\n    public void put(K key, V value, long ttl, TimeUnit unit) {\n        long expireAtNanos = (ttl &gt; 0) ? System.nanoTime() + unit.toNanos(ttl) : -1L;\n        lock.lock();\n        try {\n            Node&lt;K, V&gt; node = map.get(key);\n            if (node != null) { // Update existing node\n                node.value = value;\n                node.expireAtNanos = expireAtNanos;\n                node.dirty = true;\n                moveToFront(node);\n            } else { // Add new node\n                if (map.size() &gt;= capacity) {\n                    evictLru();\n                }\n                Node&lt;K, V&gt; newNode = new Node&lt;&gt;(key, value, expireAtNanos);\n                newNode.dirty = true;\n                map.put(key, newNode);\n                addToFront(newNode);\n            }\n        } finally {\n            lock.unlock();\n        }\n    }\n\n    public void put(K key, V value) {\n        put(key, value, -1, TimeUnit.SECONDS);\n    }\n\n    public void delete(K key) {\n        lock.lock();\n        try {\n            Node&lt;K, V&gt; node = map.remove(key);\n            if (node != null) {\n                removeNode(node);\n                if (backingStore != null &amp;&amp; node.dirty) {\n                    // Create a special marker for deletion\n                     Node&lt;K, V&gt; deleteMarker = new Node&lt;&gt;(node.key, null, 0);\n                    writeBackQueue.offer(deleteMarker);\n                }\n            }\n        } finally {\n            lock.unlock();\n        }\n    }\n\n    public void shutdown() {\n        if (writerExecutor != null) {\n            writerExecutor.shutdown();\n            try {\n                if (!writerExecutor.awaitTermination(5, TimeUnit.SECONDS)) {\n                    writerExecutor.shutdownNow();\n                }\n            } catch (InterruptedException e) {\n                writerExecutor.shutdownNow();\n            }\n        }\n    }\n\n    // --- Private helper methods ---\n\n    private void evictLru() {\n        Node&lt;K, V&gt; lruNode = tail.prev;\n        if (lruNode != head) {\n            removeNode(lruNode);\n            map.remove(lruNode.key);\n            if (backingStore != null &amp;&amp; lruNode.dirty) {\n                writeBackQueue.offer(lruNode);\n            }\n        }\n    }\n\n    private void writeBackProcessor() {\n        while (!Thread.currentThread().isInterrupted()) {\n            try {\n                Node&lt;K, V&gt; node = writeBackQueue.take();\n                if (node.value == null) { // This is our deletion marker\n                    backingStore.delete(node.key);\n                } else {\n                    backingStore.write(node.key, node.value);\n                }\n            } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n                break;\n            } catch (Exception e) {\n                // Log exception from backing store\n                System.err.println(\"Error writing back to store: \" + e.getMessage());\n            }\n        }\n    }\n\n    private boolean isExpired(Node&lt;K, V&gt; node) {\n        return node.expireAtNanos &gt; 0 &amp;&amp; System.nanoTime() &gt; node.expireAtNanos;\n    }\n\n    private void moveToFront(Node&lt;K, V&gt; node) {\n        removeNode(node);\n        addToFront(node);\n    }\n\n    private void removeNode(Node&lt;K, V&gt; node) {\n        node.prev.next = node.next;\n        node.next.prev = node.prev;\n    }\n\n    private void addToFront(Node&lt;K, V&gt; node) {\n        node.next = head.next;\n        node.prev = head;\n        head.next.prev = node;\n        head.next = node;\n    }\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/LRU%20Cache%20with%20TTL%20and%20Write-Back/#6-testing-junit-5","title":"6. Testing (JUnit 5)","text":"<p>We'll use a mock <code>BackingStore</code> to verify the write-back logic.</p> <p>Java</p> <pre><code>import org.junit.jupiter.api.AfterEach;\nimport org.junit.jupiter.api.BeforeEach;\nimport org.junit.jupiter.api.Test;\nimport static org.junit.jupiter.api.Assertions.*;\n\nimport java.util.Map;\nimport java.util.concurrent.ConcurrentHashMap;\nimport java.util.concurrent.TimeUnit;\n\nclass LRUCacheWithWriteBackTest {\n\n    // A mock backing store for testing\n    static class MockBackingStore implements LRUCacheWithWriteBack.BackingStore&lt;String, String&gt; {\n        final Map&lt;String, String&gt; store = new ConcurrentHashMap&lt;&gt;();\n        @Override public void write(String key, String value) { store.put(key, value); }\n        @Override public void delete(String key) { store.remove(key); }\n    }\n\n    private LRUCacheWithWriteBack&lt;String, String&gt; cache;\n    private MockBackingStore mockStore;\n\n    @BeforeEach\n    void setUp() {\n        mockStore = new MockBackingStore();\n        cache = new LRUCacheWithWriteBack&lt;&gt;(3, mockStore);\n    }\n\n    @AfterEach\n    void tearDown() {\n        cache.shutdown();\n    }\n\n    @Test\n    void testBasicGetAndPut() {\n        cache.put(\"k1\", \"v1\");\n        assertEquals(\"v1\", cache.get(\"k1\"));\n        assertNull(cache.get(\"k2\"));\n    }\n\n    @Test\n    void testLruEviction() {\n        cache.put(\"k1\", \"v1\");\n        cache.put(\"k2\", \"v2\");\n        cache.put(\"k3\", \"v3\");\n        cache.get(\"k1\"); // k1 is now most recent\n        cache.put(\"k4\", \"v4\"); // k2 should be evicted\n\n        assertNull(cache.get(\"k2\"));\n        assertNotNull(cache.get(\"k1\"));\n        assertNotNull(cache.get(\"k3\"));\n        assertNotNull(cache.get(\"k4\"));\n    }\n\n    @Test\n    void testTtlExpiration() throws InterruptedException {\n        cache.put(\"k1\", \"v1\", 100, TimeUnit.MILLISECONDS);\n        assertNotNull(cache.get(\"k1\"));\n        Thread.sleep(150);\n        assertNull(cache.get(\"k1\")); // Should be expired\n    }\n\n    @Test\n    void testWriteBackOnEviction() throws InterruptedException {\n        cache.put(\"k1\", \"v1\");\n        cache.put(\"k2\", \"v2\");\n        cache.put(\"k3\", \"v3\");\n        cache.put(\"k4\", \"v4\"); // Evicts k1\n\n        // Give the writer thread a moment to process\n        Thread.sleep(50); \n\n        assertEquals(\"v1\", mockStore.store.get(\"k1\"));\n        assertNull(mockStore.store.get(\"k4\")); // k4 is in cache, not written back yet\n    }\n\n    @Test\n    void testNoWriteBackForCleanOrExpiredItems() throws InterruptedException {\n        cache.put(\"k1\", \"v1\", 50, TimeUnit.MILLISECONDS);\n        Thread.sleep(100);\n        cache.get(\"k1\"); // Triggers lazy expiration\n\n        cache.put(\"k2\", \"v2\");\n        cache.put(\"k3\", \"v3\");\n        cache.put(\"k4\", \"v4\"); // Evicts k2\n\n        Thread.sleep(50);\n\n        assertNull(mockStore.store.get(\"k1\")); // Expired items are not written\n    }\n\n    @Test\n    void testWriteBackOnDelete() throws InterruptedException {\n        cache.put(\"k1\", \"v1\");\n        cache.delete(\"k1\");\n\n        Thread.sleep(50);\n\n        assertNull(cache.get(\"k1\"));\n        assertFalse(mockStore.store.containsKey(\"k1\")); // Should be deleted from backing store\n    }\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/LRU%20Cache%20with%20TTL%20and%20Write-Back/#7-concurrency-performance-and-extensions","title":"7. Concurrency, Performance, and Extensions","text":"<ul> <li>Concurrency: The use of a single <code>ReentrantLock</code> makes the design simple and correct, but it serializes all access. For highly concurrent workloads with many CPU cores, this could become a bottleneck. A more advanced design might use segmented locking, where the cache is divided into several segments, each with its own lock, similar to how <code>ConcurrentHashMap</code> works. This increases complexity but improves throughput.</li> <li>Performance: All core operations (<code>get</code>, <code>put</code>, <code>delete</code>) are O(1) because they rely on <code>HashMap</code> lookups and simple pointer manipulations in the doubly linked list, all of which are constant time operations. The write-back mechanism operates on a separate thread, so it doesn't add latency to the cache operations themselves.</li> <li>Extensions:<ul> <li>Proactive Expiration: A dedicated \"sweeper\" thread could periodically scan the cache to remove expired items. This prevents the cache from holding onto a large number of expired-but-never-accessed items, which would otherwise waste memory.</li> <li>Read-Through Cache: The <code>get</code> method could be extended. If an item is not in the cache (a miss), the cache could then try to load it from the <code>BackingStore</code>, insert it into the cache, and then return it to the caller.</li> <li>Cache Statistics: The cache could be instrumented to expose metrics like hit rate, miss rate, eviction count, and the current size of the write-back queue. This is invaluable for monitoring and tuning performance.</li> <li>Graceful Shutdown: The <code>shutdown()</code> method is essential to ensure that on application exit, any pending writes in the queue are flushed to the backing store, preventing data loss.</li> </ul> </li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Market%20Data%20Fan-out%20%28Feed%20Handler%29/","title":"Market Data Fan-out (Feed Handler)","text":"<p>This problem involves designing a high-performance, low-latency market data fan-out service (feed handler) for a trading system. The service must ingest a stream of market data updates (e.g., order book changes, trades) and efficiently distribute them to many downstream consumers (e.g., trading algorithms, GUIs, risk systems) with minimal latency and high throughput.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Market%20Data%20Fan-out%20%28Feed%20Handler%29/#1-system-overview-scope-clarification","title":"1. System Overview &amp; Scope Clarification","text":"<ul> <li>Input: A single, high-volume stream of market data updates (e.g., from an exchange or internal matching engine).</li> <li>Output: Each update must be delivered to all registered consumers (subscribers) as quickly as possible.</li> <li>Requirements:<ul> <li>Low Latency: Updates must be fanned out to all consumers with minimal delay (microseconds to low milliseconds).</li> <li>High Throughput: Must support thousands to millions of updates per second.</li> <li>Backpressure Handling: Slow consumers must not block or degrade the performance for fast consumers.</li> <li>Reliability: No update should be lost for any consumer unless explicitly dropped due to backpressure policy.</li> <li>Thread-Safety: The system must be safe for concurrent use by multiple producers and consumers.</li> </ul> </li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Market%20Data%20Fan-out%20%28Feed%20Handler%29/#2-core-components-and-class-design","title":"2. Core Components and Class Design","text":"<ul> <li>FeedHandler: The main orchestrator. Receives updates and distributes them to all consumers.</li> <li>Consumer (Subscriber): An interface implemented by downstream systems. Each consumer gets its own queue/buffer.</li> <li>RingBuffer/Queue: Each consumer is assigned a bounded, lock-free queue (e.g., Disruptor RingBuffer or ArrayBlockingQueue) to decouple producer and consumer speeds.</li> <li>Backpressure Policy: If a consumer's queue is full, the system can either drop updates for that consumer, block the producer, or disconnect the slow consumer.</li> <li>Thread Model:<ul> <li>Single Producer, Multiple Consumers: The feed handler thread reads updates and enqueues them to each consumer's buffer.</li> <li>Each Consumer: Runs in its own thread, reading from its buffer and processing updates at its own pace.</li> </ul> </li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Market%20Data%20Fan-out%20%28Feed%20Handler%29/#3-api-design","title":"3. API Design","text":"<pre><code>public interface MarketDataConsumer {\n    void onMarketData(MarketDataUpdate update);\n}\n\npublic class MarketDataUpdate {\n    // e.g., order book snapshot, trade, etc.\n    // Fields: symbol, price, size, type, timestamp, etc.\n}\n\npublic class FeedHandler {\n    public void registerConsumer(MarketDataConsumer consumer);\n    public void unregisterConsumer(MarketDataConsumer consumer);\n    public void onMarketData(MarketDataUpdate update); // Called by producer\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Market%20Data%20Fan-out%20%28Feed%20Handler%29/#4-key-workflows","title":"4. Key Workflows","text":"<p>a) Registering a Consumer - FeedHandler creates a bounded queue for the consumer and starts a thread to deliver updates from the queue to the consumer's <code>onMarketData</code> method.</p> <p>b) Receiving an Update - FeedHandler receives a <code>MarketDataUpdate</code> from the producer. - For each registered consumer, it enqueues the update into the consumer's queue. - If the queue is full, apply the backpressure policy (e.g., drop, block, or disconnect).</p> <p>c) Consumer Processing - Each consumer thread dequeues updates and processes them independently. - If a consumer is slow, its queue fills up, and backpressure policy is triggered.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Market%20Data%20Fan-out%20%28Feed%20Handler%29/#5-code-implementation-java-simplified","title":"5. Code Implementation (Java, Simplified)","text":"<pre><code>import java.util.concurrent.*;\nimport java.util.*;\n\npublic interface MarketDataConsumer {\n    void onMarketData(MarketDataUpdate update);\n}\n\npublic class MarketDataUpdate {\n    public final String symbol;\n    public final double price;\n    public final int size;\n    public final String type; // e.g., \"TRADE\", \"BOOK\"\n    public final long timestamp;\n    public MarketDataUpdate(String symbol, double price, int size, String type, long timestamp) {\n        this.symbol = symbol; this.price = price; this.size = size; this.type = type; this.timestamp = timestamp;\n    }\n}\n\npublic class FeedHandler {\n    private final Map&lt;MarketDataConsumer, BlockingQueue&lt;MarketDataUpdate&gt;&gt; consumerQueues = new ConcurrentHashMap&lt;&gt;();\n    private final int queueCapacity = 1024; // Tune as needed\n    private final ExecutorService consumerThreads = Executors.newCachedThreadPool();\n\n    public void registerConsumer(MarketDataConsumer consumer) {\n        BlockingQueue&lt;MarketDataUpdate&gt; queue = new ArrayBlockingQueue&lt;&gt;(queueCapacity);\n        consumerQueues.put(consumer, queue);\n        consumerThreads.submit(() -&gt; {\n            try {\n                while (true) {\n                    MarketDataUpdate update = queue.take();\n                    consumer.onMarketData(update);\n                }\n            } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n            }\n        });\n    }\n\n    public void unregisterConsumer(MarketDataConsumer consumer) {\n        consumerQueues.remove(consumer);\n        // Optionally interrupt the consumer thread\n    }\n\n    public void onMarketData(MarketDataUpdate update) {\n        for (BlockingQueue&lt;MarketDataUpdate&gt; queue : consumerQueues.values()) {\n            // Backpressure policy: drop if full\n            queue.offer(update);\n        }\n    }\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Market%20Data%20Fan-out%20%28Feed%20Handler%29/#6-testing-and-extensions","title":"6. Testing and Extensions","text":"<ul> <li>Testing:<ul> <li>Simulate multiple consumers with different speeds.</li> <li>Verify that fast consumers get all updates, slow consumers may drop updates if their queue is full.</li> <li>Measure end-to-end latency.</li> </ul> </li> <li>Extensions:<ul> <li>Use a high-performance ring buffer (e.g., LMAX Disruptor) for even lower latency.</li> <li>Add metrics for dropped updates, queue sizes, and consumer lag.</li> <li>Support for consumer-specific filtering (e.g., only certain symbols).</li> <li>Add replay/buffering for late-joining consumers.</li> <li>Support for multiple producers (requires more advanced concurrency control).</li> </ul> </li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Meeting%20Room%20Scheduler/","title":"Meeting Room Scheduler","text":"<p>This problem requires designing a meeting room booking system that avoids conflicts and supports search by capacity/resources.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Meeting%20Room%20Scheduler/#1-system-overview-scope-clarification","title":"1. System Overview &amp; Scope Clarification","text":"<p>We are designing a backend service to manage meeting rooms, bookings, and search for available slots.</p> <p>Functional Requirements (FR): - Create rooms with capacity and features. - Book/cancel meetings. - Search for free slots. - Support recurring bookings.</p> <p>Non-Functional Requirements (NFR): - Conflict-free booking (no double-booking). - Scalable to large offices (100+ rooms). - Efficient search and conflict detection.</p> <p>Assumptions: - All state is in-memory for demo. - Each room has a unique ID and features.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Meeting%20Room%20Scheduler/#2-core-components-and-class-design","title":"2. Core Components and Class Design","text":"<ul> <li>Room: Represents a meeting room.</li> <li>Booking: Represents a booking entry.</li> <li>Scheduler: Manages bookings and conflict checks.</li> <li>Interval: Represents a time interval.</li> </ul> <p>Class Diagram (Textual Representation):</p> <pre><code>+--------+      +---------+\n| Room   |&lt;-----| Booking |\n+--------+      +---------+\n| id     |      | roomId  |\n| cap    |      | interval|\n| features|     | user    |\n+--------+      +---------+\n      ^\n      |\n+---------+\n|Scheduler|\n+---------+\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Meeting%20Room%20Scheduler/#3-api-design-scheduler","title":"3. API Design (<code>Scheduler</code>)","text":"<p>Java</p> <pre><code>class Scheduler {\n    boolean book(String roomId, Interval interval, String user);\n    void cancel(String bookingId);\n    List&lt;Interval&gt; search(String roomId, ...);\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Meeting%20Room%20Scheduler/#4-key-workflows","title":"4. Key Workflows","text":"<p>a) Book Room 1. User calls <code>book(roomId, interval, user)</code>. 2. Scheduler checks for conflicts. 3. If free, creates booking.</p> <p>b) Search Free Slots 1. User calls <code>search(roomId, ...)</code>. 2. Scheduler returns available intervals.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Meeting%20Room%20Scheduler/#5-code-implementation-java","title":"5. Code Implementation (Java)","text":"<pre><code>import java.util.*;\n\nclass Interval {\n    long start;\n    long end;\n    // ...constructors, getters...\n}\n\nclass Room {\n    String id;\n    int capacity;\n    Set&lt;String&gt; features = new HashSet&lt;&gt;();\n}\n\nclass Booking {\n    String id;\n    String roomId;\n    Interval interval;\n    String user;\n}\n\nclass Scheduler {\n    Map&lt;String, List&lt;Booking&gt;&gt; bookings = new HashMap&lt;&gt;();\n    public boolean book(String roomId, Interval interval, String user) {\n        List&lt;Booking&gt; roomBookings = bookings.getOrDefault(roomId, new ArrayList&lt;&gt;());\n        for (Booking b : roomBookings) {\n            if (overlaps(b.interval, interval)) return false;\n        }\n        Booking booking = new Booking();\n        booking.id = UUID.randomUUID().toString();\n        booking.roomId = roomId;\n        booking.interval = interval;\n        booking.user = user;\n        roomBookings.add(booking);\n        bookings.put(roomId, roomBookings);\n        return true;\n    }\n    public void cancel(String bookingId) {\n        for (List&lt;Booking&gt; roomBookings : bookings.values()) {\n            roomBookings.removeIf(b -&gt; b.id.equals(bookingId));\n        }\n    }\n    public List&lt;Interval&gt; search(String roomId) {\n        // Return free intervals (not implemented)\n        return new ArrayList&lt;&gt;();\n    }\n    private boolean overlaps(Interval a, Interval b) {\n        return a.start &lt; b.end &amp;&amp; b.start &lt; a.end;\n    }\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Meeting%20Room%20Scheduler/#6-testing-junit-5","title":"6. Testing (JUnit 5)","text":"<pre><code>import org.junit.jupiter.api.*;\nimport static org.junit.jupiter.api.Assertions.*;\n\npublic class MeetingRoomSchedulerTest {\n    @Test\n    void testBookAndCancel() {\n        // Setup rooms, scheduler, book/cancel, assert conflicts\n    }\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Meeting%20Room%20Scheduler/#7-extensions-and-edge-cases","title":"7. Extensions and Edge Cases","text":"<ul> <li>Add buffer times, recurring bookings, and advanced search.</li> <li>Handle overlapping/adjacent intervals.</li> <li>Add permissions and notifications.</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Metrics%20Store%20%28Append-only%20%2B%20Compaction%29/","title":"Metrics Store (Append-only + Compaction)","text":"<p>This problem requires designing an in-process time-series metrics store with append-only writes and periodic compaction.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Metrics%20Store%20%28Append-only%20%2B%20Compaction%29/#1-system-overview-scope-clarification","title":"1. System Overview &amp; Scope Clarification","text":"<p>We are designing a backend service to store, fetch, and compact time-series metrics efficiently.</p> <p>Functional Requirements (FR): - <code>put(metric, ts, value)</code>: Write a data point. - <code>rangeQuery(metric, from, to)</code>: Fetch data points in a range. - Compaction: Downsample older data (e.g., 1s \u2192 1m).</p> <p>Non-Functional Requirements (NFR): - High write throughput. - Efficient range queries. - Scalable to millions of points.</p> <p>Assumptions: - All state is in-memory for demo. - Compaction runs periodically.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Metrics%20Store%20%28Append-only%20%2B%20Compaction%29/#2-core-components-and-class-design","title":"2. Core Components and Class Design","text":"<ul> <li>Segment: Append-only log of data points.</li> <li>Index: Maps metric to segments.</li> <li>Compactor: Merges/rolls up old data.</li> <li>MetricsStore: Main API for put/query.</li> </ul> <p>Class Diagram (Textual Representation):</p> <pre><code>+-----------+      +-----------+\n| Segment   |&lt;-----| Index     |\n+-----------+      +-----------+\n| points    |      | metricMap |\n+-----------+      +-----------+\n      ^\n      |\n+-----------+\n|Compactor  |\n+-----------+\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Metrics%20Store%20%28Append-only%20%2B%20Compaction%29/#3-api-design-metricsstore","title":"3. API Design (<code>MetricsStore</code>)","text":"<p>Java</p> <pre><code>class MetricsStore {\n    void put(String metric, long ts, double value);\n    List&lt;DataPoint&gt; rangeQuery(String metric, long from, long to);\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Metrics%20Store%20%28Append-only%20%2B%20Compaction%29/#4-key-workflows","title":"4. Key Workflows","text":"<p>a) Put Data Point 1. Append data point to segment for metric. 2. Update index.</p> <p>b) Range Query 1. Fetch segments for metric. 2. Merge raw and compacted data.</p> <p>c) Compaction 1. Periodically merge old data into downsampled segments.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Metrics%20Store%20%28Append-only%20%2B%20Compaction%29/#5-code-implementation-java","title":"5. Code Implementation (Java)","text":"<pre><code>import java.util.*;\n\nclass DataPoint {\n    long ts;\n    double value;\n    DataPoint(long ts, double value) { this.ts = ts; this.value = value; }\n}\n\nclass Segment {\n    List&lt;DataPoint&gt; points = new ArrayList&lt;&gt;();\n}\n\nclass Index {\n    Map&lt;String, List&lt;Segment&gt;&gt; metricMap = new HashMap&lt;&gt;();\n}\n\nclass Compactor {\n    void compact(List&lt;Segment&gt; segments) {\n        // Downsample logic (not implemented)\n    }\n}\n\nclass MetricsStore {\n    Index index = new Index();\n    public void put(String metric, long ts, double value) {\n        List&lt;Segment&gt; segs = index.metricMap.computeIfAbsent(metric, k -&gt; new ArrayList&lt;&gt;());\n        if (segs.isEmpty()) segs.add(new Segment());\n        segs.get(segs.size()-1).points.add(new DataPoint(ts, value));\n    }\n    public List&lt;DataPoint&gt; rangeQuery(String metric, long from, long to) {\n        List&lt;DataPoint&gt; result = new ArrayList&lt;&gt;();\n        List&lt;Segment&gt; segs = index.metricMap.getOrDefault(metric, List.of());\n        for (Segment s : segs) {\n            for (DataPoint dp : s.points) {\n                if (dp.ts &gt;= from &amp;&amp; dp.ts &lt;= to) result.add(dp);\n            }\n        }\n        return result;\n    }\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Metrics%20Store%20%28Append-only%20%2B%20Compaction%29/#6-testing-junit-5","title":"6. Testing (JUnit 5)","text":"<pre><code>import org.junit.jupiter.api.*;\nimport static org.junit.jupiter.api.Assertions.*;\n\npublic class MetricsStoreTest {\n    @Test\n    void testPutAndQuery() {\n        MetricsStore store = new MetricsStore();\n        store.put(\"cpu\", 1, 0.5);\n        store.put(\"cpu\", 2, 0.6);\n        List&lt;DataPoint&gt; points = store.rangeQuery(\"cpu\", 1, 2);\n        assertEquals(2, points.size());\n    }\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Metrics%20Store%20%28Append-only%20%2B%20Compaction%29/#7-extensions-and-edge-cases","title":"7. Extensions and Edge Cases","text":"<ul> <li>Add persistent storage, WAL, and sharding.</li> <li>Support for tags, labels, and advanced queries.</li> <li>Implement compaction and retention policies.</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Parking%20Lot/","title":"Parking Lot","text":"<p>This problem requires designing a multi-floor parking lot system with spot types, allocation strategies, and billing.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Parking%20Lot/#1-system-overview-scope-clarification","title":"1. System Overview &amp; Scope Clarification","text":"<p>We are designing a backend service to manage parking lots, spot allocation, and ticketing.</p> <p>Functional Requirements (FR): - Park/unpark vehicle; find nearest suitable spot. - Track tickets and calculate fees. - Support multiple floors and spot types (compact, large, handicapped).</p> <p>Non-Functional Requirements (NFR): - Real-time allocation and release. - Scalable to large lots (1000+ spots). - Accurate billing and ticket tracking.</p> <p>Assumptions: - Each spot has a unique ID and type. - Pricing is based on duration and spot type. - In-memory store for demo; DB in production.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Parking%20Lot/#2-core-components-and-class-design","title":"2. Core Components and Class Design","text":"<ul> <li>ParkingLot: Main class managing floors and allocation.</li> <li>Floor: Contains spots.</li> <li>Spot: Represents a parking spot.</li> <li>Vehicle: Represents a vehicle.</li> <li>Allocator: Strategy for finding spots.</li> <li>Ticket: Tracks parking session.</li> <li>Billing: Calculates fees.</li> </ul> <p>Class Diagram (Textual Representation):</p> <pre><code>+-------------+\n| ParkingLot  |\n+-------------+\n| + park()    |\n| + unpark()  |\n+-------------+\n      ^\n      |\n+-------------+\n|   Floor     |\n+-------------+\n| + spots     |\n+-------------+\n      ^\n      |\n+-------------+\n|   Spot      |\n+-------------+\n| id, type    |\n| isFree      |\n+-------------+\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Parking%20Lot/#3-api-design-parkinglot","title":"3. API Design (<code>ParkingLot</code>)","text":"<p>Java</p> <pre><code>class ParkingLot {\n    Ticket park(Vehicle v);\n    void unpark(Ticket t);\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Parking%20Lot/#4-key-workflows","title":"4. Key Workflows","text":"<p>a) Park Vehicle 1. Find nearest suitable free spot (by type). 2. Mark spot as occupied. 3. Issue ticket with entry time and spot info.</p> <p>b) Unpark Vehicle 1. Validate ticket. 2. Mark spot as free. 3. Calculate fee based on duration and spot type. 4. Close ticket.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Parking%20Lot/#5-code-implementation-java","title":"5. Code Implementation (Java)","text":"<pre><code>import java.util.*;\n\nclass Spot {\n    String id;\n    SpotType type;\n    boolean isFree = true;\n    // ...constructors, getters, setters...\n}\n\nenum SpotType { COMPACT, LARGE, HANDICAPPED }\n\nenum VehicleType { CAR, TRUCK, BIKE }\n\nclass Vehicle {\n    String id;\n    VehicleType type;\n    // ...constructors, getters, setters...\n}\n\nclass Ticket {\n    String id;\n    String spotId;\n    long entryTime;\n    long exitTime;\n    double fee;\n    // ...constructors, getters, setters...\n}\n\nclass Floor {\n    List&lt;Spot&gt; spots;\n    // ...constructors, methods...\n}\n\nclass ParkingLot {\n    List&lt;Floor&gt; floors;\n    Map&lt;String, Ticket&gt; activeTickets = new HashMap&lt;&gt;();\n    public Ticket park(Vehicle v) {\n        for (Floor f : floors) {\n            for (Spot s : f.spots) {\n                if (s.isFree &amp;&amp; isSuitable(s, v)) {\n                    s.isFree = false;\n                    Ticket t = new Ticket();\n                    t.id = UUID.randomUUID().toString();\n                    t.spotId = s.id;\n                    t.entryTime = System.currentTimeMillis();\n                    activeTickets.put(t.id, t);\n                    return t;\n                }\n            }\n        }\n        throw new RuntimeException(\"No spot available\");\n    }\n    public void unpark(Ticket t) {\n        t.exitTime = System.currentTimeMillis();\n        t.fee = Billing.calculate(t);\n        for (Floor f : floors) {\n            for (Spot s : f.spots) {\n                if (s.id.equals(t.spotId)) {\n                    s.isFree = true;\n                }\n            }\n        }\n        activeTickets.remove(t.id);\n    }\n    private boolean isSuitable(Spot s, Vehicle v) {\n        // Logic for spot suitability\n        return true;\n    }\n}\n\nclass Billing {\n    static double calculate(Ticket t) {\n        long duration = t.exitTime - t.entryTime;\n        return Math.ceil(duration / 3600000.0) * 10.0; // $10/hr\n    }\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Parking%20Lot/#6-testing-junit-5","title":"6. Testing (JUnit 5)","text":"<pre><code>import org.junit.jupiter.api.*;\nimport static org.junit.jupiter.api.Assertions.*;\n\npublic class ParkingLotTest {\n    @Test\n    void testParkAndUnpark() {\n        // Setup lot, floor, spots, vehicle\n        // Park, unpark, assert fee\n    }\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Parking%20Lot/#7-extensions-and-edge-cases","title":"7. Extensions and Edge Cases","text":"<ul> <li>Add reservations, overflow handling, lost ticket recovery.</li> <li>Support for different pricing models.</li> <li>Real-time spot availability dashboard.</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Publisher%E2%80%93Subscriber%20Notification%20Service/","title":"Publisher\u2013Subscriber Notification Service","text":"<p>This problem involves designing an in-process publisher-subscriber (pub-sub) system to decouple components within an application. This pattern is fundamental for building modular, event-driven architectures, allowing different parts of a system to react to events without being tightly coupled.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Publisher%E2%80%93Subscriber%20Notification%20Service/#1-system-overview-scope-clarification","title":"1. System Overview &amp; Scope Clarification","text":"<p>We are building an event bus that operates within a single application instance. Producers publish events to named \"topics,\" and consumers subscribe to these topics to receive the events. The core goal is to make this communication asynchronous and resilient.</p> <p>Functional Requirements (FR):</p> <ul> <li>Topic-based Messaging: Producers send messages (events) to topics. Consumers subscribe to topics to receive messages.</li> <li>Decoupled Communication: A single event can be received by multiple, independent subscribers.</li> <li>Durable Queues: Each subscription will have its own queue to buffer messages. This ensures that a slow consumer doesn't block the producer or other consumers.</li> <li>At-Least-Once Delivery: The system must guarantee that a published message is delivered to a subscriber at least once. This implies a retry mechanism for failed deliveries.</li> <li>Dead-Letter Queue (DLQ): Messages that consistently fail delivery after several retries should be moved to a DLQ for later inspection.</li> </ul> <p>Non-Functional Requirements (NFR):</p> <ul> <li>Performance: The system should handle a high throughput of messages and support a large number of topics and subscribers.</li> <li>Scalability: It should be easy to add more topics, producers, or consumers without significant changes to the system.</li> <li>Reliability: The system should be resilient to individual component failures. If a consumer fails, the messages should remain in the queue for that consumer until they are successfully processed or moved to the DLQ.</li> <li>Maintainability: The system should be easy to maintain and extend. New features or changes in the business logic should require minimal changes to the existing code.</li> </ul> <p>Out of Scope:</p> <ul> <li>Inter-Process Communication: The event bus is designed for communication within a single application instance. Cross-application or cross-network communication is out of scope.</li> <li>Message Content: The format and structure of the messages are not defined by the event bus. It is assumed that the producers and consumers will agree on the message format.</li> <li>Security: There is no mention of security requirements like authentication, authorization, or encryption. It is assumed that the event bus will be used within a trusted environment.</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Publisher%E2%80%93Subscriber%20Notification%20Service/#2-high-level-architecture","title":"2. High-Level Architecture","text":"<p>The system consists of the following components:</p> <ul> <li>Event Bus: The core component that manages topics, subscriptions, and message delivery.</li> <li>Producers: Components that publish messages to topics on the event bus.</li> <li>Consumers: Components that subscribe to topics and process the received messages.</li> <li>Message Queues: Each subscription has a dedicated queue to store the messages until they are processed by the consumer.</li> <li>Dead-Letter Queue (DLQ): A special queue for messages that could not be delivered after several retries.</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Publisher%E2%80%93Subscriber%20Notification%20Service/#3-component-design","title":"3. Component Design","text":""},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Publisher%E2%80%93Subscriber%20Notification%20Service/#31-event-bus","title":"3.1 Event Bus","text":"<p>The event bus is the central component that manages the communication between producers and consumers. It maintains a registry of topics and their associated subscriptions. It is responsible for:</p> <ul> <li>Accepting new topic creation requests.</li> <li>Managing subscriptions to topics.</li> <li>Publishing messages to the appropriate topics.</li> <li>Delivering messages to subscribers.</li> <li>Retrying failed deliveries.</li> <li>Moving undeliverable messages to the DLQ.</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Publisher%E2%80%93Subscriber%20Notification%20Service/#32-producers","title":"3.2 Producers","text":"<p>Producers are components that create and send messages to topics on the event bus. They are responsible for:</p> <ul> <li>Creating messages with the necessary data.</li> <li>Sending messages to the appropriate topic on the event bus.</li> <li>Handling any errors or retries if the message delivery fails.</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Publisher%E2%80%93Subscriber%20Notification%20Service/#33-consumers","title":"3.3 Consumers","text":"<p>Consumers are components that receive and process messages from the event bus. They are responsible for:</p> <ul> <li>Subscribing to the relevant topics on the event bus.</li> <li>Receiving messages from the event bus.</li> <li>Processing the received messages.</li> <li>Acknowledging the successful processing of messages.</li> <li>Handling any errors or retries if the message processing fails.</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Publisher%E2%80%93Subscriber%20Notification%20Service/#34-message-queues","title":"3.4 Message Queues","text":"<p>Message queues are used to store the messages for each subscription. They provide a buffer between the event bus and the consumers, allowing for asynchronous communication. They are responsible for:</p> <ul> <li>Storing the messages until they are processed by the consumer.</li> <li>Supporting concurrent access by the event bus and the consumer.</li> <li>Providing mechanisms for message acknowledgment and retries.</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Publisher%E2%80%93Subscriber%20Notification%20Service/#35-dead-letter-queue-dlq","title":"3.5 Dead-Letter Queue (DLQ)","text":"<p>The DLQ is a special queue for messages that could not be delivered to the consumer after several retries. It allows for the inspection and reprocessing of undeliverable messages. It is responsible for:</p> <ul> <li>Storing the undeliverable messages.</li> <li>Providing mechanisms for inspecting and reprocessing the messages.</li> <li>Supporting alerting or notification mechanisms for manual intervention.</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Publisher%E2%80%93Subscriber%20Notification%20Service/#4-sequence-diagrams","title":"4. Sequence Diagrams","text":""},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Publisher%E2%80%93Subscriber%20Notification%20Service/#41-publish-message","title":"4.1 Publish Message","text":"<pre><code>sequenceDiagram\n    participant P as Producer\n    participant EB as Event Bus\n    participant T as Topic\n    participant Q as Message Queue\n    participant C as Consumer\n\n    P-&gt;&gt;EB: publishMessage(topic, message)\n    EB-&gt;&gt;T: addMessage(message)\n    T-&gt;&gt;Q: enqueue(message)\n    Q-&gt;&gt;C: deliver(message)\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Publisher%E2%80%93Subscriber%20Notification%20Service/#42-subscribe-to-topic","title":"4.2 Subscribe to Topic","text":"<pre><code>sequenceDiagram\n    participant C as Consumer\n    participant EB as Event Bus\n    participant T as Topic\n    participant Q as Message Queue\n\n    C-&gt;&gt;EB: subscribe(topic)\n    EB-&gt;&gt;T: addSubscriber(consumerId)\n    T-&gt;&gt;Q: registerConsumer(consumerId)\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Publisher%E2%80%93Subscriber%20Notification%20Service/#43-unsubscribe-from-topic","title":"4.3 Unsubscribe from Topic","text":"<pre><code>sequenceDiagram\n    participant C as Consumer\n    participant EB as Event Bus\n    participant T as Topic\n    participant Q as Message Queue\n\n    C-&gt;&gt;EB: unsubscribe(topic)\n    EB-&gt;&gt;T: removeSubscriber(consumerId)\n    T-&gt;&gt;Q: unregisterConsumer(consumerId)\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Publisher%E2%80%93Subscriber%20Notification%20Service/#44-retry-mechanism","title":"4.4 Retry Mechanism","text":"<pre><code>sequenceDiagram\n    participant EB as Event Bus\n    participant Q as Message Queue\n    participant DLQ as Dead-Letter Queue\n    participant C as Consumer\n\n    Q-&gt;&gt;C: deliver(message)\n    alt delivery fails\n        C-&gt;&gt;EB: ackFailure(message)\n        EB-&gt;&gt;Q: retry(message)\n        Q-&gt;&gt;C: deliver(message)\n    else delivery succeeds\n        C-&gt;&gt;EB: ackSuccess(message)\n    end\n    alt max retries exceeded\n        EB-&gt;&gt;DLQ: moveToDLQ(message)\n    end\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Publisher%E2%80%93Subscriber%20Notification%20Service/#5-code-examples","title":"5. Code Examples","text":""},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Publisher%E2%80%93Subscriber%20Notification%20Service/#51-event-bus","title":"5.1 Event Bus","text":"<pre><code>class EventBus:\n    def __init__(self):\n        self.topics = {}\n        self.dlq = DeadLetterQueue()\n\n    def publish(self, topic_name, message):\n        topic = self.topics.get(topic_name)\n        if topic:\n            topic.publish(message)\n        else:\n            print(f\"Topic {topic_name} does not exist.\")\n\n    def subscribe(self, topic_name, subscriber):\n        topic = self.topics.get(topic_name)\n        if topic:\n            topic.add_subscriber(subscriber)\n        else:\n            print(f\"Topic {topic_name} does not exist.\")\n\n    def unsubscribe(self, topic_name, subscriber):\n        topic = self.topics.get(topic_name)\n        if topic:\n            topic.remove_subscriber(subscriber)\n        else:\n            print(f\"Topic {topic_name} does not exist.\")\n\n    def create_topic(self, topic_name):\n        if topic_name not in self.topics:\n            self.topics[topic_name] = Topic(topic_name)\n        else:\n            print(f\"Topic {topic_name} already exists.\")\n\n    def delete_topic(self, topic_name):\n        if topic_name in self.topics:\n            del self.topics[topic_name]\n        else:\n            print(f\"Topic {topic_name} does not exist.\")\n\nclass Topic:\n    def __init__(self, name):\n        self.name = name\n        self.subscribers = []\n        self.queue = MessageQueue()\n\n    def publish(self, message):\n        self.queue.enqueue(message)\n        for subscriber in self.subscribers:\n            subscriber.notify(message)\n\n    def add_subscriber(self, subscriber):\n        self.subscribers.append(subscriber)\n\n    def remove_subscriber(self, subscriber):\n        self.subscribers.remove(subscriber)\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Publisher%E2%80%93Subscriber%20Notification%20Service/#52-producers-and-consumers","title":"5.2 Producers and Consumers","text":"<pre><code>class Producer:\n    def __init__(self, event_bus):\n        self.event_bus = event_bus\n\n    def publish(self, topic_name, message):\n        self.event_bus.publish(topic_name, message)\n\nclass Consumer:\n    def __init__(self, event_bus):\n        self.event_bus = event_bus\n\n    def subscribe(self, topic_name):\n        self.event_bus.subscribe(topic_name, self)\n\n    def unsubscribe(self, topic_name):\n        self.event_bus.unsubscribe(topic_name, self)\n\n    def notify(self, message):\n        print(f\"Received message: {message}\")\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Publisher%E2%80%93Subscriber%20Notification%20Service/#53-message-queue-and-dead-letter-queue","title":"5.3 Message Queue and Dead-Letter Queue","text":"<pre><code>class MessageQueue:\n    def __init__(self):\n        self.messages = []\n        self.consumers = []\n\n    def enqueue(self, message):\n        self.messages.append(message)\n\n    def deliver(self, consumer):\n        if self.messages:\n            message = self.messages.pop(0)\n            consumer.notify(message)\n\nclass DeadLetterQueue:\n    def __init__(self):\n        self.messages = []\n\n    def move_to_dlq(self, message):\n        self.messages.append(message)\n\n    def reprocess(self, message):\n        # Logic to reprocess the message\n        pass\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Publisher%E2%80%93Subscriber%20Notification%20Service/#6-error-handling-reliability","title":"6. Error Handling &amp; Reliability","text":"<ul> <li>Implement a retry mechanism with exponential backoff for failed message deliveries.</li> <li>Move undeliverable messages to the DLQ after a certain number of retries.</li> <li>Provide mechanisms for monitoring and alerting on DLQ messages.</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Publisher%E2%80%93Subscriber%20Notification%20Service/#7-performance-considerations","title":"7. Performance Considerations","text":"<ul> <li>Optimize the message queue implementation for high throughput and low latency.</li> <li>Consider using a more efficient data structure for the message queue, like a ring buffer.</li> <li>Implement batch processing of messages for consumers to reduce the overhead of individual message processing.</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Publisher%E2%80%93Subscriber%20Notification%20Service/#8-security-considerations","title":"8. Security Considerations","text":"<ul> <li>Implement authentication and authorization mechanisms for producers and consumers.</li> <li>Consider encrypting the messages for confidentiality.</li> <li>Implement auditing and logging of message deliveries and errors.</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Publisher%E2%80%93Subscriber%20Notification%20Service/#9-future-enhancements","title":"9. Future Enhancements","text":"<ul> <li>Support for message filtering based on content or attributes.</li> <li>Support for message prioritization.</li> <li>Support for transactions or message grouping.</li> <li>Support for distributed or clustered event bus for scalability.</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Publisher%E2%80%93Subscriber%20Notification%20Service/#10-conclusion","title":"10. Conclusion","text":"<p>The Publisher\u2013Subscriber Notification Service provides a flexible and decoupled communication mechanism for building event-driven architectures. By implementing the pub-sub pattern, systems can achieve better modularity, scalability, and resilience. The proposed design and implementation provide a solid foundation for building such a system, with considerations for reliability, performance, and security.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Rolling%20Time-Window%20Aggregator%20%28VWAP%20EMA%29/","title":"Rolling Time-Window Aggregator (VWAP EMA)","text":"<p>This problem involves designing a rolling time-window aggregator for financial data, specifically to compute metrics like Volume Weighted Average Price (VWAP) and Exponential Moving Average (EMA) over a sliding window. This is a common requirement in trading systems, analytics, and real-time dashboards.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Rolling%20Time-Window%20Aggregator%20%28VWAP%20EMA%29/#1-system-overview-scope-clarification","title":"1. System Overview &amp; Scope Clarification","text":"<ul> <li>Input: A stream of trade events (price, volume, timestamp).</li> <li>Output: For each new event, compute the VWAP and EMA over the last N seconds/minutes (rolling window).</li> <li>Requirements:<ul> <li>Low Latency: Must update metrics in real-time as new events arrive.</li> <li>Configurable Window: Support arbitrary window sizes (e.g., 1 minute, 5 minutes).</li> <li>Thread-Safety: Safe for concurrent updates and reads.</li> <li>Memory Efficiency: Only store events within the current window.</li> </ul> </li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Rolling%20Time-Window%20Aggregator%20%28VWAP%20EMA%29/#2-core-components-and-class-design","title":"2. Core Components and Class Design","text":"<ul> <li>TradeEvent: Represents a single trade (price, volume, timestamp).</li> <li>RollingWindowAggregator: Maintains a time-ordered queue of events and computes VWAP/EMA as new events arrive and old ones expire.</li> <li>Eviction Policy: As new events arrive, remove events older than the window size.</li> <li>EMA Calculation: Use the standard EMA formula with a configurable smoothing factor.</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Rolling%20Time-Window%20Aggregator%20%28VWAP%20EMA%29/#3-api-design","title":"3. API Design","text":"<pre><code>public class TradeEvent {\n    public final double price;\n    public final double volume;\n    public final long timestamp; // epoch millis\n    public TradeEvent(double price, double volume, long timestamp) {\n        this.price = price; this.volume = volume; this.timestamp = timestamp;\n    }\n}\n\npublic class RollingWindowAggregator {\n    public RollingWindowAggregator(long windowMillis, double emaAlpha);\n    public void onTrade(TradeEvent event);\n    public double getVWAP();\n    public double getEMA();\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Rolling%20Time-Window%20Aggregator%20%28VWAP%20EMA%29/#4-key-workflows","title":"4. Key Workflows","text":"<p>a) Adding a Trade Event - Add the event to a time-ordered queue (e.g., LinkedList or ArrayDeque). - Remove events from the head of the queue if they are older than (current time - windowMillis). - Update running totals for VWAP (sum of price*volume, sum of volume). - Update EMA using the formula: <code>EMA_new = alpha * price + (1 - alpha) * EMA_prev</code>.</p> <p>b) Querying VWAP and EMA - VWAP: <code>sum(price * volume) / sum(volume)</code> over the current window. - EMA: The latest computed value.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Rolling%20Time-Window%20Aggregator%20%28VWAP%20EMA%29/#5-code-implementation-java-simplified","title":"5. Code Implementation (Java, Simplified)","text":"<pre><code>import java.util.*;\n\npublic class TradeEvent {\n    public final double price;\n    public final double volume;\n    public final long timestamp;\n    public TradeEvent(double price, double volume, long timestamp) {\n        this.price = price; this.volume = volume; this.timestamp = timestamp;\n    }\n}\n\npublic class RollingWindowAggregator {\n    private final long windowMillis;\n    private final double alpha;\n    private final Deque&lt;TradeEvent&gt; window = new ArrayDeque&lt;&gt;();\n    private double vwapNumerator = 0.0;\n    private double vwapDenominator = 0.0;\n    private double ema = Double.NaN;\n\n    public RollingWindowAggregator(long windowMillis, double emaAlpha) {\n        this.windowMillis = windowMillis;\n        this.alpha = emaAlpha;\n    }\n\n    public synchronized void onTrade(TradeEvent event) {\n        window.addLast(event);\n        vwapNumerator += event.price * event.volume;\n        vwapDenominator += event.volume;\n        if (Double.isNaN(ema)) {\n            ema = event.price;\n        } else {\n            ema = alpha * event.price + (1 - alpha) * ema;\n        }\n        evictOldEvents(event.timestamp);\n    }\n\n    private void evictOldEvents(long now) {\n        while (!window.isEmpty() &amp;&amp; window.peekFirst().timestamp &lt; now - windowMillis) {\n            TradeEvent old = window.removeFirst();\n            vwapNumerator -= old.price * old.volume;\n            vwapDenominator -= old.volume;\n        }\n    }\n\n    public synchronized double getVWAP() {\n        return vwapDenominator == 0.0 ? Double.NaN : vwapNumerator / vwapDenominator;\n    }\n\n    public synchronized double getEMA() {\n        return ema;\n    }\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Rolling%20Time-Window%20Aggregator%20%28VWAP%20EMA%29/#6-testing-and-extensions","title":"6. Testing and Extensions","text":"<ul> <li>Testing:<ul> <li>Feed a sequence of trades and verify VWAP/EMA match expected values.</li> <li>Test with trades arriving out of order or with gaps.</li> <li>Test with different window sizes and alpha values.</li> </ul> </li> <li>Extensions:<ul> <li>Support for multiple symbols (map symbol to aggregator).</li> <li>Add support for other metrics (e.g., simple moving average, max/min price).</li> <li>Use a more efficient data structure for very high-frequency data (e.g., segment tree, skip list).</li> <li>Add snapshotting for fast recovery after restart.</li> </ul> </li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Splitwise-like%20Expense%20Splitter/","title":"Splitwise-like Expense Splitter","text":"<p>This problem requires designing a group expense tracker that simplifies debts and supports various expense types.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Splitwise-like%20Expense%20Splitter/#1-system-overview-scope-clarification","title":"1. System Overview &amp; Scope Clarification","text":"<p>We are designing a backend service to track group expenses, calculate balances, and minimize cash flows for settlements.</p> <p>Functional Requirements (FR): - Add expenses (equal, unequal, percent split). - Track balances per user. - Settle up and simplify debt graph.</p> <p>Non-Functional Requirements (NFR): - Accurate calculations (handle rounding). - Scalable to large groups (100+ users). - Support multiple currencies (optional).</p> <p>Assumptions: - All state is in-memory for demo. - Each group has a unique ID and list of users.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Splitwise-like%20Expense%20Splitter/#2-core-components-and-class-design","title":"2. Core Components and Class Design","text":"<ul> <li>User: Represents a group member.</li> <li>Group: Holds users and expenses.</li> <li>Expense: Represents an expense entry.</li> <li>BalanceSheet: Tracks net balances.</li> <li>SettlementEngine: Minimizes cash flows.</li> </ul> <p>Class Diagram (Textual Representation):</p> <pre><code>+--------+      +-------+\n| User   |&lt;-----| Group |\n+--------+      +-------+\n| id     |      | users |\n| name   |      | expenses\n+--------+      +-------+\n      ^             |\n      |             v\n+--------+      +-------------+\n|Expense |      |BalanceSheet |\n+--------+      +-------------+\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Splitwise-like%20Expense%20Splitter/#3-api-design-settlementengine","title":"3. API Design (<code>SettlementEngine</code>)","text":"<p>Java</p> <pre><code>class SettlementEngine {\n    List&lt;Settlement&gt; simplify(BalanceSheet sheet);\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Splitwise-like%20Expense%20Splitter/#4-key-workflows","title":"4. Key Workflows","text":"<p>a) Add Expense 1. User adds expense (amount, split type). 2. Update balances for all users.</p> <p>b) Settle Up 1. Run min-cash-flow algorithm to minimize transactions. 2. Output list of settlements.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Splitwise-like%20Expense%20Splitter/#5-code-implementation-java","title":"5. Code Implementation (Java)","text":"<pre><code>import java.util.*;\n\nclass User {\n    String id;\n    String name;\n}\n\nclass Expense {\n    String id;\n    String paidBy;\n    double amount;\n    Map&lt;String, Double&gt; splits;\n    // ...constructors, getters...\n}\n\nclass Group {\n    String id;\n    List&lt;User&gt; users = new ArrayList&lt;&gt;();\n    List&lt;Expense&gt; expenses = new ArrayList&lt;&gt;();\n}\n\nclass BalanceSheet {\n    Map&lt;String, Double&gt; balances = new HashMap&lt;&gt;();\n}\n\nclass Settlement {\n    String from;\n    String to;\n    double amount;\n}\n\nclass SettlementEngine {\n    public List&lt;Settlement&gt; simplify(BalanceSheet sheet) {\n        // Min-cash-flow algorithm\n        List&lt;Settlement&gt; result = new ArrayList&lt;&gt;();\n        // ...algorithm...\n        return result;\n    }\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Splitwise-like%20Expense%20Splitter/#6-testing-junit-5","title":"6. Testing (JUnit 5)","text":"<pre><code>import org.junit.jupiter.api.*;\nimport static org.junit.jupiter.api.Assertions.*;\n\npublic class SplitwiseTest {\n    @Test\n    void testAddExpenseAndSettle() {\n        // Setup group, users, add expenses, run settlement\n    }\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Splitwise-like%20Expense%20Splitter/#7-extensions-and-edge-cases","title":"7. Extensions and Edge Cases","text":"<ul> <li>Handle multiple currencies, rounding errors.</li> <li>Add recurring expenses, group management.</li> <li>Support for audit/history of transactions.</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Thread-Safe%20Limit%20Order%20Book%20%28Equities%29/","title":"Thread-Safe Limit Order Book (Equities)","text":"<p>This problem requires designing the core data structure of a financial exchange: the Limit Order Book (LOB). The design must support adding and canceling orders, matching trades according to strict price-time priority rules, and do so in a thread-safe, deterministic, and low-latency manner.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Thread-Safe%20Limit%20Order%20Book%20%28Equities%29/#1-system-overview-scope-clarification","title":"1. System Overview &amp; Scope Clarification","text":"<p>A Limit Order Book is a centralized record of all outstanding buy (bid) and sell (ask) limit orders for a specific financial instrument (e.g., stock in GOOGLE). Its job is to match incoming orders against resting orders to create trades.</p> <p>Core Principle: Price-Time Priority This is the non-negotiable rule for matching orders in most exchanges:</p> <ol> <li>Price Priority: The highest-priced buy order (best bid) and the lowest-priced sell order (best ask) have the highest priority.</li> <li>Time Priority: If multiple orders exist at the same best price, the one that was submitted earliest gets executed first (First-In, First-Out).</li> </ol> <p>Functional Requirements (FR):</p> <ul> <li>Add Limit Order: Place a new buy or sell order onto the book with a specific price and quantity.</li> <li>Cancel Order: Remove an existing order from the book using its unique ID.</li> <li>Order Matching: When a new order's price \"crosses the spread\" (i.e., a buy order's price is &gt;= the best sell price, or a sell order's price is &lt;= the best buy price), it must be matched against resting orders according to price-time priority.</li> <li>Query Book State: Get the best bid and best ask prices and quantities.</li> </ul> <p>Non-Functional Requirements (NFR):</p> <ul> <li>Low Latency: All operations (add, cancel, match) must be completed in microseconds.</li> <li>Determinism: For the same sequence of input commands, the system must produce the exact same sequence of output trades. This is critical for fairness and regulatory compliance.</li> <li>High Throughput: The system must handle tens of thousands to millions of commands per second.</li> </ul> <p>Concurrency Model: The Single Writer Principle To achieve determinism and avoid complex, slow locking, the standard industry pattern is to have a single, dedicated thread (the \"matching engine\") that processes all state-changing commands serially from a queue. Other threads (e.g., network threads handling client connections) act as producers, placing commands onto this queue. This is a Multiple-Producer, Single-Consumer (MPSC) model.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Thread-Safe%20Limit%20Order%20Book%20%28Equities%29/#2-core-components-and-class-design","title":"2. Core Components and Class Design","text":"<p>The data structures are chosen for their performance characteristics in sorting and lookups.</p> <ul> <li><code>Order</code>: A simple Plain Old Java Object (POJO) representing an order.<ul> <li><code>long orderId</code>: Unique identifier.</li> <li><code>Side side</code>: An enum (<code>BUY</code>, <code>SELL</code>).</li> <li><code>long price</code>: The limit price (using <code>long</code> for fixed-point arithmetic, e.g., representing cents, is faster than <code>BigDecimal</code>).</li> <li><code>long quantity</code>: The number of shares.</li> <li><code>long timestamp</code>: Arrival time for time-priority.</li> <li><code>PriceLevel level</code>: A reference to the <code>PriceLevel</code> it belongs to, for fast cancellation.</li> </ul> </li> <li><code>PriceLevel</code>: Represents all orders at a single price point.<ul> <li><code>long price</code>: The price of this level.</li> <li><code>long totalVolume</code>: The sum of quantities of all orders at this level.</li> <li><code>Deque&lt;Order&gt; orders</code>: A queue of orders, maintaining FIFO time priority. <code>ArrayDeque</code> is a good choice.</li> </ul> </li> <li><code>OrderBook</code>: The central data structure holding the two sides of the book.<ul> <li><code>NavigableMap&lt;Long, PriceLevel&gt; bids</code>: A map of buy-side price levels, sorted from highest to lowest price. <code>TreeMap</code> with a reverse-order comparator is perfect.</li> <li><code>NavigableMap&lt;Long, PriceLevel&gt; asks</code>: A map of sell-side price levels, sorted from lowest to highest price. A standard <code>TreeMap</code> works here.</li> <li><code>Map&lt;Long, Order&gt; ordersById</code>: A <code>HashMap</code> for O(1) lookup of any order by its ID, essential for fast cancellations.</li> </ul> </li> <li><code>MatchingEngine</code>: The class that runs the single writer thread, consuming commands and operating on the <code>OrderBook</code>.</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Thread-Safe%20Limit%20Order%20Book%20%28Equities%29/#3-api-design-commands-and-the-engine","title":"3. API Design (Commands and the Engine)","text":"<p>The API is not a set of direct methods, but rather a set of command objects placed onto a queue.</p> <pre><code>// Command interface\npublic sealed interface OrderBookCommand permits AddOrder, CancelOrder {}\npublic record AddOrder(Order order) implements OrderBookCommand {}\npublic record CancelOrder(long orderId) implements OrderBookCommand {}\n\npublic class MatchingEngine implements Runnable {\n    private final BlockingQueue&lt;OrderBookCommand&gt; commandQueue;\n    private final OrderBook orderBook;\n\n    // The single thread runs this loop\n    @Override\n    public void run() {\n        while (!Thread.currentThread().isInterrupted()) {\n            try {\n                OrderBookCommand command = commandQueue.take();\n                processCommand(command);\n            } catch (InterruptedException e) { /* ... */ }\n        }\n    }\n\n    private void processCommand(OrderBookCommand command) {\n        switch (command) {\n            case AddOrder(var order) -&gt; orderBook.addOrder(order);\n            case CancelOrder(var id) -&gt; orderBook.cancelOrder(id);\n        }\n    }\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Thread-Safe%20Limit%20Order%20Book%20%28Equities%29/#4-key-workflows-executed-by-the-single-matchingengine-thread","title":"4. Key Workflows (executed by the single <code>MatchingEngine</code> thread)","text":"<p>a) <code>OrderBook.addOrder(Order newOrder)</code> Workflow</p> <ol> <li>Match or Rest?: The first step is to check if the incoming order is \"marketable\" (can be matched immediately).<ul> <li>If <code>newOrder</code> is a <code>BUY</code>: Check if the <code>asks</code> map is non-empty and <code>newOrder.price &gt;= asks.firstKey()</code>.</li> <li>If <code>newOrder</code> is a <code>SELL</code>: Check if the <code>bids</code> map is non-empty and <code>newOrder.price &lt;= bids.firstKey()</code>.</li> </ul> </li> <li>Matching Logic (if marketable):     a. Get the list of price levels from the opposite side (e.g., <code>asks.values()</code> for a buy order).     b. Iterate through the price levels, starting from the best price.     c. For each <code>PriceLevel</code>, iterate through its <code>Deque&lt;Order&gt;</code> (FIFO).     d. Match <code>newOrder</code> against the resting order (<code>restingOrder</code>). The trade quantity is <code>min(newOrder.quantity, restingOrder.quantity)</code>.     e. Generate a <code>Trade</code> event (to be published to downstream systems).     f. Decrement quantities on both orders.     g. If <code>restingOrder.quantity == 0</code>, remove it from its <code>PriceLevel</code>'s deque and the main <code>ordersById</code> map. If the <code>PriceLevel</code> becomes empty, remove it from its <code>TreeMap</code>.     h. If <code>newOrder.quantity == 0</code>, the process is complete. Stop and return.     i. If the price level is exhausted, move to the next best price level and repeat.</li> <li>Resting Logic (if not marketable or partially filled):     a. If <code>newOrder</code> still has quantity remaining, it must be placed on the book.     b. Find the correct side (<code>bids</code> or <code>asks</code>).     c. Use <code>map.computeIfAbsent(newOrder.price, ...)</code> to get or create the <code>PriceLevel</code>.     d. Add the <code>newOrder</code> to the end of the <code>PriceLevel</code>'s <code>Deque</code>, update the level's total volume.     e. Store the order in the <code>ordersById</code> map for future cancellation.</li> </ol> <p>b) <code>OrderBook.cancelOrder(long orderId)</code> Workflow</p> <ol> <li>Use the <code>ordersById</code> map to find the <code>Order</code> object in O(1) time. If it's not found, it was likely already filled; do nothing.</li> <li>Get the <code>PriceLevel</code> from the <code>order.level</code> reference.</li> <li>Remove the order from the <code>PriceLevel</code>'s <code>Deque</code>. This is O(N) on <code>ArrayDeque</code>. For extreme performance, a custom doubly-linked list implementation where the <code>Order</code> object itself is the node would make this O(1). For an interview, acknowledging this tradeoff is key.</li> <li>Update the <code>PriceLevel</code>'s total volume.</li> <li>If the <code>PriceLevel</code> is now empty, remove it from the <code>TreeMap</code> (<code>bids</code> or <code>asks</code>).</li> <li>Finally, remove the order from the <code>ordersById</code> map.</li> </ol>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Thread-Safe%20Limit%20Order%20Book%20%28Equities%29/#5-code-implementation-java","title":"5. Code Implementation (Java)","text":"<p>This is a simplified implementation of the <code>OrderBook</code>'s core logic, assuming it's called by the single-threaded <code>MatchingEngine</code>.</p> <pre><code>import java.util.*;\n\npublic enum Side { BUY, SELL }\n\n// Simplified Order class for this example\npublic class Order {\n    long orderId; Side side; long price; long quantity;\n    public Order(long id, Side s, long p, long q) {\n        this.orderId=id; this.side=s; this.price=p; this.quantity=q;\n    }\n    // ...getters and setters...\n}\n\nclass PriceLevel {\n    long totalVolume = 0;\n    final Deque&lt;Order&gt; orders = new ArrayDeque&lt;&gt;();\n}\n\npublic class OrderBook {\n    private final NavigableMap&lt;Long, PriceLevel&gt; bids = new TreeMap&lt;&gt;(Collections.reverseOrder());\n    private final NavigableMap&lt;Long, PriceLevel&gt; asks = new TreeMap&lt;&gt;();\n    private final Map&lt;Long, Order&gt; ordersById = new HashMap&lt;&gt;(); // For fast cancellations\n\n    public void addOrder(Order newOrder) {\n        // For simplicity, we assume trade events are printed to console.\n        if (newOrder.side == Side.BUY) {\n            matchOrder(newOrder, asks);\n        } else {\n            matchOrder(newOrder, bids);\n        }\n\n        if (newOrder.quantity &gt; 0) {\n            restOrder(newOrder);\n        }\n    }\n\n    private void matchOrder(Order newOrder, NavigableMap&lt;Long, PriceLevel&gt; oppositeSide) {\n        Iterator&lt;Map.Entry&lt;Long, PriceLevel&gt;&gt; levelIterator = oppositeSide.entrySet().iterator();\n\n        while (levelIterator.hasNext() &amp;&amp; newOrder.quantity &gt; 0) {\n            Map.Entry&lt;Long, PriceLevel&gt; entry = levelIterator.next();\n            long price = entry.getKey();\n            PriceLevel level = entry.getValue();\n\n            // Price check: can the new order be matched at this level?\n            boolean priceMatch = (newOrder.side == Side.BUY &amp;&amp; newOrder.price &gt;= price) ||\n                                 (newOrder.side == Side.SELL &amp;&amp; newOrder.price &lt;= price);\n            if (!priceMatch) break;\n\n            Iterator&lt;Order&gt; orderIterator = level.orders.iterator();\n            while (orderIterator.hasNext() &amp;&amp; newOrder.quantity &gt; 0) {\n                Order restingOrder = orderIterator.next();\n                long tradeQty = Math.min(newOrder.quantity, restingOrder.quantity);\n\n                System.out.printf(\"TRADE: %d shares at %d%n\", tradeQty, restingOrder.price);\n\n                newOrder.quantity -= tradeQty;\n                restingOrder.quantity -= tradeQty;\n                level.totalVolume -= tradeQty;\n\n                if (restingOrder.quantity == 0) {\n                    orderIterator.remove(); // Remove from Deque\n                    ordersById.remove(restingOrder.orderId);\n                }\n            }\n\n            if (level.orders.isEmpty()) {\n                levelIterator.remove(); // Remove PriceLevel from TreeMap\n            }\n        }\n    }\n\n    private void restOrder(Order order) {\n        NavigableMap&lt;Long, PriceLevel&gt; side = (order.side == Side.BUY) ? bids : asks;\n        PriceLevel level = side.computeIfAbsent(order.price, k -&gt; new PriceLevel());\n        level.orders.addLast(order);\n        level.totalVolume += order.quantity;\n        ordersById.put(order.orderId, order);\n    }\n\n    // Cancellation logic would be here...\n    public void cancelOrder(long orderId) { /* ... as described in workflow ... */ }\n\n    // Public query methods\n    public Optional&lt;Long&gt; getBestBid() { return Optional.ofNullable(bids.firstKey()); }\n    public Optional&lt;Long&gt; getBestAsk() { return Optional.ofNullable(asks.firstKey()); }\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Thread-Safe%20Limit%20Order%20Book%20%28Equities%29/#6-testing-key-scenarios","title":"6. Testing (Key Scenarios)","text":"<ul> <li>Building the Book: Add a series of non-crossing orders (<code>BUY 100 @ 99</code>, <code>BUY 50 @ 98</code>, <code>SELL 100 @ 101</code>, <code>SELL 50 @ 102</code>). Verify <code>getBestBid()</code> returns 99 and <code>getBestAsk()</code> returns 101.</li> <li>Simple Cross: With the book above, add <code>SELL 75 @ 99</code>. Verify a trade of 75 shares occurs, the original bid is now for 25 shares, and the sell order is gone.</li> <li>Multi-Level Cross: With the book above, add <code>SELL 200 @ 97</code>. Verify it first matches all 100 shares @ 99, then all 50 shares @ 98. The remaining 50 shares should rest on the book, making the new best ask 97.</li> <li>Cancellation: Add an order, then cancel it. Verify it's gone from all data structures.</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Thread-Safe%20Limit%20Order%20Book%20%28Equities%29/#7-performance-concurrency-and-extensions","title":"7. Performance, Concurrency, and Extensions","text":"<ul> <li>Concurrency: The MPSC queue model is the key. It serializes all writes, making the core logic simple and lock-free. Reads (like providing a market data snapshot) are tricky; they either need to be queued as commands or use non-blocking techniques to read a potentially stale copy of the book state.</li> <li>Performance Optimizations:<ul> <li>Cancellation: As noted, O(N) removal from a <code>PriceLevel</code>'s <code>ArrayDeque</code> is a bottleneck. A custom <code>Order</code> class that is also a node in a doubly-linked list makes removal O(1).</li> <li>GC-Free: For HFT, avoiding GC is critical. This involves object pooling (reusing <code>Order</code> objects instead of creating new ones) and avoiding any memory allocation on the critical path.</li> <li>Primitives: Using <code>long</code> for price/quantity avoids <code>BigDecimal</code> object overhead.</li> </ul> </li> <li>Extensions:<ul> <li>Market Orders: Add an <code>Order</code> type with no price. It matches against the best available prices until filled. In the <code>matchOrder</code> logic, a market order would simply not have the <code>priceMatch</code> condition.</li> <li>Other Order Types: Implement Immediate-Or-Cancel (IOC) orders (match what you can immediately, cancel the rest) and Fill-Or-Kill (FOK) orders (execute the entire quantity immediately or cancel).</li> <li>Market Data Feeds: The <code>OrderBook</code> should generate events for every state change (new order, cancel, trade, book update). These events are put onto outbound queues for market data publishers and other downstream systems. The matching engine thread should not be blocked by slow consumers of this data.</li> </ul> </li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Threshold%20Alerting%20Engine/","title":"Threshold Alerting Engine","text":"<p>This problem requires designing a time-series alerting engine that triggers alerts based on threshold rules over rolling windows.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Threshold%20Alerting%20Engine/#1-system-overview-scope-clarification","title":"1. System Overview &amp; Scope Clarification","text":"<p>We are designing a backend service to evaluate time-series data and trigger alerts when rules are met.</p> <p>Functional Requirements (FR): - Define rules per metric (e.g., CPU &gt; 90% for 5m). - Evaluate conditions over rolling time windows. - Suppress duplicate alerts (debounce).</p> <p>Non-Functional Requirements (NFR): - Low-latency evaluation. - Scalable to thousands of metrics/rules. - Reliable alert delivery (email/webhook).</p> <p>Assumptions: - All state is in-memory for demo. - Each rule is for a single metric.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Threshold%20Alerting%20Engine/#2-core-components-and-class-design","title":"2. Core Components and Class Design","text":"<ul> <li>Rule: Represents a threshold rule.</li> <li>Evaluator: Evaluates rules over time windows.</li> <li>Notifier: Sends alerts.</li> <li>Debounce: Suppresses duplicate alerts.</li> </ul> <p>Class Diagram (Textual Representation):</p> <pre><code>+--------+      +----------+\n| Rule   |&lt;-----|Evaluator |\n+--------+      +----------+\n| metric |      | rules    |\n| pred   |      | window   |\n| window |      +----------+\n+--------+      | Notifier |\n               +----------+\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Threshold%20Alerting%20Engine/#3-api-design-evaluator","title":"3. API Design (<code>Evaluator</code>)","text":"<p>Java</p> <pre><code>class Evaluator {\n    void addRule(Rule rule);\n    void onMetric(String metric, double value, long ts);\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Threshold%20Alerting%20Engine/#4-key-workflows","title":"4. Key Workflows","text":"<p>a) Add Rule 1. User defines rule (metric, predicate, window, duration). 2. Evaluator stores rule.</p> <p>b) On Metric 1. Evaluator receives metric value. 2. Updates rolling window. 3. Checks if rule is met for window. 4. If so, triggers alert (debounced).</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Threshold%20Alerting%20Engine/#5-code-implementation-java","title":"5. Code Implementation (Java)","text":"<pre><code>import java.util.*;\nimport java.util.function.Predicate;\n\nclass Rule {\n    String metric;\n    Predicate&lt;Double&gt; predicate;\n    long window;\n    long duration;\n}\n\nclass Evaluator {\n    Map&lt;String, Rule&gt; rules = new HashMap&lt;&gt;();\n    Map&lt;String, Deque&lt;DataPoint&gt;&gt; windows = new HashMap&lt;&gt;();\n    Notifier notifier = new Notifier();\n    Map&lt;String, Long&gt; lastAlert = new HashMap&lt;&gt;();\n    public void addRule(Rule rule) { rules.put(rule.metric, rule); }\n    public void onMetric(String metric, double value, long ts) {\n        Rule rule = rules.get(metric);\n        if (rule == null) return;\n        windows.computeIfAbsent(metric, k -&gt; new ArrayDeque&lt;&gt;()).addLast(new DataPoint(ts, value));\n        // Remove old points\n        while (!windows.get(metric).isEmpty() &amp;&amp; ts - windows.get(metric).peekFirst().ts &gt; rule.window) {\n            windows.get(metric).pollFirst();\n        }\n        // Check predicate\n        boolean triggered = windows.get(metric).stream().allMatch(dp -&gt; rule.predicate.test(dp.value));\n        if (triggered &amp;&amp; shouldAlert(metric, ts, rule)) {\n            notifier.notify(\"Alert for \" + metric);\n            lastAlert.put(metric, ts);\n        }\n    }\n    private boolean shouldAlert(String metric, long ts, Rule rule) {\n        return !lastAlert.containsKey(metric) || ts - lastAlert.get(metric) &gt; rule.duration;\n    }\n}\n\nclass DataPoint {\n    long ts;\n    double value;\n    DataPoint(long ts, double value) { this.ts = ts; this.value = value; }\n}\n\nclass Notifier {\n    public void notify(String alert) {\n        // Send email/webhook\n    }\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Threshold%20Alerting%20Engine/#6-testing-junit-5","title":"6. Testing (JUnit 5)","text":"<pre><code>import org.junit.jupiter.api.*;\nimport static org.junit.jupiter.api.Assertions.*;\n\npublic class ThresholdAlertingEngineTest {\n    @Test\n    void testAlertTrigger() {\n        // Setup rule, evaluator, send metrics, assert alert\n    }\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Threshold%20Alerting%20Engine/#7-extensions-and-edge-cases","title":"7. Extensions and Edge Cases","text":"<ul> <li>Add support for multiple predicates, composite rules.</li> <li>Integrate with persistent storage and distributed evaluation.</li> <li>Add alert suppression and escalation policies.</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Token-Bucket%20Rate%20Limiter%20%28Multi-Tenant%29/","title":"Token-Bucket Rate Limiter (Multi-Tenant)","text":"<p>This problem involves designing a rate limiter that can enforce different request limits for multiple clients (or tenants) using the token bucket algorithm. This is a critical component for API gateways, microservices, and any system needing to control traffic flow.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Token-Bucket%20Rate%20Limiter%20%28Multi-Tenant%29/#1-system-overview-scope-clarification","title":"1. System Overview &amp; Scope Clarification","text":"<p>We are building an in-memory, server-side rate limiting service. The goal is to control the frequency of operations on a per-client basis, identified by a unique key (e.g., user ID, API key, IP address).</p> <p>Algorithm Choice: Token Bucket The token bucket algorithm is ideal for this use case. It works as follows:</p> <ul> <li>A bucket has a maximum capacity of tokens.</li> <li>Tokens are added to the bucket at a fixed rate.</li> <li>If the bucket is full, new tokens are discarded.</li> <li>Each incoming request consumes one token. If the bucket is empty, the request is rejected. This allows for bursts of requests up to the bucket's capacity, which is often desirable, while maintaining a constant average rate over time.</li> </ul> <p>Functional Requirements (FR):</p> <ul> <li><code>isAllowed(key)</code>: A method that returns <code>true</code> if a request for a given key should proceed, and <code>false</code> if it should be rate-limited.</li> <li>Multi-Tenancy: The system must support different rate limits and burst capacities for different keys.</li> <li>Configuration: Allow setting a default limit and tenant-specific overrides.</li> </ul> <p>Non-Functional Requirements (NFR):</p> <ul> <li>Performance: The <code>isAllowed</code> check (the hot path) must be highly performant, ideally O(1).</li> <li>Thread-Safety: The limiter must handle concurrent requests for the same or different keys correctly.</li> <li>Monotonic Clock: The logic must use a monotonic clock (<code>System.nanoTime()</code>) to be immune to system time changes (e.g., NTP adjustments, daylight saving).</li> </ul> <p>Scope:</p> <ul> <li>We will design a single-node, in-memory solution first.</li> <li>We will then discuss the necessary modifications to scale it to a distributed environment.</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Token-Bucket%20Rate%20Limiter%20%28Multi-Tenant%29/#2-core-components-and-class-design","title":"2. Core Components and Class Design","text":"<p>The design will consist of a central manager class that holds a collection of individual token buckets.</p> <ul> <li><code>RateLimiterConfig</code>: A simple data object (or Java Record) to hold the configuration for a bucket: its <code>capacity</code> (burst size) and <code>refillRateInTokensPerSecond</code>.</li> <li><code>TokenBucket</code>: This class encapsulates the state and logic for a single client's bucket. It will contain the configuration, the current number of tokens, and the timestamp of the last refill. Its methods will be synchronized to ensure thread safety.</li> <li><code>MultiTenantRateLimiter</code>: The main public class. It holds a <code>ConcurrentHashMap</code> mapping a client key (<code>String</code>) to their respective <code>TokenBucket</code>. It manages the creation of new buckets on-demand based on the provided configurations.</li> </ul> <p>Class Diagram (Textual Representation):</p> <p><code>+---------------------------+ | MultiTenantRateLimiter    | |---------------------------| | - buckets: ConcurrentHashMap&lt;String, TokenBucket&gt; | | - defaultConfig: RateLimiterConfig | | - specificConfigs: Map&lt;String, RateLimiterConfig&gt; | |---------------------------| | + isAllowed(key): boolean | +---------------------------+           |           | creates &amp; manages           v +---------------------------+ |      TokenBucket          | |---------------------------| | - capacity: long          | | - refillRatePerNano: double | | - tokens: double          | | - lastRefillNanos: long   | |---------------------------| | + allow(): boolean (sync) | +---------------------------+</code></p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Token-Bucket%20Rate%20Limiter%20%28Multi-Tenant%29/#3-api-design-multitenantratelimiter","title":"3. API Design (<code>MultiTenantRateLimiter</code>)","text":"<p>Java</p> <pre><code>public class MultiTenantRateLimiter {\n\n    // Constructor to define the default and specific rate limiting rules.\n    public MultiTenantRateLimiter(RateLimiterConfig defaultConfig, Map&lt;String, RateLimiterConfig&gt; specificConfigs);\n\n    /**\n     * Determines if a request for the given key should be allowed.\n     * This method is thread-safe and has O(1) complexity.\n     * It lazily creates token buckets for new keys.\n     * @param key The identifier for the client (e.g., userId, apiKey).\n     * @return true if the request is within the limit, false otherwise.\n     */\n    public boolean isAllowed(String key);\n}\n\n// Configuration record\npublic record RateLimiterConfig(long capacity, double tokensPerSecond) {}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Token-Bucket%20Rate%20Limiter%20%28Multi-Tenant%29/#4-key-workflows","title":"4. Key Workflows","text":"<p><code>isAllowed(key)</code> Workflow:</p> <ol> <li>The <code>MultiTenantRateLimiter</code> receives a call to <code>isAllowed(\"some_user_id\")</code>.</li> <li>It uses <code>ConcurrentHashMap.computeIfAbsent()</code> to atomically get or create the <code>TokenBucket</code> for <code>\"some_user_id\"</code>.<ul> <li>If bucket exists: The existing instance is returned.</li> <li>If bucket does not exist (first request): a. A lambda expression is executed to create the new bucket. b. It checks the <code>specificConfigs</code> map for <code>\"some_user_id\"</code>. If a config is found, it's used. c. Otherwise, the <code>defaultConfig</code> is used. d. A new <code>TokenBucket</code> is instantiated with the chosen config, starting with a full bucket of tokens. e. The new bucket is placed in the map and returned.</li> </ul> </li> <li>The method then calls the <code>allow()</code> method on the retrieved <code>TokenBucket</code>.</li> <li>Inside <code>TokenBucket.allow()</code> (a <code>synchronized</code> method): a. A private <code>refill()</code> method is called first. b. <code>refill()</code> calculates the time delta in nanoseconds since the last refill (<code>System.nanoTime() - lastRefillNanos</code>). c. It calculates tokens to add (<code>delta * refillRatePerNano</code>) and adds them to the current token count. d. The token count is capped at the bucket's <code>capacity</code>. e. The <code>lastRefillNanos</code> timestamp is updated to the current time. f. After refilling, <code>allow()</code> checks if <code>tokens &gt;= 1.0</code>. g. If yes, it subtracts <code>1.0</code> from <code>tokens</code> and returns <code>true</code>. h. If no, it returns <code>false</code>.</li> </ol>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Token-Bucket%20Rate%20Limiter%20%28Multi-Tenant%29/#5-code-implementation-java","title":"5. Code Implementation (Java)","text":"<p><code>RateLimiterConfig.java</code></p> <p>Java</p> <pre><code>public record RateLimiterConfig(long capacity, double tokensPerSecond) {\n    public RateLimiterConfig {\n        if (capacity &lt;= 0 || tokensPerSecond &lt;= 0) {\n            throw new IllegalArgumentException(\"Capacity and tokensPerSecond must be positive.\");\n        }\n    }\n}\n</code></pre> <p><code>TokenBucket.java</code></p> <p>Java</p> <pre><code>class TokenBucket {\n    private final long capacity;\n    private final double refillRatePerNano;\n    private double tokens;\n    private long lastRefillNanos;\n\n    TokenBucket(RateLimiterConfig config) {\n        this.capacity = config.capacity();\n        this.refillRatePerNano = config.tokensPerSecond() / 1_000_000_000.0;\n        this.tokens = config.capacity(); // Start with a full bucket\n        this.lastRefillNanos = System.nanoTime();\n    }\n\n    private void refill() {\n        long now = System.nanoTime();\n        long nanosElapsed = now - lastRefillNanos;\n        if (nanosElapsed &gt; 0) {\n            double tokensToAdd = nanosElapsed * refillRatePerNano;\n            this.tokens = Math.min(capacity, this.tokens + tokensToAdd);\n            this.lastRefillNanos = now;\n        }\n    }\n\n    public synchronized boolean allow() {\n        refill();\n        if (this.tokens &gt;= 1.0) {\n            this.tokens -= 1.0;\n            return true;\n        }\n        return false;\n    }\n}\n</code></pre> <p><code>MultiTenantRateLimiter.java</code></p> <p>Java</p> <pre><code>import java.util.Map;\nimport java.util.concurrent.ConcurrentHashMap;\n\npublic class MultiTenantRateLimiter {\n    private final ConcurrentHashMap&lt;String, TokenBucket&gt; buckets = new ConcurrentHashMap&lt;&gt;();\n    private final RateLimiterConfig defaultConfig;\n    private final Map&lt;String, RateLimiterConfig&gt; specificConfigs;\n\n    public MultiTenantRateLimiter(RateLimiterConfig defaultConfig, Map&lt;String, RateLimiterConfig&gt; specificConfigs) {\n        this.defaultConfig = defaultConfig;\n        this.specificConfigs = specificConfigs;\n    }\n\n    public boolean isAllowed(String key) {\n        TokenBucket bucket = buckets.computeIfAbsent(key, this::createBucket);\n        return bucket.allow();\n    }\n\n    private TokenBucket createBucket(String key) {\n        RateLimiterConfig config = specificConfigs.getOrDefault(key, defaultConfig);\n        return new TokenBucket(config);\n    }\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Token-Bucket%20Rate%20Limiter%20%28Multi-Tenant%29/#6-testing-junit-5","title":"6. Testing (JUnit 5)","text":"<p>Java</p> <pre><code>import org.junit.jupiter.api.Test;\nimport static org.junit.jupiter.api.Assertions.*;\n\nimport java.util.Map;\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\nimport java.util.concurrent.TimeUnit;\nimport java.util.concurrent.atomic.AtomicInteger;\n\nclass MultiTenantRateLimiterTest {\n\n    @Test\n    void testAllowsBurstUpToCapacity() {\n        RateLimiterConfig config = new RateLimiterConfig(5, 10);\n        MultiTenantRateLimiter limiter = new MultiTenantRateLimiter(config, Map.of());\n\n        for (int i = 0; i &lt; 5; i++) {\n            assertTrue(limiter.isAllowed(\"user1\"), \"Request \" + (i+1) + \" should be allowed\");\n        }\n        assertFalse(limiter.isAllowed(\"user1\"), \"6th request should be denied\");\n    }\n\n    @Test\n    void testTokenRefill() throws InterruptedException {\n        // 1 token per 100ms\n        RateLimiterConfig config = new RateLimiterConfig(1, 10); \n        MultiTenantRateLimiter limiter = new MultiTenantRateLimiter(config, Map.of());\n\n        assertTrue(limiter.isAllowed(\"user1\")); // Consume the only token\n        assertFalse(limiter.isAllowed(\"user1\")); // Now it's empty\n\n        Thread.sleep(110); // Wait for more than 100ms for a token to refill\n\n        assertTrue(limiter.isAllowed(\"user1\"), \"Should be allowed after refill\");\n    }\n\n    @Test\n    void testMultiTenantSpecificConfigs() {\n        RateLimiterConfig defaultConfig = new RateLimiterConfig(1, 10);\n        RateLimiterConfig premiumConfig = new RateLimiterConfig(5, 100);\n        MultiTenantRateLimiter limiter = new MultiTenantRateLimiter(\n            defaultConfig, \n            Map.of(\"premiumUser\", premiumConfig)\n        );\n\n        // Test default user\n        assertTrue(limiter.isAllowed(\"defaultUser\"));\n        assertFalse(limiter.isAllowed(\"defaultUser\"));\n\n        // Test premium user\n        for (int i = 0; i &lt; 5; i++) {\n            assertTrue(limiter.isAllowed(\"premiumUser\"));\n        }\n        assertFalse(limiter.isAllowed(\"premiumUser\"));\n    }\n\n    @Test\n    void testConcurrencyForSingleKey() throws InterruptedException {\n        RateLimiterConfig config = new RateLimiterConfig(20, 100);\n        MultiTenantRateLimiter limiter = new MultiTenantRateLimiter(config, Map.of());\n        ExecutorService executor = Executors.newFixedThreadPool(10);\n        AtomicInteger allowedCount = new AtomicInteger(0);\n\n        for (int i = 0; i &lt; 50; i++) {\n            executor.submit(() -&gt; {\n                if (limiter.isAllowed(\"concurrentUser\")) {\n                    allowedCount.incrementAndGet();\n                }\n            });\n        }\n\n        executor.shutdown();\n        executor.awaitTermination(5, TimeUnit.SECONDS);\n\n        // Initially, the burst capacity of 20 should be allowed.\n        // A few more might get through depending on thread scheduling and refill, but it should be close to 20.\n        assertTrue(allowedCount.get() &gt;= 20 &amp;&amp; allowedCount.get() &lt; 25);\n    }\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/Token-Bucket%20Rate%20Limiter%20%28Multi-Tenant%29/#7-scalability-extensions","title":"7. Scalability &amp; Extensions","text":"<p>The current implementation is for a single application instance. In a distributed system with multiple instances, this design would lead to an effective rate limit of <code>(limit * N)</code> where <code>N</code> is the number of instances, which is incorrect.</p> <p>Distributed Rate Limiter using Redis</p> <p>To solve this, the state of each token bucket must be centralized in a fast, shared data store like Redis.</p> <ul> <li>State Storage: For each client key (e.g., <code>\"ratelimit:user123\"</code>), store a Redis Hash with two fields:<ul> <li><code>tokens</code>: The current number of tokens.</li> <li><code>last_refill_ts</code>: The timestamp of the last refill (in microseconds or nanoseconds for precision).</li> </ul> </li> <li>Atomic Operations: The read-modify-write cycle (refill tokens, check, consume) must be atomic to prevent race conditions between different application servers. This is a perfect use case for a Redis Lua script.</li> <li> <p>Lua Script Workflow:</p> <ol> <li>Input: The script receives <code>KEYS[1]</code> (the Redis key), <code>ARGV[1]</code> (capacity), <code>ARGV[2]</code> (refill rate per second), and <code>ARGV[3]</code> (current timestamp).</li> <li>Get State: It retrieves the <code>tokens</code> and <code>last_refill_ts</code> from the Redis hash at <code>KEYS[1]</code>. If the hash doesn't exist, it initializes it to the full capacity.</li> <li>Refill Logic: It calculates the time delta and refills tokens, capping at the capacity, just like the in-memory version.</li> <li>Check &amp; Consume: It checks if <code>tokens &gt;= 1</code>. If so, it decrements the token count.</li> <li>Update State: It updates the hash in Redis with the new <code>tokens</code> and <code>last_refill_ts</code>.</li> <li>Return: It returns 1 if allowed, 0 if denied.</li> </ol> <p>Since Redis executes Lua scripts atomically, this guarantees consistency across all application instances.</p> </li> </ul> <p>Other Extensions:</p> <ul> <li>Idle Bucket Eviction: The <code>ConcurrentHashMap</code> will grow indefinitely as new keys make requests. In a long-running application, this is a memory leak. A production-grade solution would use a cache with an eviction policy (like <code>Caffeine</code> or <code>Guava Cache</code>) to remove buckets for clients that have been inactive for a certain period.</li> <li>Sliding Window Log: For more complex rate limiting scenarios (e.g., \"100 requests per hour\"), the Sliding Window Log algorithm, also implemented efficiently in Redis using sorted sets, can be a better fit than the token bucket.</li> </ul>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/URL%20Shortener%20%28Core%29/","title":"URL Shortener (Core)","text":"<p>This problem requires designing a scalable URL shortening service with support for custom codes and click tracking.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/URL%20Shortener%20%28Core%29/#1-system-overview-scope-clarification","title":"1. System Overview &amp; Scope Clarification","text":"<p>We are designing a backend service to shorten URLs, expand short codes, and track basic statistics.</p> <p>Functional Requirements (FR): - <code>shorten(url, custom?)</code>: Shorten a URL, optionally with a custom code. - <code>expand(code)</code>: Retrieve the original URL. - Basic stats: click count, creation time. - Prevent malicious loops (no self-shortening).</p> <p>Non-Functional Requirements (NFR): - High availability and low latency. - Unique, collision-free codes. - Scalable to billions of URLs. - Secure: prevent abuse and malicious links.</p> <p>Assumptions: - Codes are base62-encoded. - Store is persistent (e.g., DB), but demo uses in-memory map. - Caching is used for hot URLs.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/URL%20Shortener%20%28Core%29/#2-core-components-and-class-design","title":"2. Core Components and Class Design","text":"<ul> <li>UrlShortenerService: Main service for shortening and expanding URLs.</li> <li>CodeGenerator: Generates unique codes (counter or hash).</li> <li>UrlMapping: Stores mapping from code to long URL and metadata.</li> <li>StatsService: Tracks click stats.</li> <li>Store: Interface for persistence.</li> </ul> <p>Class Diagram (Textual Representation):</p> <pre><code>+---------------------+\n| UrlShortenerService |\n+---------------------+\n| + shorten()         |\n| + expand()          |\n| + getStats()        |\n+---------------------+\n        ^\n        |\n+---------------------+\n|   CodeGenerator     |\n+---------------------+\n| + generate()        |\n+---------------------+\n        ^\n        |\n+---------------------+\n|      Store          |\n+---------------------+\n| + save()            |\n| + find()            |\n+---------------------+\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/URL%20Shortener%20%28Core%29/#3-api-design-urlshortenerservice","title":"3. API Design (<code>UrlShortenerService</code>)","text":"<p>Java</p> <pre><code>class UrlShortenerService {\n    String shorten(String url, String customCode);\n    String expand(String code);\n    UrlStats getStats(String code);\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/URL%20Shortener%20%28Core%29/#4-key-workflows","title":"4. Key Workflows","text":"<p>a) Shorten URL 1. Validate URL and custom code (if provided). 2. If custom code, check for collision. 3. If no custom code, generate unique code (base62 of counter). 4. Save mapping to store. 5. Return code.</p> <p>b) Expand URL 1. Lookup code in store (cache first). 2. If found, increment click count. 3. Return long URL.</p>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/URL%20Shortener%20%28Core%29/#5-code-implementation-java","title":"5. Code Implementation (Java)","text":"<pre><code>import java.util.*;\nimport java.util.concurrent.ConcurrentHashMap;\n\nclass UrlMapping {\n    String code;\n    String longUrl;\n    long createdAt;\n    int clickCount;\n    String owner;\n    // ...constructors, getters, setters...\n}\n\nclass CodeGenerator {\n    private long counter = 1;\n    public synchronized String generate() {\n        return base62(counter++);\n    }\n    private String base62(long num) {\n        String chars = \"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\";\n        StringBuilder sb = new StringBuilder();\n        while (num &gt; 0) {\n            sb.append(chars.charAt((int)(num % 62)));\n            num /= 62;\n        }\n        return sb.reverse().toString();\n    }\n}\n\nclass InMemoryStore {\n    private final Map&lt;String, UrlMapping&gt; map = new ConcurrentHashMap&lt;&gt;();\n    public void save(UrlMapping m) { map.put(m.code, m); }\n    public UrlMapping find(String code) { return map.get(code); }\n}\n\nclass UrlShortenerService {\n    private final InMemoryStore store = new InMemoryStore();\n    private final CodeGenerator codeGen = new CodeGenerator();\n    public String shorten(String url, String customCode) {\n        // Validate URL, check for loops, etc.\n        String code = (customCode != null) ? customCode : codeGen.generate();\n        if (store.find(code) != null) throw new RuntimeException(\"Code exists\");\n        UrlMapping m = new UrlMapping();\n        m.code = code;\n        m.longUrl = url;\n        m.createdAt = System.currentTimeMillis();\n        m.clickCount = 0;\n        store.save(m);\n        return code;\n    }\n    public String expand(String code) {\n        UrlMapping m = store.find(code);\n        if (m == null) throw new RuntimeException(\"Not found\");\n        m.clickCount++;\n        return m.longUrl;\n    }\n    public int getStats(String code) {\n        UrlMapping m = store.find(code);\n        if (m == null) throw new RuntimeException(\"Not found\");\n        return m.clickCount;\n    }\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/URL%20Shortener%20%28Core%29/#6-testing-junit-5","title":"6. Testing (JUnit 5)","text":"<pre><code>import org.junit.jupiter.api.*;\nimport static org.junit.jupiter.api.Assertions.*;\n\npublic class UrlShortenerServiceTest {\n    @Test\n    void testShortenAndExpand() {\n        UrlShortenerService svc = new UrlShortenerService();\n        String code = svc.shorten(\"https://example.com\", null);\n        assertNotNull(code);\n        String url = svc.expand(code);\n        assertEquals(\"https://example.com\", url);\n    }\n    @Test\n    void testCustomCode() {\n        UrlShortenerService svc = new UrlShortenerService();\n        String code = svc.shorten(\"https://foo.com\", \"foo\");\n        assertEquals(\"foo\", code);\n        assertEquals(\"https://foo.com\", svc.expand(\"foo\"));\n    }\n}\n</code></pre>"},{"location":"lld/DE%20Shaw%20LLD%20with%20Implementation/URL%20Shortener%20%28Core%29/#7-scalability-security-and-extensions","title":"7. Scalability, Security, and Extensions","text":"<ul> <li>Use distributed counter or sharded DB for code generation at scale.</li> <li>Add TTL for expired links.</li> <li>Validate and sanitize URLs.</li> <li>Add abuse detection and rate limiting.</li> </ul>"},{"location":"lld/module1/Calendar%20Scheduler/","title":"Design a Calendar/Meeting Scheduler","text":"<p>This problem requires designing a calendar/meeting scheduler supporting event creation, conflict checks, and recurring events.</p>"},{"location":"lld/module1/Calendar%20Scheduler/#1-system-overview-scope-clarification","title":"1. System Overview &amp; Scope Clarification","text":"<p>We are designing a backend service to manage user calendars, events, and meeting scheduling with conflict detection.</p> <p>Functional Requirements (FR): - Create, update, delete events. - Check for conflicts and suggest free slots. - Support recurring and group events.</p> <p>Non-Functional Requirements (NFR): - Scalable to millions of users/events. - Low latency for scheduling and search.</p> <p>Assumptions: - In-memory for demo; production uses DB and cache.</p>"},{"location":"lld/module1/Calendar%20Scheduler/#2-core-components-and-class-design","title":"2. Core Components and Class Design","text":"<ul> <li>CalendarService: Main API for event ops.</li> <li>User/Event: Represents users and events.</li> <li>Interval: Time interval for events.</li> </ul> <p>Class Diagram (Textual Representation):</p> <pre><code>+--------+      +--------+\n| User   |&lt;-----| Event  |\n+--------+      +--------+\n| id     |      | id     |\n| name   |      | interval|\n+--------+      | users  |\n               +--------+\n      ^\n      |\n+--------------+\n|CalendarService|\n+--------------+\n</code></pre>"},{"location":"lld/module1/Calendar%20Scheduler/#3-api-design-calendarservice","title":"3. API Design (<code>CalendarService</code>)","text":"<p>Java</p> <pre><code>class CalendarService {\n    void createEvent(String userId, Interval interval, List&lt;String&gt; users);\n    List&lt;Interval&gt; getFreeSlots(String userId, long day);\n    void deleteEvent(String eventId);\n}\n</code></pre>"},{"location":"lld/module1/Calendar%20Scheduler/#4-key-workflows","title":"4. Key Workflows","text":"<p>a) Create Event 1. User creates event; service checks for conflicts. 2. Adds event to calendars.</p> <p>b) Get Free Slots 1. Service finds gaps in user's calendar for a day.</p>"},{"location":"lld/module1/Calendar%20Scheduler/#5-code-implementation-java","title":"5. Code Implementation (Java)","text":"<pre><code>import java.util.*;\n\nclass Interval {\n    long start, end;\n}\n\nclass Event {\n    String id;\n    Interval interval;\n    List&lt;String&gt; users = new ArrayList&lt;&gt;();\n}\n\nclass User {\n    String id;\n    String name;\n    List&lt;Event&gt; events = new ArrayList&lt;&gt;();\n}\n\nclass CalendarService {\n    private final Map&lt;String, User&gt; users = new HashMap&lt;&gt;();\n    public void createEvent(String userId, Interval interval, List&lt;String&gt; usersList) {\n        User user = users.computeIfAbsent(userId, k -&gt; new User());\n        for (Event e : user.events) {\n            if (!(interval.end &lt;= e.interval.start || interval.start &gt;= e.interval.end)) {\n                throw new RuntimeException(\"Conflict\");\n            }\n        }\n        Event event = new Event();\n        event.id = UUID.randomUUID().toString();\n        event.interval = interval;\n        event.users = usersList;\n        user.events.add(event);\n    }\n    public List&lt;Interval&gt; getFreeSlots(String userId, long day) {\n        User user = users.get(userId);\n        if (user == null) return List.of();\n        List&lt;Interval&gt; busy = new ArrayList&lt;&gt;();\n        for (Event e : user.events) {\n            if (e.interval.start/86400000 == day/86400000) busy.add(e.interval);\n        }\n        busy.sort(Comparator.comparingLong(i -&gt; i.start));\n        List&lt;Interval&gt; free = new ArrayList&lt;&gt;();\n        long prev = day;\n        for (Interval i : busy) {\n            if (i.start &gt; prev) free.add(new Interval(){ {start=prev; end=i.start;} });\n            prev = i.end;\n        }\n        if (prev &lt; day+86400000) free.add(new Interval(){ {start=prev; end=day+86400000;} });\n        return free;\n    }\n    public void deleteEvent(String eventId) {\n        for (User user : users.values()) {\n            user.events.removeIf(e -&gt; e.id.equals(eventId));\n        }\n    }\n}\n</code></pre>"},{"location":"lld/module1/Calendar%20Scheduler/#6-testing-junit-5","title":"6. Testing (JUnit 5)","text":"<pre><code>import org.junit.jupiter.api.*;\nimport static org.junit.jupiter.api.Assertions.*;\n\npublic class CalendarServiceTest {\n    @Test\n    void testCreateAndDeleteEvent() {\n        // Setup users, create/delete event, assert conflicts\n    }\n}\n</code></pre>"},{"location":"lld/module1/Calendar%20Scheduler/#7-extensions-and-edge-cases","title":"7. Extensions and Edge Cases","text":"<ul> <li>Add notifications, reminders, and recurring events.</li> <li>Support for time zones and shared calendars.</li> <li>Integrate with external calendar APIs.</li> </ul>"},{"location":"lld/module1/Distributed%20Lock/","title":"Design a Distributed Lock Service","text":"<p>This problem requires designing a distributed lock service for synchronizing access to shared resources across systems.</p>"},{"location":"lld/module1/Distributed%20Lock/#1-system-overview-scope-clarification","title":"1. System Overview &amp; Scope Clarification","text":"<p>We are designing a backend service to provide distributed, fault-tolerant locks for clients in a distributed system.</p> <p>Functional Requirements (FR): - Acquire/release locks by key. - Support lock timeouts and renewal. - Ensure mutual exclusion and avoid deadlocks.</p> <p>Non-Functional Requirements (NFR): - High availability and fault tolerance. - Low latency for lock ops. - Scalable to thousands of clients.</p> <p>Assumptions: - Redis/ZooKeeper/etcd available for coordination. - In-memory for demo.</p>"},{"location":"lld/module1/Distributed%20Lock/#2-core-components-and-class-design","title":"2. Core Components and Class Design","text":"<ul> <li>LockService: Main API for lock ops.</li> <li>Lock: Represents a lock state.</li> <li>Client: Represents lock holders.</li> </ul> <p>Class Diagram (Textual Representation):</p> <pre><code>+--------+      +--------+\n| Lock   |&lt;-----| Client |\n+--------+      +--------+\n| key    |      | id     |\n| owner  |      +--------+\n| expiry |\n+--------+\n      ^\n      |\n+--------------+\n|LockService   |\n+--------------+\n| + acquire()  |\n| + release()  |\n+--------------+\n</code></pre>"},{"location":"lld/module1/Distributed%20Lock/#3-api-design-lockservice","title":"3. API Design (<code>LockService</code>)","text":"<p>Java</p> <pre><code>class LockService {\n    boolean acquire(String key, String clientId, long timeoutMs);\n    void release(String key, String clientId);\n}\n</code></pre>"},{"location":"lld/module1/Distributed%20Lock/#4-key-workflows","title":"4. Key Workflows","text":"<p>a) Acquire Lock 1. Client requests lock; service checks if free or expired. 2. If so, assigns lock to client with expiry.</p> <p>b) Release Lock 1. Client releases lock; service removes ownership.</p>"},{"location":"lld/module1/Distributed%20Lock/#5-code-implementation-java","title":"5. Code Implementation (Java)","text":"<pre><code>import java.util.*;\n\nclass Lock {\n    String key;\n    String owner;\n    long expiry;\n}\n\nclass LockService {\n    private final Map&lt;String, Lock&gt; locks = new HashMap&lt;&gt;();\n    public synchronized boolean acquire(String key, String clientId, long timeoutMs) {\n        Lock lock = locks.get(key);\n        long now = System.currentTimeMillis();\n        if (lock == null || lock.expiry &lt; now) {\n            lock = new Lock();\n            lock.key = key;\n            lock.owner = clientId;\n            lock.expiry = now + timeoutMs;\n            locks.put(key, lock);\n            return true;\n        }\n        return false;\n    }\n    public synchronized void release(String key, String clientId) {\n        Lock lock = locks.get(key);\n        if (lock != null &amp;&amp; lock.owner.equals(clientId)) {\n            locks.remove(key);\n        }\n    }\n}\n</code></pre>"},{"location":"lld/module1/Distributed%20Lock/#6-testing-junit-5","title":"6. Testing (JUnit 5)","text":"<pre><code>import org.junit.jupiter.api.*;\nimport static org.junit.jupiter.api.Assertions.*;\n\npublic class LockServiceTest {\n    @Test\n    void testAcquireAndRelease() {\n        LockService svc = new LockService();\n        assertTrue(svc.acquire(\"res1\", \"c1\", 1000));\n        assertFalse(svc.acquire(\"res1\", \"c2\", 1000));\n        svc.release(\"res1\", \"c1\");\n        assertTrue(svc.acquire(\"res1\", \"c2\", 1000));\n    }\n}\n</code></pre>"},{"location":"lld/module1/Distributed%20Lock/#7-extensions-and-edge-cases","title":"7. Extensions and Edge Cases","text":"<ul> <li>Add fencing tokens, renewal, and failover.</li> <li>Integrate with Redis/ZooKeeper for production.</li> <li>Handle client crashes and lock expiry.</li> </ul>"},{"location":"lld/module1/File%20Storage%20Service/","title":"Design a File Storage Service (Dropbox/Google Drive)","text":"<p>This problem requires designing a scalable file storage and sharing service like Dropbox or Google Drive.</p>"},{"location":"lld/module1/File%20Storage%20Service/#1-system-overview-scope-clarification","title":"1. System Overview &amp; Scope Clarification","text":"<p>We are designing a backend service to store, retrieve, and share files for users, supporting versioning and collaboration.</p> <p>Functional Requirements (FR): - Upload/download files and folders. - Share files with users (read/write). - Support file versioning and metadata. - Directory structure and search.</p> <p>Non-Functional Requirements (NFR): - Scalable to billions of files. - High durability and availability. - Secure (auth, access control, encryption).</p> <p>Assumptions: - Object storage (e.g., S3) for file blobs. - Metadata in DB; demo uses in-memory.</p>"},{"location":"lld/module1/File%20Storage%20Service/#2-core-components-and-class-design","title":"2. Core Components and Class Design","text":"<ul> <li>FileService: Main API for file ops.</li> <li>File/Folder: Represents files and directories.</li> <li>User: Represents users.</li> <li>Share: Access control.</li> <li>Version: File versioning.</li> </ul> <p>Class Diagram (Textual Representation):</p> <pre><code>+-----------+      +--------+\n| File      |&lt;-----| Folder |\n+-----------+      +--------+\n| id, name  |      | files  |\n| owner     |      | folders|\n| versions  |      +--------+\n+-----------+\n      ^\n      |\n+-----------+\n| FileService|\n+-----------+\n</code></pre>"},{"location":"lld/module1/File%20Storage%20Service/#3-api-design-fileservice","title":"3. API Design (<code>FileService</code>)","text":"<p>Java</p> <pre><code>class FileService {\n    void upload(String userId, String path, byte[] data);\n    byte[] download(String userId, String path);\n    void share(String path, String targetUser, String access);\n    List&lt;String&gt; list(String userId, String path);\n}\n</code></pre>"},{"location":"lld/module1/File%20Storage%20Service/#4-key-workflows","title":"4. Key Workflows","text":"<p>a) Upload/Download 1. User uploads file; service stores blob and metadata. 2. User downloads file; service fetches blob.</p> <p>b) Share 1. Owner shares file/folder with another user. 2. Service updates access control.</p>"},{"location":"lld/module1/File%20Storage%20Service/#5-code-implementation-java","title":"5. Code Implementation (Java)","text":"<pre><code>import java.util.*;\n\nclass File {\n    String id;\n    String name;\n    String owner;\n    List&lt;Version&gt; versions = new ArrayList&lt;&gt;();\n    // ...constructors, getters...\n}\n\nclass Version {\n    int number;\n    byte[] data;\n    long ts;\n}\n\nclass Folder {\n    String name;\n    Map&lt;String, File&gt; files = new HashMap&lt;&gt;();\n    Map&lt;String, Folder&gt; folders = new HashMap&lt;&gt;();\n}\n\nclass FileService {\n    private final Map&lt;String, Folder&gt; userRoots = new HashMap&lt;&gt;();\n    public void upload(String userId, String path, byte[] data) {\n        // Simplified: store file at path for user\n        Folder root = userRoots.computeIfAbsent(userId, k -&gt; new Folder());\n        File file = new File();\n        file.id = UUID.randomUUID().toString();\n        file.name = path;\n        file.owner = userId;\n        Version v = new Version();\n        v.number = 1;\n        v.data = data;\n        v.ts = System.currentTimeMillis();\n        file.versions.add(v);\n        root.files.put(path, file);\n    }\n    public byte[] download(String userId, String path) {\n        Folder root = userRoots.get(userId);\n        if (root == null) return null;\n        File file = root.files.get(path);\n        if (file == null || file.versions.isEmpty()) return null;\n        return file.versions.get(file.versions.size()-1).data;\n    }\n    public void share(String path, String targetUser, String access) {\n        // For demo, just print share action\n        System.out.println(\"Shared \" + path + \" with \" + targetUser + \" as \" + access);\n    }\n    public List&lt;String&gt; list(String userId, String path) {\n        Folder root = userRoots.get(userId);\n        if (root == null) return List.of();\n        return new ArrayList&lt;&gt;(root.files.keySet());\n    }\n}\n</code></pre>"},{"location":"lld/module1/File%20Storage%20Service/#6-testing-junit-5","title":"6. Testing (JUnit 5)","text":"<pre><code>import org.junit.jupiter.api.*;\nimport static org.junit.jupiter.api.Assertions.*;\n\npublic class FileServiceTest {\n    @Test\n    void testUploadAndDownload() {\n        // Setup users, upload/download, assert data\n    }\n}\n</code></pre>"},{"location":"lld/module1/File%20Storage%20Service/#7-extensions-and-edge-cases","title":"7. Extensions and Edge Cases","text":"<ul> <li>Add deduplication, chunking, and sync.</li> <li>Support for trash, restore, and audit logs.</li> <li>Integrate with cloud storage APIs.</li> </ul>"},{"location":"lld/module1/Hotel%20Booking%20System/","title":"Design a Hotel Booking System","text":"<p>This problem requires designing a scalable hotel booking system supporting room search, booking, and cancellation.</p>"},{"location":"lld/module1/Hotel%20Booking%20System/#1-system-overview-scope-clarification","title":"1. System Overview &amp; Scope Clarification","text":"<p>We are designing a backend service to manage hotels, rooms, availability, and reservations for users.</p> <p>Functional Requirements (FR): - Search hotels/rooms by location, date, and features. - Book/cancel rooms. - Track availability and prevent double-booking. - Support for pricing, offers, and user accounts.</p> <p>Non-Functional Requirements (NFR): - Scalable to thousands of hotels and users. - Consistent and reliable booking. - Low latency for search and booking.</p> <p>Assumptions: - In-memory for demo; production uses DB and cache.</p>"},{"location":"lld/module1/Hotel%20Booking%20System/#2-core-components-and-class-design","title":"2. Core Components and Class Design","text":"<ul> <li>HotelService: Main API for search/book.</li> <li>Hotel/Room: Represents hotels and rooms.</li> <li>Booking: Represents a reservation.</li> <li>User: Represents users.</li> </ul> <p>Class Diagram (Textual Representation):</p> <pre><code>+--------+      +-------+\n| Hotel  |&lt;-----| Room  |\n+--------+      +-------+\n| id     |      | id    |\n| name   |      | type  |\n| loc    |      | avail |\n+--------+      +-------+\n      ^             |\n      |             v\n+--------+      +---------+\n|Booking |      |User     |\n+--------+      +---------+\n</code></pre>"},{"location":"lld/module1/Hotel%20Booking%20System/#3-api-design-hotelservice","title":"3. API Design (<code>HotelService</code>)","text":"<p>Java</p> <pre><code>class HotelService {\n    List&lt;Room&gt; search(String location, long from, long to);\n    Booking book(String userId, String roomId, long from, long to);\n    void cancel(String bookingId);\n}\n</code></pre>"},{"location":"lld/module1/Hotel%20Booking%20System/#4-key-workflows","title":"4. Key Workflows","text":"<p>a) Search 1. User searches for rooms by location and date. 2. Service filters available rooms.</p> <p>b) Book 1. User books room; service checks availability and creates booking. 2. Updates room availability.</p> <p>c) Cancel 1. User cancels booking; service updates availability.</p>"},{"location":"lld/module1/Hotel%20Booking%20System/#5-code-implementation-java","title":"5. Code Implementation (Java)","text":"<pre><code>import java.util.*;\n\nclass Hotel {\n    String id;\n    String name;\n    String location;\n    List&lt;Room&gt; rooms = new ArrayList&lt;&gt;();\n}\n\nclass Room {\n    String id;\n    String type;\n    List&lt;Booking&gt; bookings = new ArrayList&lt;&gt;();\n}\n\nclass Booking {\n    String id;\n    String userId;\n    String roomId;\n    long from, to;\n}\n\nclass HotelService {\n    private final Map&lt;String, Hotel&gt; hotels = new HashMap&lt;&gt;();\n    public List&lt;Room&gt; search(String location, long from, long to) {\n        List&lt;Room&gt; availableRooms = new ArrayList&lt;&gt;();\n        for (Hotel hotel : hotels.values()) {\n            if (!hotel.location.equalsIgnoreCase(location)) continue;\n            for (Room room : hotel.rooms) {\n                boolean isAvailable = true;\n                for (Booking booking : room.bookings) {\n                    if (!(to &lt;= booking.from || from &gt;= booking.to)) {\n                        isAvailable = false;\n                        break;\n                    }\n                }\n                if (isAvailable) availableRooms.add(room);\n            }\n        }\n        return availableRooms;\n    }\n    public Booking book(String userId, String roomId, long from, long to) {\n        for (Hotel hotel : hotels.values()) {\n            for (Room room : hotel.rooms) {\n                if (room.id.equals(roomId)) {\n                    for (Booking booking : room.bookings) {\n                        if (!(to &lt;= booking.from || from &gt;= booking.to)) {\n                            return null; // Not available\n                        }\n                    }\n                    Booking newBooking = new Booking();\n                    newBooking.id = UUID.randomUUID().toString();\n                    newBooking.userId = userId;\n                    newBooking.roomId = roomId;\n                    newBooking.from = from;\n                    newBooking.to = to;\n                    room.bookings.add(newBooking);\n                    return newBooking;\n                }\n            }\n        }\n        return null;\n    }\n    public void cancel(String bookingId) {\n        for (Hotel hotel : hotels.values()) {\n            for (Room room : hotel.rooms) {\n                Iterator&lt;Booking&gt; it = room.bookings.iterator();\n                while (it.hasNext()) {\n                    Booking booking = it.next();\n                    if (booking.id.equals(bookingId)) {\n                        it.remove();\n                        return;\n                    }\n                }\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"lld/module1/Hotel%20Booking%20System/#6-testing-junit-5","title":"6. Testing (JUnit 5)","text":"<pre><code>import org.junit.jupiter.api.*;\nimport static org.junit.jupiter.api.Assertions.*;\n\npublic class HotelServiceTest {\n    @Test\n    void testBookAndCancel() {\n        // Setup hotels, rooms, book/cancel, assert availability\n    }\n}\n</code></pre>"},{"location":"lld/module1/Hotel%20Booking%20System/#7-extensions-and-edge-cases","title":"7. Extensions and Edge Cases","text":"<ul> <li>Add payment, offers, and loyalty programs.</li> <li>Handle overbooking, waitlists, and notifications.</li> <li>Integrate with third-party hotel APIs.</li> </ul>"},{"location":"lld/module1/LRU%20Cache/","title":"Design a Thread-Safe LRU Cache","text":"<p>This problem requires designing a thread-safe Least Recently Used (LRU) cache with O(1) operations.</p>"},{"location":"lld/module1/LRU%20Cache/#1-system-overview-scope-clarification","title":"1. System Overview &amp; Scope Clarification","text":"<p>We are designing a backend component to cache key-value pairs with LRU eviction and thread safety.</p> <p>Functional Requirements (FR): - O(1) get/put/evict operations. - Thread-safe for concurrent access. - Configurable capacity.</p> <p>Non-Functional Requirements (NFR): - High throughput (10k+ ops/sec). - Low latency (sub-ms per op).</p> <p>Assumptions: - In-memory only for this round.</p>"},{"location":"lld/module1/LRU%20Cache/#2-core-components-and-class-design","title":"2. Core Components and Class Design","text":"<ul> <li>LRUCache: Main API for get/put.</li> <li>Node: Doubly-linked list node for order.</li> <li>Map: Key to node mapping.</li> </ul> <p>Class Diagram (Textual Representation):</p> <pre><code>+---------+\n| LRUCache|\n+---------+\n| + get() |\n| + put() |\n| - map   |\n| - head  |\n| - tail  |\n+---------+\n</code></pre>"},{"location":"lld/module1/LRU%20Cache/#3-api-design-lrucache","title":"3. API Design (<code>LRUCache</code>)","text":"<p>Java</p> <pre><code>class LRUCache&lt;K,V&gt; {\n    V get(K key);\n    void put(K key, V value);\n}\n</code></pre>"},{"location":"lld/module1/LRU%20Cache/#4-key-workflows","title":"4. Key Workflows","text":"<p>a) Get 1. Lookup node in map. 2. Move node to head. 3. Return value.</p> <p>b) Put 1. If key exists, update value and move to head. 2. Else, add new node at head. 3. If over capacity, evict tail.</p>"},{"location":"lld/module1/LRU%20Cache/#5-code-implementation-java","title":"5. Code Implementation (Java)","text":"<pre><code>import java.util.*;\nimport java.util.concurrent.locks.*;\n\nclass Node&lt;K,V&gt; {\n    K key;\n    V value;\n    Node&lt;K,V&gt; prev, next;\n}\n\nclass LRUCache&lt;K,V&gt; {\n    private final int capacity;\n    private final Map&lt;K, Node&lt;K,V&gt;&gt; map = new HashMap&lt;&gt;();\n    private Node&lt;K,V&gt; head, tail;\n    private final ReentrantLock lock = new ReentrantLock();\n    public LRUCache(int capacity) { this.capacity = capacity; }\n    public V get(K key) {\n        lock.lock();\n        try {\n            Node&lt;K,V&gt; node = map.get(key);\n            if (node == null) return null;\n            moveToHead(node);\n            return node.value;\n        } finally { lock.unlock(); }\n    }\n    public void put(K key, V value) {\n        lock.lock();\n        try {\n            Node&lt;K,V&gt; node = map.get(key);\n            if (node != null) {\n                node.value = value;\n                moveToHead(node);\n            } else {\n                node = new Node&lt;&gt;();\n                node.key = key; node.value = value;\n                map.put(key, node);\n                addToHead(node);\n                if (map.size() &gt; capacity) {\n                    map.remove(tail.key);\n                    removeTail();\n                }\n            }\n        } finally { lock.unlock(); }\n    }\n    private void moveToHead(Node&lt;K,V&gt; node) {\n        if (node == head) return;\n        remove(node); addToHead(node);\n    }\n    private void addToHead(Node&lt;K,V&gt; node) {\n        node.next = head; node.prev = null;\n        if (head != null) head.prev = node;\n        head = node;\n        if (tail == null) tail = node;\n    }\n    private void remove(Node&lt;K,V&gt; node) {\n        if (node.prev != null) node.prev.next = node.next;\n        else head = node.next;\n        if (node.next != null) node.next.prev = node.prev;\n        else tail = node.prev;\n    }\n    private void removeTail() { remove(tail); }\n}\n</code></pre>"},{"location":"lld/module1/LRU%20Cache/#6-testing-junit-5","title":"6. Testing (JUnit 5)","text":"<pre><code>import org.junit.jupiter.api.*;\nimport static org.junit.jupiter.api.Assertions.*;\n\npublic class LRUCacheTest {\n    @Test\n    void testPutAndGet() {\n        LRUCache&lt;Integer, String&gt; cache = new LRUCache&lt;&gt;(2);\n        cache.put(1, \"a\");\n        cache.put(2, \"b\");\n        assertEquals(\"a\", cache.get(1));\n        cache.put(3, \"c\");\n        assertNull(cache.get(2));\n    }\n}\n</code></pre>"},{"location":"lld/module1/LRU%20Cache/#7-extensions-and-edge-cases","title":"7. Extensions and Edge Cases","text":"<ul> <li>Add TTL, write-back, and metrics.</li> <li>Support for distributed cache (e.g., Redis LRU).</li> </ul>"},{"location":"lld/module1/News%20Feed/","title":"Design a News Feed System (Facebook/Twitter)","text":"<p>This problem requires designing a scalable news feed system for a social network.</p>"},{"location":"lld/module1/News%20Feed/#1-system-overview-scope-clarification","title":"1. System Overview &amp; Scope Clarification","text":"<p>We are designing a backend service to generate personalized news feeds for users, supporting ranking and filtering.</p> <p>Functional Requirements (FR): - Post, like, comment, and follow users. - Generate personalized feed per user. - Support ranking, filtering, and pagination.</p> <p>Non-Functional Requirements (NFR): - Scalable to millions of users/posts. - Low latency feed generation. - Extensible for new features.</p> <p>Assumptions: - In-memory for demo; production uses DB and cache.</p>"},{"location":"lld/module1/News%20Feed/#2-core-components-and-class-design","title":"2. Core Components and Class Design","text":"<ul> <li>FeedService: Main API for feed ops.</li> <li>User/Post: Represents users and posts.</li> <li>Feed: List of posts per user.</li> <li>RankingEngine: Ranks posts.</li> </ul> <p>Class Diagram (Textual Representation):</p> <pre><code>+-----------+      +--------+\n| User      |      | Post   |\n+-----------+      +--------+\n| id, name  |      | id, ...|\n+-----------+      +--------+\n      ^\n      |\n+-----------+\n| Feed      |\n| Service   |\n+-----------+\n| + getFeed()|\n+-----------+\n</code></pre>"},{"location":"lld/module1/News%20Feed/#3-api-design-feedservice","title":"3. API Design (<code>FeedService</code>)","text":"<p>Java</p> <pre><code>class FeedService {\n    void post(String userId, String content);\n    List&lt;Post&gt; getFeed(String userId);\n}\n</code></pre>"},{"location":"lld/module1/News%20Feed/#4-key-workflows","title":"4. Key Workflows","text":"<p>a) Post 1. User posts content; service stores post. 2. Updates followers' feeds.</p> <p>b) Get Feed 1. Service fetches posts for user, ranks and filters.</p>"},{"location":"lld/module1/News%20Feed/#5-code-implementation-java","title":"5. Code Implementation (Java)","text":"<pre><code>import java.util.*;\n\nclass Post {\n    String id;\n    String userId;\n    String content;\n    long ts;\n}\n\nclass User {\n    String id;\n    String name;\n    Set&lt;String&gt; following = new HashSet&lt;&gt;();\n}\n\nclass FeedService {\n    private final Map&lt;String, User&gt; users = new HashMap&lt;&gt;();\n    private final Map&lt;String, List&lt;Post&gt;&gt; posts = new HashMap&lt;&gt;();\n    public void post(String userId, String content) {\n        Post p = new Post();\n        p.id = UUID.randomUUID().toString();\n        p.userId = userId;\n        p.content = content;\n        p.ts = System.currentTimeMillis();\n        posts.computeIfAbsent(userId, k -&gt; new ArrayList&lt;&gt;()).add(p);\n    }\n    public List&lt;Post&gt; getFeed(String userId) {\n        User user = users.get(userId);\n        List&lt;Post&gt; feed = new ArrayList&lt;&gt;();\n        for (String followee : user.following) {\n            feed.addAll(posts.getOrDefault(followee, List.of()));\n        }\n        feed.sort(Comparator.comparingLong(p -&gt; -p.ts));\n        return feed;\n    }\n}\n</code></pre>"},{"location":"lld/module1/News%20Feed/#6-testing-junit-5","title":"6. Testing (JUnit 5)","text":"<pre><code>import org.junit.jupiter.api.*;\nimport static org.junit.jupiter.api.Assertions.*;\n\npublic class FeedServiceTest {\n    @Test\n    void testPostAndFeed() {\n        // Setup users, post, get feed, assert order\n    }\n}\n</code></pre>"},{"location":"lld/module1/News%20Feed/#7-extensions-and-edge-cases","title":"7. Extensions and Edge Cases","text":"<ul> <li>Add feed ranking, filtering, and pagination.</li> <li>Support for comments, likes, and notifications.</li> <li>Integrate with recommendation engine.</li> </ul>"},{"location":"lld/module1/Notification%20System/","title":"Design a Notification/Observer System","text":"<p>This problem requires designing a notification system using the Observer pattern, supporting multiple channels and subscribers.</p>"},{"location":"lld/module1/Notification%20System/#1-system-overview-scope-clarification","title":"1. System Overview &amp; Scope Clarification","text":"<p>We are designing a backend service to send notifications to users via multiple channels (email, SMS, push), supporting subscriptions and event-driven delivery.</p> <p>Functional Requirements (FR): - Subscribe/unsubscribe to topics/events. - Notify all subscribers on event. - Support multiple channels (email, SMS, push). - Delivery guarantees (at-least-once).</p> <p>Non-Functional Requirements (NFR): - Low latency (real-time delivery). - Scalable to millions of users/events. - Extensible for new channels.</p> <p>Assumptions: - In-memory for demo; production uses message queues.</p>"},{"location":"lld/module1/Notification%20System/#2-core-components-and-class-design","title":"2. Core Components and Class Design","text":"<ul> <li>NotificationService: Main API for subscribe/notify.</li> <li>Subscriber: Interface for notification channels.</li> <li>Event: Represents an event/topic.</li> </ul> <p>Class Diagram (Textual Representation):</p> <pre><code>+---------------------+\n| NotificationService |\n+---------------------+\n| + subscribe()       |\n| + unsubscribe()     |\n| + notify()          |\n+---------------------+\n        ^\n        |\n+---------------------+\n|   Subscriber        |\n+---------------------+\n| + notify()          |\n+---------------------+\n</code></pre>"},{"location":"lld/module1/Notification%20System/#3-api-design-notificationservice","title":"3. API Design (<code>NotificationService</code>)","text":"<p>Java</p> <pre><code>class NotificationService {\n    void subscribe(String event, Subscriber s);\n    void unsubscribe(String event, Subscriber s);\n    void notify(String event, String message);\n}\n</code></pre>"},{"location":"lld/module1/Notification%20System/#4-key-workflows","title":"4. Key Workflows","text":"<p>a) Subscribe/Unsubscribe 1. User subscribes/unsubscribes to event/topic. 2. Service updates subscriber list.</p> <p>b) Notify 1. Event occurs; service notifies all subscribers. 2. Each subscriber receives message via their channel.</p>"},{"location":"lld/module1/Notification%20System/#5-code-implementation-java","title":"5. Code Implementation (Java)","text":"<pre><code>import java.util.*;\n\ninterface Subscriber {\n    void notify(String message);\n}\n\nclass NotificationService {\n    private final Map&lt;String, List&lt;Subscriber&gt;&gt; subs = new HashMap&lt;&gt;();\n    public void subscribe(String event, Subscriber s) {\n        subs.computeIfAbsent(event, k -&gt; new ArrayList&lt;&gt;()).add(s);\n    }\n    public void unsubscribe(String event, Subscriber s) {\n        List&lt;Subscriber&gt; list = subs.get(event);\n        if (list != null) list.remove(s);\n    }\n    public void notify(String event, String message) {\n        List&lt;Subscriber&gt; list = subs.get(event);\n        if (list != null) for (Subscriber s : list) s.notify(message);\n    }\n}\n</code></pre>"},{"location":"lld/module1/Notification%20System/#6-testing-junit-5","title":"6. Testing (JUnit 5)","text":"<pre><code>import org.junit.jupiter.api.*;\nimport static org.junit.jupiter.api.Assertions.*;\n\npublic class NotificationServiceTest {\n    @Test\n    void testSubscribeAndNotify() {\n        NotificationService svc = new NotificationService();\n        List&lt;String&gt; received = new ArrayList&lt;&gt;();\n        Subscriber s = received::add;\n        svc.subscribe(\"event1\", s);\n        svc.notify(\"event1\", \"msg\");\n        assertEquals(List.of(\"msg\"), received);\n    }\n}\n</code></pre>"},{"location":"lld/module1/Notification%20System/#7-extensions-and-edge-cases","title":"7. Extensions and Edge Cases","text":"<ul> <li>Add message queues for reliability.</li> <li>Support for retries, dead-letter queues.</li> <li>Add filtering and batching.</li> </ul>"},{"location":"lld/module1/Payment%20Wallet/","title":"Design a Payment Wallet System","text":"<p>This problem requires designing a digital payment wallet supporting balance management, transfers, and transaction history.</p>"},{"location":"lld/module1/Payment%20Wallet/#1-system-overview-scope-clarification","title":"1. System Overview &amp; Scope Clarification","text":"<p>We are designing a backend service to manage user balances, transfers, and transaction records securely.</p> <p>Functional Requirements (FR): - Add/withdraw funds. - Transfer funds between users. - Track transaction history. - Support for refunds and reversals.</p> <p>Non-Functional Requirements (NFR): - Secure and auditable. - Scalable to millions of users/transactions. - Low latency for transfers.</p> <p>Assumptions: - In-memory for demo; production uses DB and payment gateway.</p>"},{"location":"lld/module1/Payment%20Wallet/#2-core-components-and-class-design","title":"2. Core Components and Class Design","text":"<ul> <li>WalletService: Main API for wallet ops.</li> <li>User/Wallet: Represents users and balances.</li> <li>Transaction: Represents a transfer or operation.</li> </ul> <p>Class Diagram (Textual Representation):</p> <pre><code>+--------+      +--------+\n| User   |&lt;-----| Wallet |\n+--------+      +--------+\n| id     |      | id     |\n| name   |      | balance|\n+--------+      +--------+\n      ^\n      |\n+--------------+\n|Transaction   |\n+--------------+\n| id, from, to |\n| amount, ts   |\n+--------------+\n</code></pre>"},{"location":"lld/module1/Payment%20Wallet/#3-api-design-walletservice","title":"3. API Design (<code>WalletService</code>)","text":"<p>Java</p> <pre><code>class WalletService {\n    void addFunds(String userId, double amount);\n    void transfer(String fromUser, String toUser, double amount);\n    List&lt;Transaction&gt; getHistory(String userId);\n}\n</code></pre>"},{"location":"lld/module1/Payment%20Wallet/#4-key-workflows","title":"4. Key Workflows","text":"<p>a) Add/Withdraw Funds 1. User adds/withdraws funds; service updates balance and records transaction.</p> <p>b) Transfer 1. User transfers funds; service checks balance, updates both wallets, records transaction.</p>"},{"location":"lld/module1/Payment%20Wallet/#5-code-implementation-java","title":"5. Code Implementation (Java)","text":"<pre><code>import java.util.*;\n\nclass Wallet {\n    String id;\n    double balance;\n}\n\nclass Transaction {\n    String id;\n    String from, to;\n    double amount;\n    long ts;\n}\n\nclass User {\n    String id;\n    String name;\n    Wallet wallet = new Wallet();\n    List&lt;Transaction&gt; history = new ArrayList&lt;&gt;();\n}\n\nclass WalletService {\n    private final Map&lt;String, User&gt; users = new HashMap&lt;&gt;();\n    public void addFunds(String userId, double amount) {\n        User user = users.computeIfAbsent(userId, k -&gt; new User());\n        user.wallet.id = userId;\n        user.wallet.balance += amount;\n        Transaction t = new Transaction();\n        t.id = UUID.randomUUID().toString();\n        t.from = \"external\";\n        t.to = userId;\n        t.amount = amount;\n        t.ts = System.currentTimeMillis();\n        user.history.add(t);\n    }\n    public void transfer(String fromUser, String toUser, double amount) {\n        User from = users.get(fromUser);\n        User to = users.get(toUser);\n        if (from == null || to == null) throw new RuntimeException(\"User not found\");\n        if (from.wallet.balance &lt; amount) throw new RuntimeException(\"Insufficient funds\");\n        from.wallet.balance -= amount;\n        to.wallet.balance += amount;\n        Transaction t = new Transaction();\n        t.id = UUID.randomUUID().toString();\n        t.from = fromUser;\n        t.to = toUser;\n        t.amount = amount;\n        t.ts = System.currentTimeMillis();\n        from.history.add(t);\n        to.history.add(t);\n    }\n    public List&lt;Transaction&gt; getHistory(String userId) {\n        User user = users.get(userId);\n        if (user == null) return List.of();\n        return user.history;\n    }\n}\n</code></pre>"},{"location":"lld/module1/Payment%20Wallet/#6-testing-junit-5","title":"6. Testing (JUnit 5)","text":"<pre><code>import org.junit.jupiter.api.*;\nimport static org.junit.jupiter.api.Assertions.*;\n\npublic class WalletServiceTest {\n    @Test\n    void testAddFundsAndTransfer() {\n        // Setup users, add/transfer funds, assert balances\n    }\n}\n</code></pre>"},{"location":"lld/module1/Payment%20Wallet/#7-extensions-and-edge-cases","title":"7. Extensions and Edge Cases","text":"<ul> <li>Add fraud detection, KYC, and compliance.</li> <li>Support for multiple currencies and wallets.</li> <li>Integrate with payment gateways and banks.</li> </ul>"},{"location":"lld/module1/Rate%20Limiter/","title":"Design a Scalable Rate Limiter","text":"<p>This problem requires designing a distributed, scalable rate limiter (token bucket/leaky bucket) for APIs or services.</p>"},{"location":"lld/module1/Rate%20Limiter/#1-system-overview-scope-clarification","title":"1. System Overview &amp; Scope Clarification","text":"<p>We are designing a backend service to limit the rate of requests per user, API key, or IP, supporting distributed deployments.</p> <p>Functional Requirements (FR): - Enforce rate limits (e.g., 100 req/min) per key. - Support burst and steady rates (token bucket). - Distributed: works across multiple servers. - Configurable per user/API.</p> <p>Non-Functional Requirements (NFR): - Low latency (sub-ms per check). - High throughput (10k+ req/sec). - Fault-tolerant and consistent.</p> <p>Assumptions: - Redis or similar is available for distributed state. - In-memory fallback for demo.</p>"},{"location":"lld/module1/Rate%20Limiter/#2-core-components-and-class-design","title":"2. Core Components and Class Design","text":"<ul> <li>RateLimiter: Main API for checking/consuming tokens.</li> <li>TokenBucket: Per-key state (tokens, last refill).</li> <li>Store: Interface for state (in-memory/Redis).</li> </ul> <p>Class Diagram (Textual Representation):</p> <pre><code>+-------------+\n| RateLimiter |\n+-------------+\n| + allow()   |\n| - store     |\n+-------------+\n        ^\n        |\n+-------------+\n| TokenBucket |\n+-------------+\n| tokens      |\n| lastRefill  |\n+-------------+\n</code></pre>"},{"location":"lld/module1/Rate%20Limiter/#3-api-design-ratelimiter","title":"3. API Design (<code>RateLimiter</code>)","text":"<p>Java</p> <pre><code>class RateLimiter {\n    boolean allow(String key);\n}\n</code></pre>"},{"location":"lld/module1/Rate%20Limiter/#4-key-workflows","title":"4. Key Workflows","text":"<p>a) Allow Request 1. Fetch bucket for key. 2. Refill tokens if needed. 3. If tokens &gt; 0, allow and decrement; else, reject. 4. Persist state.</p>"},{"location":"lld/module1/Rate%20Limiter/#5-code-implementation-java","title":"5. Code Implementation (Java)","text":"<pre><code>import java.util.*;\nimport java.util.concurrent.ConcurrentHashMap;\n\nclass TokenBucket {\n    int tokens;\n    long lastRefill;\n    final int capacity;\n    final int refillRate;\n    TokenBucket(int capacity, int refillRate) {\n        this.capacity = capacity;\n        this.refillRate = refillRate;\n        this.tokens = capacity;\n        this.lastRefill = System.currentTimeMillis();\n    }\n}\n\nclass InMemoryStore {\n    private final Map&lt;String, TokenBucket&gt; buckets = new ConcurrentHashMap&lt;&gt;();\n    public TokenBucket get(String key) { return buckets.get(key); }\n    public void put(String key, TokenBucket bucket) { buckets.put(key, bucket); }\n}\n\nclass RateLimiter {\n    private final InMemoryStore store = new InMemoryStore();\n    public boolean allow(String key) {\n        TokenBucket bucket = store.get(key);\n        if (bucket == null) {\n            bucket = new TokenBucket(100, 100); // 100 tokens/min\n            store.put(key, bucket);\n        }\n        refill(bucket);\n        if (bucket.tokens &gt; 0) {\n            bucket.tokens--;\n            return true;\n        }\n        return false;\n    }\n    private void refill(TokenBucket bucket) {\n        long now = System.currentTimeMillis();\n        long elapsed = now - bucket.lastRefill;\n        int tokensToAdd = (int)(elapsed / 600);\n        if (tokensToAdd &gt; 0) {\n            bucket.tokens = Math.min(bucket.capacity, bucket.tokens + tokensToAdd);\n            bucket.lastRefill = now;\n        }\n    }\n}\n</code></pre>"},{"location":"lld/module1/Rate%20Limiter/#6-testing-junit-5","title":"6. Testing (JUnit 5)","text":"<pre><code>import org.junit.jupiter.api.*;\nimport static org.junit.jupiter.api.Assertions.*;\n\npublic class RateLimiterTest {\n    @Test\n    void testAllow() {\n        RateLimiter rl = new RateLimiter();\n        for (int i = 0; i &lt; 100; i++) assertTrue(rl.allow(\"user1\"));\n        assertFalse(rl.allow(\"user1\"));\n    }\n}\n</code></pre>"},{"location":"lld/module1/Rate%20Limiter/#7-extensions-and-edge-cases","title":"7. Extensions and Edge Cases","text":"<ul> <li>Use Redis for distributed buckets.</li> <li>Add leaky bucket, sliding window algorithms.</li> <li>Support for dynamic configs and quotas.</li> </ul>"},{"location":"lld/module1/Ride%20Sharing%20Service/","title":"Design a Ride-Sharing Matching Service (Uber)","text":"<p>This problem requires designing a real-time ride-matching service for a ride-sharing platform like Uber or Lyft.</p>"},{"location":"lld/module1/Ride%20Sharing%20Service/#1-system-overview-scope-clarification","title":"1. System Overview &amp; Scope Clarification","text":"<p>We are designing a backend service to match riders and drivers in real time, supporting surge pricing and location-based matching.</p> <p>Functional Requirements (FR): - Register drivers/riders and update locations. - Match riders to nearest available drivers. - Support surge pricing and cancellations. - Track trip state (requested, accepted, completed).</p> <p>Non-Functional Requirements (NFR): - Low latency (real-time matching). - Scalable to millions of users. - Fault-tolerant and highly available.</p> <p>Assumptions: - In-memory for demo; production uses distributed DB and geospatial index.</p>"},{"location":"lld/module1/Ride%20Sharing%20Service/#2-core-components-and-class-design","title":"2. Core Components and Class Design","text":"<ul> <li>RideService: Main API for matching.</li> <li>Driver/Rider: Represents users.</li> <li>Trip: Represents a ride.</li> <li>Location: Geospatial data.</li> <li>MatchingEngine: Finds nearest driver.</li> </ul> <p>Class Diagram (Textual Representation):</p> <pre><code>+-----------+      +--------+\n| Driver    |      | Rider  |\n+-----------+      +--------+\n| id, loc   |      | id, loc|\n+-----------+      +--------+\n      ^\n      |\n+-----------+\n| Matching  |\n|  Engine   |\n+-----------+\n| + match() |\n+-----------+\n</code></pre>"},{"location":"lld/module1/Ride%20Sharing%20Service/#3-api-design-rideservice","title":"3. API Design (<code>RideService</code>)","text":"<p>Java</p> <pre><code>class RideService {\n    void registerDriver(String id, Location loc);\n    void registerRider(String id, Location loc);\n    Trip requestRide(String riderId, Location dest);\n    void updateLocation(String id, Location loc);\n}\n</code></pre>"},{"location":"lld/module1/Ride%20Sharing%20Service/#4-key-workflows","title":"4. Key Workflows","text":"<p>a) Request Ride 1. Rider requests ride; service finds nearest driver. 2. Assigns trip, updates state.</p> <p>b) Update Location 1. Driver/rider updates location; service updates index.</p>"},{"location":"lld/module1/Ride%20Sharing%20Service/#5-code-implementation-java","title":"5. Code Implementation (Java)","text":"<pre><code>import java.util.*;\n\nclass Location {\n    double lat, lon;\n}\n\nclass Driver {\n    String id;\n    Location loc;\n    boolean available = true;\n}\n\nclass Rider {\n    String id;\n    Location loc;\n}\n\nclass Trip {\n    String id;\n    String driverId, riderId;\n    Location from, to;\n    String state;\n}\n\nclass RideService {\n    private final Map&lt;String, Driver&gt; drivers = new HashMap&lt;&gt;();\n    private final Map&lt;String, Rider&gt; riders = new HashMap&lt;&gt;();\n    public void registerDriver(String id, Location loc) {\n        Driver d = new Driver();\n        d.id = id; d.loc = loc; d.available = true;\n        drivers.put(id, d);\n    }\n    public void registerRider(String id, Location loc) {\n        Rider r = new Rider();\n        r.id = id; r.loc = loc;\n        riders.put(id, r);\n    }\n    public Trip requestRide(String riderId, Location dest) {\n        Rider rider = riders.get(riderId);\n        if (rider == null) return null;\n        Driver nearest = null;\n        double minDist = Double.MAX_VALUE;\n        for (Driver d : drivers.values()) {\n            if (!d.available) continue;\n            double dist = Math.hypot(d.loc.lat - rider.loc.lat, d.loc.lon - rider.loc.lon);\n            if (dist &lt; minDist) {\n                minDist = dist;\n                nearest = d;\n            }\n        }\n        if (nearest == null) return null;\n        nearest.available = false;\n        Trip trip = new Trip();\n        trip.id = UUID.randomUUID().toString();\n        trip.driverId = nearest.id;\n        trip.riderId = riderId;\n        trip.from = rider.loc;\n        trip.to = dest;\n        trip.state = \"requested\";\n        return trip;\n    }\n    public void updateLocation(String id, Location loc) {\n        if (drivers.containsKey(id)) drivers.get(id).loc = loc;\n        if (riders.containsKey(id)) riders.get(id).loc = loc;\n    }\n}\n</code></pre>"},{"location":"lld/module1/Ride%20Sharing%20Service/#6-testing-junit-5","title":"6. Testing (JUnit 5)","text":"<pre><code>import org.junit.jupiter.api.*;\nimport static org.junit.jupiter.api.Assertions.*;\n\npublic class RideServiceTest {\n    @Test\n    void testRequestRide() {\n        // Setup drivers/riders, request ride, assert trip\n    }\n}\n</code></pre>"},{"location":"lld/module1/Ride%20Sharing%20Service/#7-extensions-and-edge-cases","title":"7. Extensions and Edge Cases","text":"<ul> <li>Add geospatial index (e.g., k-d tree, R-tree).</li> <li>Handle surge pricing, cancellations, and no-shows.</li> <li>Add trip history and analytics.</li> </ul>"}]}